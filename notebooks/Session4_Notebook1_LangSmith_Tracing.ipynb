{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nObC08RLarHB"
      },
      "source": [
        "# Session 4.1: BakeryAI - LangSmith Tracing & Observability\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/15iijCXgCn0xgj35mmglpfWL6CYtpWGaC?usp=sharing)\n",
        "\n",
        "## üéØ Production Readiness: Observability\n",
        "\n",
        "### Why Observability Matters\n",
        "\n",
        "In production, you need to know:\n",
        "- üìä **What's happening**: Which tools are being called?\n",
        "- ‚è±Ô∏è **Performance**: How long does each step take?\n",
        "- üí∞ **Cost**: How many tokens are we using?\n",
        "- üêõ **Errors**: Where do failures occur?\n",
        "- üìà **Quality**: Are responses getting better or worse?\n",
        "\n",
        "### What is LangSmith?\n",
        "\n",
        "**LangSmith** is LangChain's official observability and evaluation platform:\n",
        "\n",
        "```\n",
        "Your Application\n",
        "     ‚Üì\n",
        "[LangSmith Tracing]\n",
        "     ‚Üì\n",
        "Dashboard Shows:\n",
        "- Every LLM call\n",
        "- Tool executions\n",
        "- Latency metrics\n",
        "- Token usage\n",
        "- Error logs\n",
        "- User feedback\n",
        "```\n",
        "\n",
        "### LangSmith Features:\n",
        "\n",
        "1. **Tracing**: See every step of agent execution\n",
        "2. **Monitoring**: Real-time performance metrics\n",
        "3. **Debugging**: Pinpoint errors instantly\n",
        "4. **Evaluation**: Test prompts and chains\n",
        "5. **Datasets**: Build test suites\n",
        "6. **Feedback**: Collect user ratings\n",
        "\n",
        "Let's instrument BakeryAI! üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaQL0V3sarHG",
        "outputId": "749575cc-198d-4433-ec6b-88ee937f33a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/76.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-openai langsmith\n",
        "!pip install -q python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXgynuFmarHI"
      },
      "source": [
        "## 1. Setting Up LangSmith\n",
        "\n",
        "**Get your API keys:**\n",
        "1. Go to https://smith.langchain.com\n",
        "2. Sign up for free account\n",
        "3. Go to Settings ‚Üí API Keys\n",
        "4. Create a new API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8hHo-BGjcaGI"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Set OpenAI API key from Google Colab's user environment or default\n",
        "def set_openai_api_key(default_key: str = \"YOUR_API_KEY\") -> None:\n",
        "    \"\"\"Set the OpenAI API key from Google Colab's user environment or use a default value.\"\"\"\n",
        "    #if not (userdata.get(\"OPENAI_API_KEY\") or \"OPENAI_API_KEY\" in os.environ):\n",
        "    try:\n",
        "      os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"MDX_OPENAI_API_KEY\")\n",
        "    except:\n",
        "      os.environ[\"OPENAI_API_KEY\"] = default_key\n",
        "\n",
        "set_openai_api_key()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE5YFXu-arHI",
        "outputId": "429d9fc8-f03b-454d-8b07-6d4cd0870fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LangSmith Configuration:\n",
            "   Tracing Enabled: true\n",
            "   Project: mdx-conclave-agents\n",
            "\n",
            "‚ö†Ô∏è  Make sure to set LANGCHAIN_API_KEY in your .env file!\n"
          ]
        }
      ],
      "source": [
        "# Enable LangSmith tracing\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"MDX_LANGSMITH_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"mdx-conclave-agents\"  # Project name\n",
        "\n",
        "print(\"‚úÖ LangSmith Configuration:\")\n",
        "print(f\"   Tracing Enabled: {os.getenv('LANGCHAIN_TRACING_V2')}\")\n",
        "print(f\"   Project: {os.getenv('LANGCHAIN_PROJECT')}\")\n",
        "print(\"\\n‚ö†Ô∏è  Make sure to set LANGCHAIN_API_KEY in your .env file!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdW9OPcFarHK",
        "outputId": "7b1139de-316e-4d79-fcd6-33cf9fed6810"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LangChain initialized with LangSmith tracing\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "print(\"‚úÖ LangChain initialized with LangSmith tracing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFfRE50aarHK"
      },
      "source": [
        "## 2. Basic Tracing\n",
        "\n",
        "Every LangChain call is now automatically traced!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH9G_P3yarHL",
        "outputId": "0fd4db15-d109-45ca-e351-9d8c38dfbe4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: A good chocolate cake is the perfect balance of rich flavor, moist texture, and an appealing appearance. Here are some key elements that contribute to making a great chocolate cake:\n",
            "\n",
            "1. **Quality Ingredients:** Use high-quality cocoa powder or chocolate, preferably with a higher cocoa content for a rich flavor. Fresh eggs, real butter, and pure vanilla extract will also enhance the taste.\n",
            "\n",
            "2. **Moisture:** A good chocolate cake should be moist without being overly dense. Ingredients like buttermilk, sour cream, or even coffee can add moisture and depth of flavor.\n",
            "\n",
            "3. **Texture:** The cake should be fluffy with a tender crumb. Properly sifting the dry ingredients and not over-mixing the batter can help achieve this. Incorporating air by creaming the butter and sugar well can also contribute to a lighter texture.\n",
            "\n",
            "4. **Balance of Flavors:** The bitterness of the chocolate should be balanced with the sweetness from sugar and the richness from fats like butter or oil. A hint of salt can enhance these flavors further.\n",
            "\n",
            "5. **Even Baking:** Ensure even baking by preheating the oven correctly and using the appropriate size baking pans. The cake should rise evenly without doming or sinking.\n",
            "\n",
            "6. **Consistency:** A great chocolate cake should have a consistent flavor and texture throughout, without any dry or overly moist spots.\n",
            "\n",
            "7. **Frosting:** While the cake itself must be delicious, a good frosting can make it even better. A creamy, smooth chocolate ganache or buttercream can complement the cake‚Äôs flavor and add an extra layer of richness.\n",
            "\n",
            "8. **Decoration:** An inviting appearance with a smooth frosting, perhaps garnished with chocolate shavings, berries, or nuts, can make the cake even more appealing.\n",
            "\n",
            "9. **Serving Temperature:** A chocolate cake can taste different at various temperatures. It is often best served at room temperature where the flavors are more pronounced.\n",
            "\n",
            "By focusing on these elements, you can create a chocolate cake that is not only delicious but looks stunning as well.\n",
            "\n",
            "‚úÖ Check LangSmith dashboard to see the trace!\n",
            "   Go to: https://smith.langchain.com\n"
          ]
        }
      ],
      "source": [
        "# Simple chain with automatic tracing\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"You are a helpful bakery assistant. Answer: {question}\"\n",
        ")\n",
        "\n",
        "chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# This will be traced in LangSmith!\n",
        "result = chain.invoke({\"question\": \"What makes a good chocolate cake?\"})\n",
        "\n",
        "print(\"Answer:\", result)\n",
        "print(\"\\n‚úÖ Check LangSmith dashboard to see the trace!\")\n",
        "print(\"   Go to: https://smith.langchain.com\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HA6aZLdarHL"
      },
      "source": [
        "## 3. Tracing with Custom Names and Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MrSPUhqarHM",
        "outputId": "69003983-dbd2-4531-e32a-652f6e53e98c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommendation: For a birthday party with a chocolate-loving honoree, I recommend a decadent Chocolate Fudge Cake. This cake is rich, moist, and intensely chocolate-flavored, making it a perfect centerpiece for the celebration. \n",
            "\n",
            "The layers are made with high-quality cocoa and dark chocolate to enhance the depth of flavor. The cake is generously filled and frosted with a luscious chocolate ganache or a silky chocolate buttercream, depending on preference. For an extra touch of indulgence, consider adding a layer of chocolate mousse inside or a drizzle of chocolate ganache on top. Garnish with chocolate shavings or curls for added visual appeal and texture.\n",
            "\n",
            "This cake will surely delight any chocolate enthusiast and leave a lasting impression on all the party guests.\n",
            "\n",
            "‚úÖ This trace includes custom tags and metadata!\n"
          ]
        }
      ],
      "source": [
        "from langsmith import traceable\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "@traceable(name=\"bakery_recommendation\")\n",
        "def get_cake_recommendation(occasion: str, preferences: str) -> str:\n",
        "    \"\"\"Get cake recommendation with custom tracing\"\"\"\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(\n",
        "        \"\"\"Recommend a cake for this occasion and preferences.\n",
        "\n",
        "        Occasion: {occasion}\n",
        "        Preferences: {preferences}\n",
        "\n",
        "        Provide a specific recommendation.\"\"\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "    # Add metadata to trace\n",
        "    config = RunnableConfig(\n",
        "        run_name=\"cake_recommendation\",\n",
        "        tags=[\"recommendation\", \"customer_facing\"],\n",
        "        metadata={\n",
        "            \"occasion\": occasion,\n",
        "            \"preferences\": preferences,\n",
        "            \"version\": \"1.0\"\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return chain.invoke(\n",
        "        {\"occasion\": occasion, \"preferences\": preferences},\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "# Test with tracing\n",
        "result = get_cake_recommendation(\n",
        "    occasion=\"birthday party\",\n",
        "    preferences=\"chocolate lover\"\n",
        ")\n",
        "\n",
        "print(\"Recommendation:\", result)\n",
        "print(\"\\n‚úÖ This trace includes custom tags and metadata!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMwVONrnarHN"
      },
      "source": [
        "## 4. Tracing Agents and Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHtID97BarHN",
        "outputId": "9a784697-66ce-406d-b483-9f1f74a92935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Agent created with traced tools\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool\n",
        "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "\n",
        "@tool\n",
        "@traceable(name=\"check_inventory_tool\")\n",
        "def check_inventory(product_name: str) -> str:\n",
        "    \"\"\"Check product inventory status.\n",
        "\n",
        "    Args:\n",
        "        product_name: Name of the product to check\n",
        "\n",
        "    Returns:\n",
        "        Inventory status\n",
        "    \"\"\"\n",
        "    # Simulate inventory check\n",
        "    import random\n",
        "\n",
        "    in_stock = random.random() < 0.8\n",
        "\n",
        "    if in_stock:\n",
        "        stock = random.randint(5, 20)\n",
        "        return f\"‚úÖ {product_name} in stock: {stock} units\"\n",
        "    else:\n",
        "        return f\"‚ùå {product_name} out of stock\"\n",
        "\n",
        "@tool\n",
        "@traceable(name=\"calculate_price_tool\")\n",
        "def calculate_price(product: str, quantity: int) -> str:\n",
        "    \"\"\"Calculate order price.\n",
        "\n",
        "    Args:\n",
        "        product: Product name\n",
        "        quantity: Quantity to order\n",
        "\n",
        "    Returns:\n",
        "        Price calculation\n",
        "    \"\"\"\n",
        "    base_price = 45\n",
        "    total = base_price * quantity\n",
        "    delivery = 10 if total < 100 else 0\n",
        "\n",
        "    return f\"Price: ${total}, Delivery: ${delivery}, Total: ${total + delivery}\"\n",
        "\n",
        "# Create agent\n",
        "tools = [check_inventory, calculate_price]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are BakeryAI assistant. Help customers with orders.\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "])\n",
        "\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Agent created with traced tools\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GlFmnjFarHO",
        "outputId": "b4e0cee4-9f88-4907-91cc-f2aa36bbebae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result: The chocolate cake is in stock with 8 units available. The price for 3 chocolate cakes is $135, and there's no additional delivery charge, bringing the total to $135. Would you like to place an order?\n",
            "\n",
            "‚úÖ Check LangSmith - you'll see:\n",
            "   - Agent reasoning\n",
            "   - Tool calls (check_inventory, calculate_price)\n",
            "   - LLM calls\n",
            "   - Token usage\n",
            "   - Latency for each step\n"
          ]
        }
      ],
      "source": [
        "# Run agent - every step will be traced!\n",
        "result = agent_executor.invoke({\n",
        "    \"input\": \"Check if chocolate cake is in stock and calculate price for 3\"\n",
        "})\n",
        "\n",
        "print(\"Result:\", result['output'])\n",
        "print(\"\\n‚úÖ Check LangSmith - you'll see:\")\n",
        "print(\"   - Agent reasoning\")\n",
        "print(\"   - Tool calls (check_inventory, calculate_price)\")\n",
        "print(\"   - LLM calls\")\n",
        "print(\"   - Token usage\")\n",
        "print(\"   - Latency for each step\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJvXkRLUarHO"
      },
      "source": [
        "## 5. Capturing User Feedback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqQGxUPSarHO",
        "outputId": "604a7070-9946-4a0b-ca56-b89b768bd67d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LangSmith client initialized\n",
            "\n",
            "Example feedback capture:\n",
            "  capture_user_feedback(run_id='abc123', score=0.8, comment='Helpful!')\n"
          ]
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "# Initialize LangSmith client\n",
        "try:\n",
        "    client = Client()\n",
        "    print(\"‚úÖ LangSmith client initialized\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  LangSmith client not available: {e}\")\n",
        "    print(\"   Make sure LANGCHAIN_API_KEY is set in .env\")\n",
        "    client = None\n",
        "\n",
        "# Function to capture feedback\n",
        "def capture_user_feedback(run_id: str, score: float, comment: str = \"\"):\n",
        "    \"\"\"Capture user feedback for a run\n",
        "\n",
        "    Args:\n",
        "        run_id: The LangSmith run ID\n",
        "        score: Rating from 0-1 (or 1-5 scaled to 0-1)\n",
        "        comment: Optional feedback comment\n",
        "    \"\"\"\n",
        "    if client:\n",
        "        try:\n",
        "            client.create_feedback(\n",
        "                run_id=run_id,\n",
        "                key=\"user_rating\",\n",
        "                score=score,\n",
        "                comment=comment\n",
        "            )\n",
        "            print(f\"‚úÖ Feedback captured: {score} stars\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Could not capture feedback: {e}\")\n",
        "\n",
        "# Example: Capture feedback after agent run\n",
        "# In production, you'd get run_id from the trace\n",
        "print(\"\\nExample feedback capture:\")\n",
        "print(\"  capture_user_feedback(run_id='abc123', score=0.8, comment='Helpful!')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb0HUNtKarHO"
      },
      "source": [
        "## 6. Creating Datasets for Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-lV5x52arHP",
        "outputId": "cabb47f1-b0e1-4d63-c314-4ec710a4c4e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Created dataset: bakery-ai-test-cases\n",
            "   Examples: 3\n"
          ]
        }
      ],
      "source": [
        "# Create a test dataset\n",
        "test_cases = [\n",
        "    {\n",
        "        \"input\": \"What is your refund policy?\",\n",
        "        \"expected\": \"Should mention 24 hours and store credit\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Check if chocolate cake is available\",\n",
        "        \"expected\": \"Should use check_inventory tool\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"How much for 2 vanilla cakes?\",\n",
        "        \"expected\": \"Should use calculate_price tool\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Create dataset in LangSmith\n",
        "if client:\n",
        "    try:\n",
        "        dataset_name = \"bakery-ai-test-cases\"\n",
        "\n",
        "        # Create dataset\n",
        "        dataset = client.create_dataset(\n",
        "            dataset_name=dataset_name,\n",
        "            description=\"Test cases for BakeryAI agent\"\n",
        "        )\n",
        "\n",
        "        # Add examples\n",
        "        for case in test_cases:\n",
        "            client.create_example(\n",
        "                inputs={\"input\": case[\"input\"]},\n",
        "                outputs={\"expected\": case[\"expected\"]},\n",
        "                dataset_id=dataset.id\n",
        "            )\n",
        "\n",
        "        print(f\"‚úÖ Created dataset: {dataset_name}\")\n",
        "        print(f\"   Examples: {len(test_cases)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Dataset creation failed: {e}\")\n",
        "else:\n",
        "    print(\"üí° Dataset structure defined (requires LangSmith API key to create)\")\n",
        "    for i, case in enumerate(test_cases, 1):\n",
        "        print(f\"\\n{i}. Input: {case['input']}\")\n",
        "        print(f\"   Expected: {case['expected']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WSw6l_barHP"
      },
      "source": [
        "## 7. Running Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "1060487d04a741f6a2c27921f94d560d",
            "bacedd20d4624b2a8823af00a71e93c9",
            "138937c18054444d9710dcc6733b7640",
            "06232534d4594659bbc681e21c3446e0",
            "871653272b31483b9e143ae9493a3514",
            "378f9401f0a847d69143c85e653ca7fe",
            "b91e3a1f6c66490b94e6131532705311",
            "11f4450240ec4549abd9ccd948e104a1",
            "a17372f1e7f04579b0cb096394959491",
            "44f316ee89c245c1ac69e224a8cd33d5",
            "705ba62b9d7547d28e682bf296cad7c1"
          ]
        },
        "id": "rcd_n9hGarHP",
        "outputId": "2756a7fd-ee65-4347-c487-0f7b1facef5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Running evaluation...\n",
            "View the evaluation results for experiment: 'bakery-eval-4ea4e596' at:\n",
            "https://smith.langchain.com/o/570e9dfa-bc13-4000-96aa-f798e00a4212/datasets/42b09b39-211b-4e26-891e-8a177e68407b/compare?selectedSessions=36d29c66-3ff7-475d-b029-a0ec498e1eae\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1060487d04a741f6a2c27921f94d560d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Evaluation complete!\n",
            "   Results: <ExperimentResults bakery-eval-4ea4e596>\n"
          ]
        }
      ],
      "source": [
        "from langsmith.evaluation import evaluate\n",
        "\n",
        "def run_evaluation():\n",
        "    \"\"\"Run evaluation on test dataset\"\"\"\n",
        "\n",
        "    if not client:\n",
        "        print(\"‚ö†Ô∏è  LangSmith client not available\")\n",
        "        return\n",
        "\n",
        "    # Define evaluation function\n",
        "    def my_evaluator(run, example):\n",
        "        \"\"\"Simple evaluator - checks if output contains expected keywords\"\"\"\n",
        "        output = run.outputs.get(\"output\", \"\")\n",
        "        expected = example.outputs.get(\"expected\", \"\")\n",
        "\n",
        "        # Simple keyword matching\n",
        "        score = 1.0 if any(word in output.lower() for word in expected.lower().split()) else 0.0\n",
        "\n",
        "        return {\"key\": \"keyword_match\", \"score\": score}\n",
        "\n",
        "    # Run evaluation\n",
        "    try:\n",
        "        results = evaluate(\n",
        "            lambda inputs: agent_executor.invoke(inputs),\n",
        "            data=\"bakery-ai-test-cases\",\n",
        "            evaluators=[my_evaluator],\n",
        "            experiment_prefix=\"bakery-eval\"\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ Evaluation complete!\")\n",
        "        print(f\"   Results: {results}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Evaluation failed: {e}\")\n",
        "\n",
        "# Run evaluation\n",
        "print(\"üß™ Running evaluation...\")\n",
        "run_evaluation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FboXukEZarHS"
      },
      "source": [
        "## 8. Custom Tracing for Complex Workflows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO3llX0QarHT",
        "outputId": "ba37e26c-d896-41a9-cdb5-6c87e7b3605d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Order Processing Result:\n",
            "  customer_valid: True\n",
            "  inventory: {'available': True, 'quantity': 100}\n",
            "  price: {'total': 50.0, 'unit_price': 25.0}\n",
            "  order_id: ORD1761432412\n",
            "\n",
            "‚úÖ Check LangSmith - you'll see hierarchical trace of all steps!\n"
          ]
        }
      ],
      "source": [
        "from langsmith import traceable\n",
        "import time\n",
        "\n",
        "# Create separate functions for each step\n",
        "@traceable(name=\"validate_customer\")\n",
        "def validate_customer(customer_id: str):\n",
        "    \"\"\"Validate customer\"\"\"\n",
        "    time.sleep(0.1)  # Simulate\n",
        "    return True\n",
        "\n",
        "@traceable(name=\"check_inventory\")\n",
        "def check_inventory_step(product: str):\n",
        "    \"\"\"Check inventory for product\"\"\"\n",
        "    # Replace with your actual check_inventory.invoke() call\n",
        "    return {\"available\": True, \"quantity\": 100}\n",
        "\n",
        "@traceable(name=\"calculate_price\")\n",
        "def calculate_price_step(product: str, quantity: int):\n",
        "    \"\"\"Calculate price for order\"\"\"\n",
        "    # Replace with your actual calculate_price.invoke() call\n",
        "    base_price = 25.0 if \"Cake\" in product else 10.0\n",
        "    return {\"total\": base_price * quantity, \"unit_price\": base_price}\n",
        "\n",
        "@traceable(name=\"create_order\")\n",
        "def create_order_step(customer_id: str, product: str, quantity: int):\n",
        "    \"\"\"Create order record\"\"\"\n",
        "    time.sleep(0.1)  # Simulate\n",
        "    return f\"ORD{int(time.time())}\"\n",
        "\n",
        "@traceable(name=\"order_processing_workflow\")\n",
        "def process_order(customer_id: str, product: str, quantity: int):\n",
        "    \"\"\"Complete order processing with custom tracing\"\"\"\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Step 1: Validate customer\n",
        "    results['customer_valid'] = validate_customer(customer_id)\n",
        "\n",
        "    # Step 2: Check inventory\n",
        "    results['inventory'] = check_inventory_step(product)\n",
        "\n",
        "    # Step 3: Calculate price\n",
        "    results['price'] = calculate_price_step(product, quantity)\n",
        "\n",
        "    # Step 4: Create order\n",
        "    results['order_id'] = create_order_step(customer_id, product, quantity)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Test\n",
        "result = process_order(\n",
        "    customer_id=\"CUST123\",\n",
        "    product=\"Chocolate Cake\",\n",
        "    quantity=2\n",
        ")\n",
        "\n",
        "print(\"Order Processing Result:\")\n",
        "for key, value in result.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\n‚úÖ Check LangSmith - you'll see hierarchical trace of all steps!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWweHhpgarHV"
      },
      "source": [
        "## 9. Performance Monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-R_c-10arHW",
        "outputId": "bc006de0-ba9b-4697-9c0c-409f1de53a49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Running monitored requests...\n",
            "\n",
            "‚úÖ Request: Check chocolate cake inventory...\n",
            "   Latency: 1.46s\n",
            "\n",
            "‚úÖ Request: Calculate price for 2 vanilla cakes...\n",
            "   Latency: 1.48s\n",
            "\n",
            "‚úÖ Request: What is your refund policy?...\n",
            "   Latency: 3.11s\n",
            "\n",
            "\n",
            "üìà Performance Statistics:\n",
            "   total_requests: 3\n",
            "   success_rate: 100.0%\n",
            "   avg_latency: 2.02s\n",
            "   errors: 0\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "class PerformanceMonitor:\n",
        "    \"\"\"Monitor application performance\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.metrics = {\n",
        "            'total_requests': 0,\n",
        "            'total_latency': 0,\n",
        "            'errors': 0,\n",
        "            'success': 0\n",
        "        }\n",
        "\n",
        "    @traceable(name=\"monitored_request\")\n",
        "    def process_request(self, request_type: str, data: dict):\n",
        "        \"\"\"Process request with monitoring\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            # Process based on type\n",
        "            if request_type == \"chat\":\n",
        "                result = agent_executor.invoke(data)\n",
        "            else:\n",
        "                result = {\"output\": \"Unknown request type\"}\n",
        "\n",
        "            # Update metrics\n",
        "            self.metrics['success'] += 1\n",
        "            latency = time.time() - start_time\n",
        "            self.metrics['total_latency'] += latency\n",
        "            self.metrics['total_requests'] += 1\n",
        "\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"result\": result,\n",
        "                \"latency\": latency\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            self.metrics['errors'] += 1\n",
        "            self.metrics['total_requests'] += 1\n",
        "\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"error\": str(e),\n",
        "                \"latency\": time.time() - start_time\n",
        "            }\n",
        "\n",
        "    def get_stats(self):\n",
        "        \"\"\"Get performance statistics\"\"\"\n",
        "        avg_latency = (self.metrics['total_latency'] / self.metrics['total_requests']\n",
        "                      if self.metrics['total_requests'] > 0 else 0)\n",
        "\n",
        "        success_rate = (self.metrics['success'] / self.metrics['total_requests'] * 100\n",
        "                       if self.metrics['total_requests'] > 0 else 0)\n",
        "\n",
        "        return {\n",
        "            'total_requests': self.metrics['total_requests'],\n",
        "            'success_rate': f\"{success_rate:.1f}%\",\n",
        "            'avg_latency': f\"{avg_latency:.2f}s\",\n",
        "            'errors': self.metrics['errors']\n",
        "        }\n",
        "\n",
        "# Test monitoring\n",
        "monitor = PerformanceMonitor()\n",
        "\n",
        "test_requests = [\n",
        "    {\"input\": \"Check chocolate cake inventory\"},\n",
        "    {\"input\": \"Calculate price for 2 vanilla cakes\"},\n",
        "    {\"input\": \"What is your refund policy?\"}\n",
        "]\n",
        "\n",
        "print(\"üìä Running monitored requests...\\n\")\n",
        "\n",
        "for req in test_requests:\n",
        "    result = monitor.process_request(\"chat\", req)\n",
        "    print(f\"‚úÖ Request: {req['input'][:40]}...\")\n",
        "    print(f\"   Latency: {result['latency']:.2f}s\\n\")\n",
        "\n",
        "# Show statistics\n",
        "stats = monitor.get_stats()\n",
        "print(\"\\nüìà Performance Statistics:\")\n",
        "for key, value in stats.items():\n",
        "    print(f\"   {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh4qPOjAarHW"
      },
      "source": [
        "## 10. LangSmith Dashboard Overview\n",
        "\n",
        "**In the LangSmith dashboard, you can:**\n",
        "\n",
        "### üìä Traces\n",
        "- See every LLM call with inputs/outputs\n",
        "- Token usage per call\n",
        "- Latency breakdown\n",
        "- Tool executions\n",
        "\n",
        "### üìà Analytics\n",
        "- Request volume over time\n",
        "- Average latency trends\n",
        "- Error rates\n",
        "- Cost tracking\n",
        "\n",
        "### üß™ Datasets\n",
        "- Store test cases\n",
        "- Version control\n",
        "- Regression testing\n",
        "\n",
        "### ‚≠ê Feedback\n",
        "- User ratings\n",
        "- Comments\n",
        "- Track improvements\n",
        "\n",
        "### üéØ Experiments\n",
        "- A/B test prompts\n",
        "- Compare models\n",
        "- Evaluate performance\n",
        "\n",
        "**Go explore:** https://smith.langchain.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-54ZukwarHX"
      },
      "source": [
        "## Summary: What We Built\n",
        "\n",
        "### ‚úÖ Session 4.1 Achievements:\n",
        "\n",
        "1. **LangSmith Setup**: Configured tracing for all chains\n",
        "2. **Custom Tracing**: Added metadata and tags\n",
        "3. **Agent Tracing**: Monitored tool calls and reasoning\n",
        "4. **User Feedback**: Captured ratings and comments\n",
        "5. **Test Datasets**: Created evaluation suites\n",
        "6. **Evaluations**: Automated quality testing\n",
        "7. **Performance Monitoring**: Real-time metrics\n",
        "8. **Complex Workflows**: Hierarchical tracing\n",
        "\n",
        "### üéØ Production Observability:\n",
        "\n",
        "**Now you can:**\n",
        "- ‚úÖ See every step of agent execution\n",
        "- ‚úÖ Track token usage and costs\n",
        "- ‚úÖ Identify bottlenecks and errors\n",
        "- ‚úÖ Test changes with datasets\n",
        "- ‚úÖ Collect user feedback\n",
        "- ‚úÖ Monitor performance over time\n",
        "\n",
        "### üöÄ Next: Notebook 4.2\n",
        "\n",
        "We'll deploy BakeryAI with **LangServe**:\n",
        "- Create REST API endpoints\n",
        "- FastAPI integration\n",
        "- Async handling\n",
        "- Production deployment\n",
        "- Load balancing"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
