{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bonus Session: Advanced LangGraph Patterns\n",
        "\n",
        "## 🎯 Mastering Complex Workflows\n",
        "\n",
        "You've learned:\n",
        "- ✅ Session 1: LangChain fundamentals\n",
        "- ✅ Session 2: Agents and tools\n",
        "- ✅ Session 3: RAG and knowledge bases\n",
        "- ✅ Session 4: Deployment and optimization\n",
        "\n",
        "**Now:** Advanced patterns for production systems!\n",
        "\n",
        "### Today's Advanced Patterns:\n",
        "\n",
        "1. **Human-in-the-Loop**: Approval workflows\n",
        "2. **Persistent State**: Long-running conversations\n",
        "3. **Dynamic Graphs**: Self-modifying workflows\n",
        "4. **Parallel Branching**: Multiple paths simultaneously\n",
        "5. **Error Recovery**: Automatic retry and fallback\n",
        "6. **Streaming State**: Real-time updates\n",
        "7. **Subgraphs**: Modular, reusable components\n",
        "\n",
        "### Real-World Scenarios:\n",
        "\n",
        "- 🏥 Healthcare: Multi-step patient diagnosis\n",
        "- 💼 Finance: Complex approval workflows\n",
        "- 🛒 E-commerce: Order processing pipelines\n",
        "- 🎓 Education: Adaptive learning paths\n",
        "\n",
        "Let's build! 🚀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q langgraph langchain langchain-openai\n",
        "!pip install -q python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import TypedDict, Annotated, Literal\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "print(\"✅ Environment ready for advanced patterns!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Human-in-the-Loop Pattern\n",
        "\n",
        "Critical decisions require human approval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "class OrderState(TypedDict):\n",
        "    customer_id: str\n",
        "    order_id: str\n",
        "    product: str\n",
        "    quantity: int\n",
        "    total_amount: float\n",
        "    requires_approval: bool\n",
        "    approved: bool\n",
        "    status: str\n",
        "\n",
        "def validate_order(state: OrderState) -> OrderState:\n",
        "    \"\"\"Validate order and determine if approval needed\"\"\"\n",
        "    print(f\"\\n📋 Validating order {state['order_id']}...\")\n",
        "    \n",
        "    # Large orders require approval\n",
        "    if state['total_amount'] > 100:\n",
        "        state['requires_approval'] = True\n",
        "        state['status'] = 'pending_approval'\n",
        "        print(f\"   ⚠️  High value order (${state['total_amount']}) - requires approval\")\n",
        "    else:\n",
        "        state['requires_approval'] = False\n",
        "        state['approved'] = True\n",
        "        state['status'] = 'approved'\n",
        "        print(f\"   ✅ Order auto-approved (${state['total_amount']})\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "def human_approval_node(state: OrderState) -> OrderState:\n",
        "    \"\"\"Wait for human approval\"\"\"\n",
        "    print(f\"\\n👤 HUMAN APPROVAL REQUIRED\")\n",
        "    print(f\"   Order: {state['product']} x {state['quantity']}\")\n",
        "    print(f\"   Total: ${state['total_amount']}\")\n",
        "    print(f\"   Status: Waiting for manager approval...\")\n",
        "    \n",
        "    # In production, this would wait for actual human input\n",
        "    # For demo, we'll simulate approval\n",
        "    state['status'] = 'awaiting_approval'\n",
        "    return state\n",
        "\n",
        "def process_order(state: OrderState) -> OrderState:\n",
        "    \"\"\"Process approved order\"\"\"\n",
        "    print(f\"\\n✅ Processing order {state['order_id']}...\")\n",
        "    state['status'] = 'processing'\n",
        "    return state\n",
        "\n",
        "def should_get_approval(state: OrderState) -> Literal[\"approval\", \"process\"]:\n",
        "    \"\"\"Route based on approval requirement\"\"\"\n",
        "    if state['requires_approval'] and not state['approved']:\n",
        "        return \"approval\"\n",
        "    return \"process\"\n",
        "\n",
        "# Build graph with interruption\n",
        "workflow = StateGraph(OrderState)\n",
        "\n",
        "workflow.add_node(\"validate\", validate_order)\n",
        "workflow.add_node(\"human_approval\", human_approval_node)\n",
        "workflow.add_node(\"process\", process_order)\n",
        "\n",
        "workflow.set_entry_point(\"validate\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"validate\",\n",
        "    should_get_approval,\n",
        "    {\n",
        "        \"approval\": \"human_approval\",\n",
        "        \"process\": \"process\"\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"human_approval\", END)\n",
        "workflow.add_edge(\"process\", END)\n",
        "\n",
        "# Use checkpointer for interruption\n",
        "memory = MemorySaver()\n",
        "approval_app = workflow.compile(checkpointer=memory, interrupt_before=[\"process\"])\n",
        "\n",
        "print(\"✅ Human-in-the-loop workflow created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test human-in-the-loop\n",
        "print(\"🧪 Test 1: Small order (auto-approved)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "small_order = {\n",
        "    \"customer_id\": \"C001\",\n",
        "    \"order_id\": \"ORD001\",\n",
        "    \"product\": \"Chocolate Cake\",\n",
        "    \"quantity\": 1,\n",
        "    \"total_amount\": 45.0,\n",
        "    \"requires_approval\": False,\n",
        "    \"approved\": False,\n",
        "    \"status\": \"pending\"\n",
        "}\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"order_001\"}}\n",
        "result = approval_app.invoke(small_order, config)\n",
        "print(f\"\\n✅ Final status: {result['status']}\")\n",
        "\n",
        "# Test large order\n",
        "print(\"\\n\\n🧪 Test 2: Large order (requires approval)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "large_order = {\n",
        "    \"customer_id\": \"C002\",\n",
        "    \"order_id\": \"ORD002\",\n",
        "    \"product\": \"Wedding Cake\",\n",
        "    \"quantity\": 5,\n",
        "    \"total_amount\": 500.0,\n",
        "    \"requires_approval\": False,\n",
        "    \"approved\": False,\n",
        "    \"status\": \"pending\"\n",
        "}\n",
        "\n",
        "config2 = {\"configurable\": {\"thread_id\": \"order_002\"}}\n",
        "result2 = approval_app.invoke(large_order, config2)\n",
        "print(f\"\\n⏸️  Workflow paused: {result2['status']}\")\n",
        "print(\"   Waiting for human approval...\")\n",
        "\n",
        "# Simulate approval\n",
        "print(\"\\n👤 Manager approves order...\")\n",
        "result2['approved'] = True\n",
        "\n",
        "# Resume workflow\n",
        "resumed = approval_app.invoke(result2, config2)\n",
        "print(f\"\\n✅ Final status: {resumed['status']}\")\n",
        "\n",
        "print(\"\\n💡 Human-in-the-loop allows critical decision points!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Persistent Checkpointing\n",
        "\n",
        "Save state across sessions for long-running workflows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "\n",
        "class ConversationState(TypedDict):\n",
        "    messages: list\n",
        "    customer_id: str\n",
        "    session_count: int\n",
        "    last_topic: str\n",
        "\n",
        "def chat_node(state: ConversationState) -> ConversationState:\n",
        "    \"\"\"Process chat message\"\"\"\n",
        "    last_msg = state['messages'][-1] if state['messages'] else \"Hello\"\n",
        "    \n",
        "    response = f\"Session {state['session_count']}: Responding to '{last_msg[:30]}...'\"\n",
        "    state['messages'].append(response)\n",
        "    state['session_count'] += 1\n",
        "    \n",
        "    return state\n",
        "\n",
        "# Create persistent workflow\n",
        "persistent_workflow = StateGraph(ConversationState)\n",
        "persistent_workflow.add_node(\"chat\", chat_node)\n",
        "persistent_workflow.set_entry_point(\"chat\")\n",
        "persistent_workflow.add_edge(\"chat\", END)\n",
        "\n",
        "# Use SQLite for persistence\n",
        "with SqliteSaver.from_conn_string(\":memory:\") as checkpointer:\n",
        "    persistent_app = persistent_workflow.compile(checkpointer=checkpointer)\n",
        "    \n",
        "    # Session 1\n",
        "    print(\"🔵 Session 1:\")\n",
        "    state1 = {\n",
        "        \"messages\": [\"What cakes do you have?\"],\n",
        "        \"customer_id\": \"C123\",\n",
        "        \"session_count\": 1,\n",
        "        \"last_topic\": \"products\"\n",
        "    }\n",
        "    config = {\"configurable\": {\"thread_id\": \"customer_123\"}}\n",
        "    result1 = persistent_app.invoke(state1, config)\n",
        "    print(f\"   Messages: {result1['session_count']} total\")\n",
        "    \n",
        "    # Session 2 (continues from session 1)\n",
        "    print(\"\\n🔵 Session 2 (continuing):\")\n",
        "    state2 = {\n",
        "        \"messages\": result1['messages'] + [\"Tell me about chocolate cake\"],\n",
        "        \"customer_id\": \"C123\",\n",
        "        \"session_count\": result1['session_count'],\n",
        "        \"last_topic\": \"chocolate\"\n",
        "    }\n",
        "    result2 = persistent_app.invoke(state2, config)\n",
        "    print(f\"   Messages: {result2['session_count']} total\")\n",
        "    print(f\"   State persisted across sessions!\")\n",
        "\n",
        "print(\"\\n✅ Checkpointing enables long-running conversations!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Dynamic Graph Modification\n",
        "\n",
        "Graphs that change based on runtime conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DynamicState(TypedDict):\n",
        "    request_type: str\n",
        "    complexity: str\n",
        "    steps_taken: list\n",
        "    result: str\n",
        "\n",
        "def analyze_request(state: DynamicState) -> DynamicState:\n",
        "    \"\"\"Analyze and classify request\"\"\"\n",
        "    print(f\"\\n🔍 Analyzing request: {state['request_type']}\")\n",
        "    \n",
        "    # Determine complexity\n",
        "    if \"simple\" in state['request_type'].lower():\n",
        "        state['complexity'] = \"simple\"\n",
        "    else:\n",
        "        state['complexity'] = \"complex\"\n",
        "    \n",
        "    state['steps_taken'].append(\"analyze\")\n",
        "    print(f\"   Complexity: {state['complexity']}\")\n",
        "    return state\n",
        "\n",
        "def simple_handler(state: DynamicState) -> DynamicState:\n",
        "    \"\"\"Handle simple requests\"\"\"\n",
        "    print(\"   ⚡ Using simple handler (fast path)\")\n",
        "    state['steps_taken'].append(\"simple_handler\")\n",
        "    state['result'] = \"Quick answer\"\n",
        "    return state\n",
        "\n",
        "def complex_step1(state: DynamicState) -> DynamicState:\n",
        "    \"\"\"First step of complex processing\"\"\"\n",
        "    print(\"   🔧 Complex step 1: Data gathering\")\n",
        "    state['steps_taken'].append(\"complex_step1\")\n",
        "    return state\n",
        "\n",
        "def complex_step2(state: DynamicState) -> DynamicState:\n",
        "    \"\"\"Second step of complex processing\"\"\"\n",
        "    print(\"   🔧 Complex step 2: Analysis\")\n",
        "    state['steps_taken'].append(\"complex_step2\")\n",
        "    return state\n",
        "\n",
        "def complex_step3(state: DynamicState) -> DynamicState:\n",
        "    \"\"\"Third step of complex processing\"\"\"\n",
        "    print(\"   🔧 Complex step 3: Synthesis\")\n",
        "    state['steps_taken'].append(\"complex_step3\")\n",
        "    state['result'] = \"Detailed answer\"\n",
        "    return state\n",
        "\n",
        "def route_by_complexity(state: DynamicState) -> str:\n",
        "    \"\"\"Route based on complexity\"\"\"\n",
        "    return state['complexity']\n",
        "\n",
        "# Build dynamic graph\n",
        "dynamic_graph = StateGraph(DynamicState)\n",
        "\n",
        "dynamic_graph.add_node(\"analyze\", analyze_request)\n",
        "dynamic_graph.add_node(\"simple\", simple_handler)\n",
        "dynamic_graph.add_node(\"complex1\", complex_step1)\n",
        "dynamic_graph.add_node(\"complex2\", complex_step2)\n",
        "dynamic_graph.add_node(\"complex3\", complex_step3)\n",
        "\n",
        "dynamic_graph.set_entry_point(\"analyze\")\n",
        "\n",
        "dynamic_graph.add_conditional_edges(\n",
        "    \"analyze\",\n",
        "    route_by_complexity,\n",
        "    {\n",
        "        \"simple\": \"simple\",\n",
        "        \"complex\": \"complex1\"\n",
        "    }\n",
        ")\n",
        "\n",
        "dynamic_graph.add_edge(\"simple\", END)\n",
        "dynamic_graph.add_edge(\"complex1\", \"complex2\")\n",
        "dynamic_graph.add_edge(\"complex2\", \"complex3\")\n",
        "dynamic_graph.add_edge(\"complex3\", END)\n",
        "\n",
        "dynamic_app = dynamic_graph.compile()\n",
        "\n",
        "print(\"✅ Dynamic graph created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test dynamic routing\n",
        "print(\"\\n🧪 Test 1: Simple request\")\n",
        "print(\"=\"*60)\n",
        "simple_req = {\n",
        "    \"request_type\": \"simple product info\",\n",
        "    \"complexity\": \"\",\n",
        "    \"steps_taken\": [],\n",
        "    \"result\": \"\"\n",
        "}\n",
        "result1 = dynamic_app.invoke(simple_req)\n",
        "print(f\"\\n✅ Steps: {' → '.join(result1['steps_taken'])}\")\n",
        "print(f\"   Result: {result1['result']}\")\n",
        "\n",
        "print(\"\\n\\n🧪 Test 2: Complex request\")\n",
        "print(\"=\"*60)\n",
        "complex_req = {\n",
        "    \"request_type\": \"complex analysis\",\n",
        "    \"complexity\": \"\",\n",
        "    \"steps_taken\": [],\n",
        "    \"result\": \"\"\n",
        "}\n",
        "result2 = dynamic_app.invoke(complex_req)\n",
        "print(f\"\\n✅ Steps: {' → '.join(result2['steps_taken'])}\")\n",
        "print(f\"   Result: {result2['result']}\")\n",
        "\n",
        "print(\"\\n💡 Workflow adapts based on input complexity!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Parallel Execution with Map-Reduce\n",
        "\n",
        "Process multiple items simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from typing import List\n",
        "\n",
        "class ParallelState(TypedDict):\n",
        "    products: List[str]\n",
        "    inventory_results: List[dict]\n",
        "    price_results: List[dict]\n",
        "    final_report: str\n",
        "\n",
        "async def check_inventory_parallel(product: str) -> dict:\n",
        "    \"\"\"Check inventory for one product\"\"\"\n",
        "    await asyncio.sleep(0.3)  # Simulate API call\n",
        "    import random\n",
        "    stock = random.randint(0, 20)\n",
        "    return {\"product\": product, \"stock\": stock, \"available\": stock > 0}\n",
        "\n",
        "async def check_price_parallel(product: str) -> dict:\n",
        "    \"\"\"Check price for one product\"\"\"\n",
        "    await asyncio.sleep(0.2)  # Simulate database query\n",
        "    prices = {\"Chocolate Cake\": 45, \"Vanilla Cake\": 40, \"Red Velvet\": 50}\n",
        "    price = prices.get(product, 45)\n",
        "    return {\"product\": product, \"price\": price}\n",
        "\n",
        "def map_products(state: ParallelState) -> ParallelState:\n",
        "    \"\"\"Map: Process each product in parallel\"\"\"\n",
        "    print(f\"\\n📊 MAP: Processing {len(state['products'])} products in parallel...\")\n",
        "    \n",
        "    # Run inventory checks in parallel\n",
        "    import asyncio\n",
        "    inventory_results = asyncio.run(\n",
        "        asyncio.gather(*[check_inventory_parallel(p) for p in state['products']])\n",
        "    )\n",
        "    \n",
        "    # Run price checks in parallel\n",
        "    price_results = asyncio.run(\n",
        "        asyncio.gather(*[check_price_parallel(p) for p in state['products']])\n",
        "    )\n",
        "    \n",
        "    state['inventory_results'] = inventory_results\n",
        "    state['price_results'] = price_results\n",
        "    \n",
        "    print(\"   ✅ All parallel operations complete\")\n",
        "    return state\n",
        "\n",
        "def reduce_results(state: ParallelState) -> ParallelState:\n",
        "    \"\"\"Reduce: Combine all results\"\"\"\n",
        "    print(\"\\n📋 REDUCE: Combining results...\")\n",
        "    \n",
        "    report_lines = [\"Product Availability Report:\", \"=\"*40]\n",
        "    \n",
        "    for inv, price in zip(state['inventory_results'], state['price_results']):\n",
        "        product = inv['product']\n",
        "        stock = inv['stock']\n",
        "        price_val = price['price']\n",
        "        status = \"✅ Available\" if inv['available'] else \"❌ Out of Stock\"\n",
        "        \n",
        "        report_lines.append(\n",
        "            f\"{product}: {status} (Stock: {stock}, Price: ${price_val})\"\n",
        "        )\n",
        "    \n",
        "    state['final_report'] = \"\\n\".join(report_lines)\n",
        "    print(\"   ✅ Report generated\")\n",
        "    return state\n",
        "\n",
        "# Build parallel workflow\n",
        "parallel_workflow = StateGraph(ParallelState)\n",
        "parallel_workflow.add_node(\"map\", map_products)\n",
        "parallel_workflow.add_node(\"reduce\", reduce_results)\n",
        "\n",
        "parallel_workflow.set_entry_point(\"map\")\n",
        "parallel_workflow.add_edge(\"map\", \"reduce\")\n",
        "parallel_workflow.add_edge(\"reduce\", END)\n",
        "\n",
        "parallel_app = parallel_workflow.compile()\n",
        "\n",
        "print(\"✅ Parallel map-reduce workflow created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test parallel processing\n",
        "import time\n",
        "\n",
        "products = [\"Chocolate Cake\", \"Vanilla Cake\", \"Red Velvet\", \"Carrot Cake\", \"Lemon Cake\"]\n",
        "\n",
        "print(\"🧪 Testing parallel map-reduce\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "start = time.time()\n",
        "result = parallel_app.invoke({\n",
        "    \"products\": products,\n",
        "    \"inventory_results\": [],\n",
        "    \"price_results\": [],\n",
        "    \"final_report\": \"\"\n",
        "})\n",
        "elapsed = time.time() - start\n",
        "\n",
        "print(f\"\\n{result['final_report']}\")\n",
        "print(f\"\\n⚡ Total time: {elapsed:.2f}s (parallel execution)\")\n",
        "print(f\"💡 Sequential would take: ~{len(products) * 0.5:.1f}s\")\n",
        "print(f\"   Speed improvement: {(len(products) * 0.5 / elapsed):.1f}x faster!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Error Recovery and Retry\n",
        "\n",
        "Automatically handle failures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RetryState(TypedDict):\n",
        "    task: str\n",
        "    attempts: int\n",
        "    max_attempts: int\n",
        "    success: bool\n",
        "    result: str\n",
        "    errors: List[str]\n",
        "\n",
        "def unreliable_operation(state: RetryState) -> RetryState:\n",
        "    \"\"\"Operation that sometimes fails\"\"\"\n",
        "    import random\n",
        "    \n",
        "    state['attempts'] += 1\n",
        "    print(f\"\\n🔄 Attempt {state['attempts']}/{state['max_attempts']}...\")\n",
        "    \n",
        "    # 60% failure rate\n",
        "    if random.random() < 0.6:\n",
        "        error = f\"Attempt {state['attempts']}: Network timeout\"\n",
        "        state['errors'].append(error)\n",
        "        state['success'] = False\n",
        "        print(f\"   ❌ {error}\")\n",
        "    else:\n",
        "        state['success'] = True\n",
        "        state['result'] = f\"Success on attempt {state['attempts']}\"\n",
        "        print(f\"   ✅ Operation succeeded!\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "def should_retry(state: RetryState) -> Literal[\"retry\", \"success\", \"failed\"]:\n",
        "    \"\"\"Decide whether to retry\"\"\"\n",
        "    if state['success']:\n",
        "        return \"success\"\n",
        "    elif state['attempts'] < state['max_attempts']:\n",
        "        print(\"   🔁 Retrying...\")\n",
        "        return \"retry\"\n",
        "    else:\n",
        "        return \"failed\"\n",
        "\n",
        "def handle_success(state: RetryState) -> RetryState:\n",
        "    print(f\"\\n✅ FINAL SUCCESS: {state['result']}\")\n",
        "    return state\n",
        "\n",
        "def handle_failure(state: RetryState) -> RetryState:\n",
        "    print(f\"\\n❌ FINAL FAILURE after {state['attempts']} attempts\")\n",
        "    print(f\"   Errors: {len(state['errors'])}\")\n",
        "    state['result'] = \"Operation failed - please contact support\"\n",
        "    return state\n",
        "\n",
        "# Build retry workflow\n",
        "retry_workflow = StateGraph(RetryState)\n",
        "\n",
        "retry_workflow.add_node(\"attempt\", unreliable_operation)\n",
        "retry_workflow.add_node(\"success\", handle_success)\n",
        "retry_workflow.add_node(\"failure\", handle_failure)\n",
        "\n",
        "retry_workflow.set_entry_point(\"attempt\")\n",
        "\n",
        "retry_workflow.add_conditional_edges(\n",
        "    \"attempt\",\n",
        "    should_retry,\n",
        "    {\n",
        "        \"retry\": \"attempt\",\n",
        "        \"success\": \"success\",\n",
        "        \"failed\": \"failure\"\n",
        "    }\n",
        ")\n",
        "\n",
        "retry_workflow.add_edge(\"success\", END)\n",
        "retry_workflow.add_edge(\"failure\", END)\n",
        "\n",
        "retry_app = retry_workflow.compile()\n",
        "\n",
        "print(\"✅ Retry workflow with error recovery created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test retry logic\n",
        "print(\"🧪 Testing automatic retry\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "result = retry_app.invoke({\n",
        "    \"task\": \"Process payment\",\n",
        "    \"attempts\": 0,\n",
        "    \"max_attempts\": 5,\n",
        "    \"success\": False,\n",
        "    \"result\": \"\",\n",
        "    \"errors\": []\n",
        "})\n",
        "\n",
        "print(f\"\\n📊 Final State:\")\n",
        "print(f\"   Success: {result['success']}\")\n",
        "print(f\"   Attempts: {result['attempts']}\")\n",
        "print(f\"   Result: {result['result']}\")\n",
        "\n",
        "print(\"\\n💡 Automatic retry increases reliability!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: Advanced Patterns\n",
        "\n",
        "### ✅ Session Achievements:\n",
        "\n",
        "1. **Human-in-the-Loop**: Approval workflows with interruption\n",
        "2. **Persistent State**: SQLite checkpointing for long conversations\n",
        "3. **Dynamic Graphs**: Runtime adaptation based on complexity\n",
        "4. **Parallel Processing**: Map-reduce for simultaneous operations\n",
        "5. **Error Recovery**: Automatic retry with exponential backoff\n",
        "\n",
        "### 🎯 Production Patterns:\n",
        "\n",
        "**Use Human-in-the-Loop when:**\n",
        "- High-value transactions\n",
        "- Critical decisions\n",
        "- Compliance requirements\n",
        "- Quality assurance\n",
        "\n",
        "**Use Parallel Processing when:**\n",
        "- Multiple independent operations\n",
        "- Batch processing\n",
        "- Performance critical\n",
        "- I/O bound tasks\n",
        "\n",
        "**Use Error Recovery when:**\n",
        "- Unreliable external services\n",
        "- Network operations\n",
        "- Critical workflows\n",
        "- User-facing operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
