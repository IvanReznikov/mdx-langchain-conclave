{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLF9k93H_Sn2"
   },
   "source": [
    "# Session 3.3: BakeryAI - RAG Pipeline & Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8w9kR1t_Skd"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Xe5g768967-1eW2GIYnHTMsnyic1muQt?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZX8CGIh_PTF"
   },
   "source": [
    "## üéØ Today's Goal\n",
    "\n",
    "Build **production-ready RAG pipelines** with best practices!\n",
    "\n",
    "### What is a RAG Pipeline?\n",
    "\n",
    "```\n",
    "User Question\n",
    "     ‚Üì\n",
    "[Retrieve] ‚Üê Vector Store\n",
    "     ‚Üì\n",
    "[Rerank/Filter]\n",
    "     ‚Üì\n",
    "[Generate] ‚Üê LLM + Context\n",
    "     ‚Üì\n",
    "Answer with Citations\n",
    "```\n",
    "\n",
    "### Why RAG vs Alternatives?\n",
    "\n",
    "| Approach | Pros | Cons | Use Case |\n",
    "|----------|------|------|----------|\n",
    "| **RAG** | Up-to-date, cites sources, cost-effective | Retrieval quality matters | Knowledge bases, Q&A |\n",
    "| **Fine-tuning** | Specialized behavior | Expensive, static knowledge | Style/format learning |\n",
    "| **Long Context** | No retrieval needed | Expensive, slower | Small knowledge bases |\n",
    "| **Prompt Engineering** | Simple, fast | Limited knowledge | Simple tasks |\n",
    "\n",
    "### RAG Best Practices:\n",
    "\n",
    "1. **Chunk Size**: 500-1500 chars (we use 800)\n",
    "2. **Overlap**: 10-20% (we use 100 chars)\n",
    "3. **Top K**: 3-5 documents\n",
    "4. **Reranking**: Always rerank if possible\n",
    "5. **Citations**: Track sources for every fact\n",
    "6. **Evaluation**: Measure retrieval and generation quality\n",
    "\n",
    "Let's build it! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 16545,
     "status": "ok",
     "timestamp": 1761340327604,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "lbmXywFc_PTL"
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-openai langchain-community\n",
    "!pip install -q faiss-cpu chromadb ragas\n",
    "!pip install -q python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1761340327657,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "qAu9mRZj_78L",
    "outputId": "1daf5a61-142a-49a9-988c-42d996489b31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'mdx-langchain-conclave' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/IvanReznikov/mdx-langchain-conclave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6950,
     "status": "ok",
     "timestamp": 1761340334624,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "e8N-JJ2d_PTM",
    "outputId": "fde27833-0177-4391-a459-8d5696470179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment ready!\n",
      "Embedding model: text-embedding-3-small (1536 dimensions)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Set OpenAI API key from Google Colab's user environment or default\n",
    "def set_openai_api_key(default_key: str = \"YOUR_API_KEY\") -> None:\n",
    "    \"\"\"Set the OpenAI API key from Google Colab's user environment or use a default value.\"\"\"\n",
    "    #if not (userdata.get(\"OPENAI_API_KEY\") or \"OPENAI_API_KEY\" in os.environ):\n",
    "    try:\n",
    "      os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"MDX_OPENAI_API_KEY\")\n",
    "    except:\n",
    "      os.environ[\"OPENAI_API_KEY\"] = default_key\n",
    "\n",
    "set_openai_api_key()\n",
    "#set_openai_api_key(\"sk-...\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "print(\"‚úÖ Environment ready!\")\n",
    "print(f\"Embedding model: text-embedding-3-small (1536 dimensions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SmYSMkv_PTN"
   },
   "source": [
    "## 1. Load Vector Store from Session 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1761340334754,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "LvwMInLe_PTN",
    "outputId": "16dc539e-0f9a-4db2-b7ee-f86d3969d6b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded FAISS vector store from Session 3.2\n",
      "‚úÖ Retriever configured: MMR search, top-k=3\n"
     ]
    }
   ],
   "source": [
    "# Load FAISS vector store\n",
    "try:\n",
    "    vectorstore = FAISS.load_local(\n",
    "        \"/content/mdx-langchain-conclave/rag_artifacts/bakery_faiss_index\",\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(\"‚úÖ Loaded FAISS vector store from Session 3.2\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Creating sample vector store...\")\n",
    "    from langchain_core.documents import Document\n",
    "\n",
    "    sample_docs = [\n",
    "        Document(\n",
    "            page_content=\"Our refund policy: Full refunds within 24 hours of order. After that, store credit is offered.\",\n",
    "            metadata={\"source\": \"Customer_Service_Policy.txt\", \"category\": \"policy\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"Chocolate Truffle Cake: Rich chocolate with Belgian truffle filling. Price $45. Allergens: dairy, eggs, gluten.\",\n",
    "            metadata={\"source\": \"cakes.pdf\", \"category\": \"product\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"Red Velvet Cake: Velvety red sponge with cream cheese frosting. Price $50. Allergens: dairy, eggs, gluten.\",\n",
    "            metadata={\"source\": \"cakes.pdf\", \"category\": \"product\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"Food handlers must wash hands with soap for at least 20 seconds before handling food items.\",\n",
    "            metadata={\"source\": \"SOP_Hygiene_Food_Safety.txt\", \"category\": \"safety\"}\n",
    "        ),\n",
    "        Document(\n",
    "            page_content=\"Response time standard: All customer inquiries must be responded to within 2 hours during business hours.\",\n",
    "            metadata={\"source\": \"Customer_Service_Policy.txt\", \"category\": \"policy\"}\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    vectorstore = FAISS.from_documents(sample_docs, embeddings)\n",
    "    print(\"‚úÖ Created sample vector store\")\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 3, \"fetch_k\": 10}\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Retriever configured: MMR search, top-k=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLIaQMHn_PTN"
   },
   "source": [
    "## 2. Basic RAG Chain (Method 1: Simple)\n",
    "\n",
    "The simplest way to build RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11600,
     "status": "ok",
     "timestamp": 1761340346358,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "93HDeryr_PTO",
    "outputId": "e6b6b78a-a41e-4821-ed85-333b86c7a0a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç SIMPLE RAG CHAIN TEST\n",
      "======================================================================\n",
      "\n",
      "Question: What is the refund policy?\n",
      "\n",
      "Answer: - Eligible for a full refund for product quality issues (stale, spoiled, incorrect), our error in order fulfillment, or delivery failure due to our fault, within 24 hours of purchase with the receipt. \n",
      "- Manager approval is required for refunds over AED 300. \n",
      "- Not eligible for a refund includes change of mind after custom order production begins.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Pull the prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Test it - pass the string directly, not as a dict\n",
    "query = \"What is the refund policy?\"\n",
    "result = qa_chain.invoke(query)  # Changed from invoke({\"query\": query})\n",
    "\n",
    "print(\"üîç SIMPLE RAG CHAIN TEST\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nQuestion: {query}\")\n",
    "print(f\"\\nAnswer: {result}\")  # result is a string, not a dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4s7h-tjO_PTO"
   },
   "source": [
    "## 3. Advanced RAG Chain (Method 2: LCEL)\n",
    "\n",
    "Build custom RAG with LangChain Expression Language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1761340346391,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "Be6wxZgy_PTO",
    "outputId": "cbc878c2-5a31-4de6-d0f1-f63d3fcc4392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Advanced RAG Chain built with LCEL\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Custom RAG prompt\n",
    "rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are BakeryAI's knowledge assistant. Answer questions accurately based on the provided context.\n",
    "\n",
    "Context from our knowledge base:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Instructions:\n",
    "1. Answer based ONLY on the provided context\n",
    "2. If the answer isn't in the context, say \"I don't have that information in my knowledge base\"\n",
    "3. Be specific and cite details from the context\n",
    "4. Keep answers concise but complete\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "# Helper function to format documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(f\"Document {i+1} (from {doc.metadata.get('source', 'unknown')}): {doc.page_content}\"\n",
    "                      for i, doc in enumerate(docs))\n",
    "\n",
    "# Build RAG chain with LCEL\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Advanced RAG Chain built with LCEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38555,
     "status": "ok",
     "timestamp": 1761340384950,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "5stADkYZ_PTP",
    "outputId": "2f57989b-83ce-4dfb-c2cc-5d50933a1faf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING ADVANCED RAG CHAIN\n",
      "======================================================================\n",
      "\n",
      "‚ùì Question: What is the refund policy?\n",
      "üí° Answer: - Eligible for a full refund: if there are product quality issues (stale, spoiled, incorrect), if it was our error in order fulfillment, or if delivery failed due to our fault; eligible within 24 hours of purchase with receipt.\n",
      "\n",
      "- Manager approval: refunds over AED 300 require manager approval.\n",
      "\n",
      "- Not eligible for refund: change of mind after production has begun on a custom order. (Note: the document also mentions allergic reactions, but the text is cut off in the provided context.)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "‚ùì Question: Tell me about chocolate cakes and their allergens\n",
      "üí° Answer: Here are the chocolate-related cakes and their allergens from the provided context:\n",
      "\n",
      "- Red Velvet Cake (R): Has a cocoa base giving a chocolate hint. Allergens: dairy, gluten (wheat), and eggs. (Doc 1: ‚ÄúAllergens: dairy, gluten, eggs.‚Äù and ‚ÄúContains dairy, wheat, and eggs.‚Äù)\n",
      "\n",
      "- Black Forest Cake (R): A chocolate-layered cake. Allergens: dairy, eggs, and coconut. (Doc 3: ‚ÄúContains dairy, eggs, and coconut.‚Äù)\n",
      "\n",
      "- ChocoCaramel Birthday Surprise (G): Rich chocolate cake with caramel and fudge. Allergens: dairy, gluten, and berries. (Doc 2: ‚ÄúContains dairy, gluten, and berries.‚Äù)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "‚ùì Question: What are the hygiene requirements for food handlers?\n",
      "üí° Answer: Here are the hygiene requirements for food handlers, per the provided SOPs:\n",
      "\n",
      "- Personal hygiene\n",
      "  - Handwashing: wash hands thoroughly for a minimum of 20 seconds with antibacterial soap; required before starting work, after breaks, after handling raw materials, and after touching face/hair; use hand sanitizer between washings.\n",
      "\n",
      "- Nail and skin care\n",
      "  - Nails must be trimmed short and clean; no nail polish.\n",
      "\n",
      "- Uniform and protective equipment\n",
      "  - Wear a clean bakery uniform daily (white chef coat, apron, pants).\n",
      "  - Hair must be completely covered with a hairnet or chef hat; beard nets required for all facial hair.\n",
      "  - Shoes must be closed-toe and non-slip.\n",
      "  - Remove all jewelry except a plain wedding band.\n",
      "  - Disposable gloves must be worn when handling ready-to-eat products.\n",
      "\n",
      "- Health and illness\n",
      "  - Report any illness, cuts, or infections to a supervisor immediately.\n",
      "  - Do not work if experiencing fever, vomiting, diarrhea, jaundice, or open wounds.\n",
      "  - Cover all cuts with a waterproof bandage plus glove.\n",
      "  - Medical clearance is required before returning to work after a foodborne illness.\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test advanced chain\n",
    "questions = [\n",
    "    \"What is the refund policy?\",\n",
    "    \"Tell me about chocolate cakes and their allergens\",\n",
    "    \"What are the hygiene requirements for food handlers?\"\n",
    "]\n",
    "\n",
    "print(\"üß™ TESTING ADVANCED RAG CHAIN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\n‚ùì Question: {q}\")\n",
    "    answer = rag_chain.invoke(q)\n",
    "    print(f\"üí° Answer: {answer}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yw4LqK-A_PTP"
   },
   "source": [
    "## 4. RAG with Source Citations\n",
    "\n",
    "Track and display sources for every answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19056,
     "status": "ok",
     "timestamp": 1761340404034,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "f6yfrbeN_PTP",
    "outputId": "1b1fec5b-d3a7-4ef0-d80b-cc1958872ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö RAG WITH CITATIONS\n",
      "======================================================================\n",
      "\n",
      "Question: What are the allergens in our cakes?\n",
      "\n",
      "Answer:\n",
      "- Dairy. [Doc 1][Doc 3]\n",
      "\n",
      "- Gluten. [Doc 1][Doc 3]\n",
      "\n",
      "- Eggs. [Doc 1]\n",
      "\n",
      "- Nuts. [Doc 2]\n",
      "\n",
      "- Milk. [Doc 2]\n",
      "\n",
      "- Wheat. [Doc 2][Doc 3]\n",
      "\n",
      "Sources: [Doc 1], [Doc 2], [Doc 3]\n",
      "\n",
      "üìë Sources:\n",
      "   1. /content/mdx-langchain-conclave/data/cakes.docx\n",
      "   2. /content/mdx-langchain-conclave/data/cakes.pdf\n"
     ]
    }
   ],
   "source": [
    "# Enhanced RAG with citations\n",
    "citation_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the question based on the provided documents. Include inline citations.\n",
    "\n",
    "Documents:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide your answer with citations in the format [Doc X] after each fact.\n",
    "At the end, list all sources used.\n",
    "\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "# Chain with source tracking\n",
    "def rag_with_sources(question):\n",
    "    # Retrieve documents\n",
    "    docs = retriever.invoke(question)\n",
    "\n",
    "    # Format with doc numbers\n",
    "    context = \"\\n\\n\".join(\n",
    "        f\"[Doc {i+1}] (Source: {doc.metadata.get('source', 'unknown')})\\n{doc.page_content}\"\n",
    "        for i, doc in enumerate(docs)\n",
    "    )\n",
    "\n",
    "    # Generate answer\n",
    "    chain = citation_prompt | llm | StrOutputParser()\n",
    "    answer = chain.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"sources\": [doc.metadata.get('source', 'unknown') for doc in docs],\n",
    "        \"documents\": docs\n",
    "    }\n",
    "\n",
    "# Test\n",
    "query = \"What are the allergens in our cakes?\"\n",
    "result = rag_with_sources(query)\n",
    "\n",
    "print(\"üìö RAG WITH CITATIONS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nQuestion: {query}\")\n",
    "print(f\"\\nAnswer:\\n{result['answer']}\")\n",
    "print(f\"\\nüìë Sources:\")\n",
    "for i, source in enumerate(set(result['sources']), 1):\n",
    "    print(f\"   {i}. {source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3xo37Nv_PTP"
   },
   "source": [
    "## 5. Conversational RAG with Memory\n",
    "\n",
    "RAG that remembers conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 186,
     "status": "ok",
     "timestamp": 1761340404225,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "PwFLqN8d_PTP",
    "outputId": "e77bca4a-35f1-471b-a25d-a703d274376e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conversational RAG with memory created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-472545440.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Create memory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"\n",
    ")\n",
    "\n",
    "# Conversational RAG chain\n",
    "conversational_rag = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Conversational RAG with memory created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62099,
     "status": "ok",
     "timestamp": 1761340466328,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "cANDngvN_PTQ",
    "outputId": "8bc4dda0-1a7a-47b1-95e8-d58c198cc137"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ CONVERSATIONAL RAG TEST\n",
      "======================================================================\n",
      "\n",
      "üë§ Customer: What cakes do we offer?\n",
      "üç∞ BakeryAI: Here's the cake lineup described in your material:\n",
      "\n",
      "- Carrot Cake: Hearty, slightly denser-than-sponge; great for brunch or celebrations. Contains nuts, dairy, and gluten.\n",
      "- Opera Cake (R): French classic with almond sponge soaked in coffee syrup, layered with ganache and coffee buttercream, topped with chocolate glaze. Contains dairy, eggs, nuts, and gluten.\n",
      "- Cheesecake: Rich cream cheese base on a buttery graham cracker crust, topped with seasonal fruit compote; no-bake. Contains dairy, eggs, and wheat.\n",
      "- Rainbow Cake (R): Layered vanilla sponge in different colors with buttercream frosting; festive and crowd-pleasing.\n",
      "- Seasonal Mango Coconut Cake: A warm-weather favorite, currently temporarily off the menu. Contains dairy, eggs, and coconut.\n",
      "- Black Forest Cake (R): Chocolate sponge with whipped cream and cherries, kirsch-soaked layers; elegant and balanced. Contains dairy, eggs, and gluten.\n",
      "\n",
      "If you‚Äôd like, I can format this as a quick menu card or tailor it for a specific audience (kids, adults, dietary notes, etc.).\n",
      "\n",
      "üë§ Customer: What are the allergens in them?\n",
      "üç∞ BakeryAI: Here are the allergens given for each cake in your descriptions:\n",
      "\n",
      "- Red Velvet Cake (R): dairy, gluten (wheat), eggs\n",
      "- Carrot Cake (R): nuts, milk, wheat, eggs\n",
      "- Molten Mango Lava Cake (G): Allergens not specified in the provided description\n",
      "- Lemon Drizzle Cake (R): eggs, dairy, gluten\n",
      "- Cheesecake (R): Allergens not explicitly listed in the provided description\n",
      "- Strawberry Shortcake: dairy, eggs, gluten\n",
      "\n",
      "Note: The base allergen categories mentioned at the top are dairy, gluten, and eggs, but some items also list nuts or other specifics. If you want, I can re-check or format this differently.\n",
      "\n",
      "üë§ Customer: What if I want a refund?\n",
      "üç∞ BakeryAI: Here‚Äôs how refunds work and what you should do:\n",
      "\n",
      "WhoQualifies for a refund\n",
      "- Product quality issues (stale, spoiled, incorrect item)\n",
      "- Our error in order fulfillment\n",
      "- Delivery failure due to our fault\n",
      "- The request is made within 24 hours of purchase with the receipt\n",
      "\n",
      "What isn‚Äôt automatically eligible\n",
      "- Change of mind after a custom order has begun production (not eligible for refund)\n",
      "- Some allergy-related situations (policy details may vary; please contact us to review)\n",
      "\n",
      "What you should do\n",
      "- Gather: your order number, receipt, and a clear description of the issue. If it‚Äôs a quality issue, photos help.\n",
      "- Contact us through your preferred channel (email, WhatsApp Business, or social media). Include:\n",
      "  - Order number and purchase date\n",
      "  - Description of the issue\n",
      "  - Your preferred resolution (refund or replacement)\n",
      "- We‚Äôll respond within 24 hours (business days) and guide you through the next steps.\n",
      "\n",
      "What you can expect if eligible\n",
      "- We will offer a full replacement or a full refund (your choice).\n",
      "- For refunds over AED 300, manager approval is required.\n",
      "- In some cases, we may offer compensation (e.g., discount on next purchase) or a complimentary item.\n",
      "- We will follow up within 24 hours of agreeing on a remedy to ensure you‚Äôre satisfied.\n",
      "\n",
      "What if it‚Äôs a custom order\n",
      "- If you‚Äôre unhappy with a custom order, discuss the concerns with us.\n",
      "- We may offer modifications if time permits.\n",
      "- If we cannot resolve it, a full refund may be offered.\n",
      "- You may keep the cake (within reason) in certain situations.\n",
      "- All refunds over AED 300 still require manager approval.\n",
      "\n",
      "If you‚Äôd like, tell me your order number and a brief description of the issue and I can help draft the message you should send to our support team.\n",
      "\n",
      "‚úÖ Memory allows context from previous turns!\n"
     ]
    }
   ],
   "source": [
    "# Test conversation\n",
    "print(\"üí¨ CONVERSATIONAL RAG TEST\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Turn 1\n",
    "q1 = \"What cakes do we offer?\"\n",
    "r1 = conversational_rag.invoke({\"question\": q1})\n",
    "print(f\"\\nüë§ Customer: {q1}\")\n",
    "print(f\"üç∞ BakeryAI: {r1['answer']}\")\n",
    "\n",
    "# Turn 2 (references previous)\n",
    "q2 = \"What are the allergens in them?\"\n",
    "r2 = conversational_rag.invoke({\"question\": q2})\n",
    "print(f\"\\nüë§ Customer: {q2}\")\n",
    "print(f\"üç∞ BakeryAI: {r2['answer']}\")\n",
    "\n",
    "# Turn 3\n",
    "q3 = \"What if I want a refund?\"\n",
    "r3 = conversational_rag.invoke({\"question\": q3})\n",
    "print(f\"\\nüë§ Customer: {q3}\")\n",
    "print(f\"üç∞ BakeryAI: {r3['answer']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Memory allows context from previous turns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADFtPN-N_PTQ"
   },
   "source": [
    "## 6. Alternative to RAG: Long Context Windows\n",
    "\n",
    "Compare RAG vs putting everything in context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25362,
     "status": "ok",
     "timestamp": 1761340491673,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "iFNy0x7F_PTQ",
    "outputId": "6b7baf85-642b-4ad0-ffc5-e3349d8f91cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è  COMPARING: Long Context vs RAG\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ LONG CONTEXT (all docs in prompt):\n",
      "   Answer: Here is the refund policy as listed:\n",
      "\n",
      "Eligible for refund\n",
      "- Change of mind after custom order produc...\n",
      "   Time: 7.47s\n",
      "   Tokens used: ~547 (context)\n",
      "\n",
      "2Ô∏è‚É£ RAG (retrieve then generate):\n",
      "   Answer: - Eligible for full refund:\n",
      "  - Product quality issues (stale, spoiled, incorrect)\n",
      "  - Our error in ...\n",
      "   Time: 16.81s\n",
      "   Tokens used: ~296 (context)\n",
      "\n",
      "üìä Comparison:\n",
      "   Speed: RAG is 0.4x faster\n",
      "   Cost: RAG uses ~1.8x fewer tokens\n",
      "   Scalability: RAG scales to millions of documents, long context limited\n"
     ]
    }
   ],
   "source": [
    "# Get all documents\n",
    "all_docs = vectorstore.similarity_search(\"\", k=100)  # Get everything\n",
    "all_content = \"\\n\\n\".join([doc.page_content for doc in all_docs[:10]])  # Take first 10\n",
    "\n",
    "# Method 1: Long Context (no retrieval)\n",
    "long_context_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Here is our complete knowledge base:\n",
    "\n",
    "{all_knowledge}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer based on the knowledge base above:\n",
    "\"\"\")\n",
    "\n",
    "long_context_chain = long_context_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Method 2: RAG (with retrieval)\n",
    "# (already built above)\n",
    "\n",
    "# Compare\n",
    "import time\n",
    "\n",
    "test_question = \"What is the refund policy?\"\n",
    "\n",
    "print(\"‚öñÔ∏è  COMPARING: Long Context vs RAG\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Long context\n",
    "print(\"\\n1Ô∏è‚É£ LONG CONTEXT (all docs in prompt):\")\n",
    "start = time.time()\n",
    "lc_answer = long_context_chain.invoke({\n",
    "    \"all_knowledge\": all_content,\n",
    "    \"question\": test_question\n",
    "})\n",
    "lc_time = time.time() - start\n",
    "print(f\"   Answer: {lc_answer[:100]}...\")\n",
    "print(f\"   Time: {lc_time:.2f}s\")\n",
    "print(f\"   Tokens used: ~{len(all_content.split())} (context)\")\n",
    "\n",
    "# RAG\n",
    "print(\"\\n2Ô∏è‚É£ RAG (retrieve then generate):\")\n",
    "start = time.time()\n",
    "rag_answer = rag_chain.invoke(test_question)\n",
    "rag_time = time.time() - start\n",
    "retrieved_docs = retriever.invoke(test_question)\n",
    "retrieved_content = \" \".join([doc.page_content for doc in retrieved_docs])\n",
    "print(f\"   Answer: {rag_answer[:100]}...\")\n",
    "print(f\"   Time: {rag_time:.2f}s\")\n",
    "print(f\"   Tokens used: ~{len(retrieved_content.split())} (context)\")\n",
    "\n",
    "print(\"\\nüìä Comparison:\")\n",
    "print(f\"   Speed: RAG is {lc_time/rag_time:.1f}x faster\")\n",
    "print(f\"   Cost: RAG uses ~{len(all_content.split())/len(retrieved_content.split()):.1f}x fewer tokens\")\n",
    "print(f\"   Scalability: RAG scales to millions of documents, long context limited\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPjD6jKp_PTQ"
   },
   "source": [
    "## 7. Advanced RAG: Query Decomposition\n",
    "\n",
    "Break complex questions into sub-questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69810,
     "status": "ok",
     "timestamp": 1761340561499,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "vNxYw3X9_PTR",
    "outputId": "0eadf2b2-c370-429a-cb96-1bb7e0a58e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ QUERY DECOMPOSITION RAG\n",
      "======================================================================\n",
      "\n",
      "Complex Question: What cakes do we offer and what are their allergens, and if someone has allergies what is our policy?\n",
      "\n",
      "üîç Decomposed into sub-questions:\n",
      "What cakes do we offer?\n",
      "What allergens are present in each cake?\n",
      "What is our policy for customers with allergies?\n",
      "\n",
      "\n",
      "üìù Final Synthesized Answer:\n",
      "Here‚Äôs a consolidated answer addressing both what we offer and our allergy policy.\n",
      "\n",
      "Cakes we offer (with available allergen details)\n",
      "- Carrot Cake ‚Äî described as a brunch-style cake; allergen information is not available in our current knowledge base. Please check with staff for exact allergens.\n",
      "- Opera Cake (R) ‚Äî French classic with almond sponge, coffee components, and ganache; contains dairy, eggs, nuts, and gluten.\n",
      "- Cheesecake ‚Äî rich cream cheese base on a buttery crust with seasonal fruit topping; contains dairy, eggs, and wheat (gluten).\n",
      "- Rainbow Cake (R) ‚Äî vanilla-flavored layered cake with buttercream; contains eggs, gluten, and dairy.\n",
      "- Black Forest Cake (R) ‚Äî chocolate sponge with whipped cream and cherries; allergen details not provided in the available sources. Please verify with staff.\n",
      "\n",
      "Allergens by cake (as available from our sources)\n",
      "- Carrot Cake: allergen information not found in our knowledge base.\n",
      "- Opera Cake (R): dairy, eggs, nuts, gluten.\n",
      "- Cheesecake: dairy, eggs, wheat (gluten).\n",
      "- Rainbow Cake (R): eggs, gluten, dairy.\n",
      "- Black Forest Cake (R): allergen information not provided in the available sources.\n",
      "\n",
      "Note: If you need precise allergen details for any item (especially Carrot Cake or Black Forest Cake), please ask a staff member or request the latest allergen card/matrix for confirmation.\n",
      "\n",
      "Policy for customers with allergies\n",
      "- Refunds for allergies: If an allergic reaction occurs and the allergen was disclosed, the customer is eligible for a refund.\n",
      "- Allergy handling and prevention in-store:\n",
      "  - Use separate cutting boards for different allergens and follow a color-coded system:\n",
      "    - Red = meat\n",
      "    - Blue = fish\n",
      "    - Green = vegetables\n",
      "    - Yellow = baked goods\n",
      "  - Never place finished products near raw ingredients.\n",
      "  - Clean and sanitize all surfaces between tasks.\n",
      "  - Store raw materials below finished products in refrigerators.\n",
      "\n",
      "If you‚Äôd like, I can help you compile a one-page allergen quick reference (cakes with their allergens) or connect you with staff to verify any item‚Äôs allergen details.\n"
     ]
    }
   ],
   "source": [
    "decomposition_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Break down this complex question into 2-3 simpler sub-questions.\n",
    "\n",
    "Complex Question: {question}\n",
    "\n",
    "List the sub-questions (one per line):\n",
    "\"\"\")\n",
    "\n",
    "def multi_query_rag(complex_question):\n",
    "    \"\"\"Answer complex questions by decomposing into sub-queries\"\"\"\n",
    "\n",
    "    # Decompose question\n",
    "    decompose_chain = decomposition_prompt | llm | StrOutputParser()\n",
    "    sub_questions = decompose_chain.invoke({\"question\": complex_question})\n",
    "\n",
    "    print(f\"üîç Decomposed into sub-questions:\")\n",
    "    print(sub_questions)\n",
    "    print()\n",
    "\n",
    "    # Answer each sub-question\n",
    "    sub_answers = []\n",
    "    for sq in sub_questions.split('\\n'):\n",
    "        if sq.strip():\n",
    "            answer = rag_chain.invoke(sq.strip())\n",
    "            sub_answers.append(f\"Q: {sq}\\nA: {answer}\")\n",
    "\n",
    "    # Synthesize final answer\n",
    "    synthesis_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Original question: {question}\n",
    "\n",
    "    Sub-answers:\n",
    "    {sub_answers}\n",
    "\n",
    "    Synthesize a comprehensive answer to the original question:\n",
    "    \"\"\")\n",
    "\n",
    "    final_chain = synthesis_prompt | llm | StrOutputParser()\n",
    "    final_answer = final_chain.invoke({\n",
    "        \"question\": complex_question,\n",
    "        \"sub_answers\": \"\\n\\n\".join(sub_answers)\n",
    "    })\n",
    "\n",
    "    return final_answer\n",
    "\n",
    "# Test\n",
    "complex_q = \"What cakes do we offer and what are their allergens, and if someone has allergies what is our policy?\"\n",
    "\n",
    "print(\"üéØ QUERY DECOMPOSITION RAG\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nComplex Question: {complex_q}\\n\")\n",
    "\n",
    "answer = multi_query_rag(complex_q)\n",
    "print(\"\\nüìù Final Synthesized Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW149HkM_PTR"
   },
   "source": [
    "## 8. Advanced RAG: HyDE (Hypothetical Document Embeddings)\n",
    "\n",
    "Generate hypothetical answers, embed them, then retrieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20939,
     "status": "ok",
     "timestamp": 1761340582434,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "xGkpKlc9_PTR",
    "outputId": "fb96b87e-f9fa-43be-d26d-c6d0b7c94157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ HyDE RAG TEST\n",
      "======================================================================\n",
      "\n",
      "Question: What makes our cakes special?\n",
      "\n",
      "üí≠ Hypothetical answer generated:\n",
      "   Each cake is handmade in small batches from real, locally sourced ingredients, delivering a moist crumb and rich, layered flavors. We marry classic baking techniques with playful, custom decorations to reflect your celebration and taste. Best of all, we tailor every cake to your preferences and dietary needs, making it truly yours.\n",
      "\n",
      "üìö Retrieved docs using hypothetical answer:\n",
      "   1. . Its hearty, satisfying, and just the right level of indulg...\n",
      "   2. From New York-style to Japanese jiggly versions, cheesecake ...\n",
      "   3. . Finished with spun sugar and caramel crowns, it truly look...\n",
      "\n",
      "‚ú® Final Answer:\n",
      "What makes our cakes special:\n",
      "\n",
      "- Versatility for every occasion: perfect for brunch, birthdays, family reunions, and office celebrations.\n",
      "- Rich, multi-layered flavors with distinct textures: from the dense, wholesome carrot cake and the refined Opera Cake to the no-bake cheesecake and the molten Mango Lava Cake.\n",
      "- Premium ingredients and classic techniques: almond sponge, ganache, coffee syrup, buttercreams, mango coulis, coconut-influenced sponges, and buttery crusts.\n",
      "- Eye-catching presentation: bold colors (Rainbow Cake), elegant finishes (spun sugar, caramel crowns), and visually appealing layers that wow guests.\n",
      "- Thoughtful safety and quality: some items crafted in an HACCP-certified kitchen; clear allergen notes (nuts, dairy, gluten, eggs) so guests can choose confidently.\n",
      "- Not overly sweet, yet indulgent: many flavors are refined and balanced, offering pure satisfaction in every bite.\n",
      "\n",
      "In short: a curated, experience-driven lineup that blends flavor, texture, and stunning presentation for any celebration.\n",
      "\n",
      "üí° HyDE often retrieves better docs by matching answer patterns!\n"
     ]
    }
   ],
   "source": [
    "hyde_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Generate a hypothetical ideal answer to this question (even if you don't know the real answer):\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Hypothetical answer (2-3 sentences):\n",
    "\"\"\")\n",
    "\n",
    "def hyde_rag(question):\n",
    "    \"\"\"RAG with hypothetical document embeddings\"\"\"\n",
    "\n",
    "    # Generate hypothetical answer\n",
    "    hyde_chain = hyde_prompt | llm | StrOutputParser()\n",
    "    hypothetical_answer = hyde_chain.invoke({\"question\": question})\n",
    "\n",
    "    print(f\"üí≠ Hypothetical answer generated:\")\n",
    "    print(f\"   {hypothetical_answer}\\n\")\n",
    "\n",
    "    # Retrieve using hypothetical answer (not original question)\n",
    "    docs = vectorstore.similarity_search(hypothetical_answer, k=3)\n",
    "\n",
    "    print(f\"üìö Retrieved docs using hypothetical answer:\")\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        print(f\"   {i}. {doc.page_content[:60]}...\")\n",
    "\n",
    "    # Generate final answer\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    final_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Context: {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\")\n",
    "\n",
    "    final_chain = final_prompt | llm | StrOutputParser()\n",
    "    return final_chain.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "# Test\n",
    "print(\"üîÆ HyDE RAG TEST\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "test_q = \"What makes our cakes special?\"\n",
    "print(f\"Question: {test_q}\\n\")\n",
    "\n",
    "hyde_answer = hyde_rag(test_q)\n",
    "print(f\"\\n‚ú® Final Answer:\\n{hyde_answer}\")\n",
    "\n",
    "print(\"\\nüí° HyDE often retrieves better docs by matching answer patterns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kGr7kPu_PTR"
   },
   "source": [
    "## 9. RAG Evaluation\n",
    "\n",
    "Measure RAG quality with metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29160,
     "status": "ok",
     "timestamp": 1761340611597,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "j7vaoF-O_PTR",
    "outputId": "5f478cc4-2ec1-4c40-c4fd-4d87742e34d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä RAG EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Test 1:\n",
      "Question: What is the refund policy?\n",
      "Answer: - Eligible for a full refund:\n",
      "  - Product quality issues (stale, spoiled, incorr...\n",
      "Score: 66.7% (2/3 keywords)\n",
      "\n",
      "Test 2:\n",
      "Question: What allergens are in chocolate cake?\n",
      "Answer: Dairy, gluten, and soy. (Chocolate Truffle Cake contains dairy, gluten, and soy....\n",
      "Score: 66.7% (2/3 keywords)\n",
      "\n",
      "Test 3:\n",
      "Question: What are hygiene requirements?\n",
      "Answer: Here are the hygiene requirements from the SOPs:\n",
      "\n",
      "- Personal hygiene\n",
      "  - Handwas...\n",
      "Score: 100.0% (3/3 keywords)\n",
      "\n",
      "üìà Overall Score: 77.8%\n"
     ]
    }
   ],
   "source": [
    "# Simple RAG evaluation\n",
    "test_qa_pairs = [\n",
    "    {\n",
    "        \"question\": \"What is the refund policy?\",\n",
    "        \"expected_keywords\": [\"24 hours\", \"refund\", \"store credit\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What allergens are in chocolate cake?\",\n",
    "        \"expected_keywords\": [\"dairy\", \"eggs\", \"gluten\"]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are hygiene requirements?\",\n",
    "        \"expected_keywords\": [\"wash\", \"hands\", \"20 seconds\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "def evaluate_rag(qa_pairs):\n",
    "    \"\"\"Simple keyword-based evaluation\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for qa in qa_pairs:\n",
    "        answer = rag_chain.invoke(qa[\"question\"])\n",
    "        answer_lower = answer.lower()\n",
    "\n",
    "        # Check if expected keywords appear\n",
    "        keywords_found = sum(1 for kw in qa[\"expected_keywords\"]\n",
    "                            if kw.lower() in answer_lower)\n",
    "        score = keywords_found / len(qa[\"expected_keywords\"])\n",
    "\n",
    "        results.append({\n",
    "            \"question\": qa[\"question\"],\n",
    "            \"answer\": answer,\n",
    "            \"score\": score,\n",
    "            \"keywords_found\": keywords_found,\n",
    "            \"keywords_total\": len(qa[\"expected_keywords\"])\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "print(\"üìä RAG EVALUATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "eval_results = evaluate_rag(test_qa_pairs)\n",
    "\n",
    "for i, result in enumerate(eval_results, 1):\n",
    "    print(f\"\\nTest {i}:\")\n",
    "    print(f\"Question: {result['question']}\")\n",
    "    print(f\"Answer: {result['answer'][:80]}...\")\n",
    "    print(f\"Score: {result['score']:.1%} ({result['keywords_found']}/{result['keywords_total']} keywords)\")\n",
    "\n",
    "avg_score = sum(r['score'] for r in eval_results) / len(eval_results)\n",
    "print(f\"\\nüìà Overall Score: {avg_score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ux9XSK4q_PTR"
   },
   "source": [
    "## üéØ Exercise 5: Implement Contextual Compression\n",
    "\n",
    "**Task**: Filter retrieved documents to keep only relevant parts:\n",
    "1. Retrieve more documents initially (k=10)\n",
    "2. Use LLM to extract only relevant sentences\n",
    "3. Pass compressed context to generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1761340611627,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "CVzNFjo4_PTR"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# TODO: Build compression retriever\n",
    "# compressor = LLMChainExtractor.from_llm(llm)\n",
    "# compression_retriever = ContextualCompressionRetriever(\n",
    "#     base_compressor=compressor,\n",
    "#     base_retriever=retriever\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfQdQ3lR_PTR"
   },
   "source": [
    "## üéØ Exercise 6: Build RAG Evaluation Framework\n",
    "\n",
    "**Task**: Create comprehensive evaluation:\n",
    "1. Retrieval quality (precision, recall)\n",
    "2. Answer quality (relevance, faithfulness)\n",
    "3. Latency and cost metrics\n",
    "4. Generate evaluation report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1761340611638,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "wWGov-sS_PTS"
   },
   "outputs": [],
   "source": [
    "class RAGEvaluator:\n",
    "    def __init__(self, rag_chain, retriever, test_set):\n",
    "        self.rag_chain = rag_chain\n",
    "        self.retriever = retriever\n",
    "        self.test_set = test_set\n",
    "\n",
    "    def evaluate_retrieval(self):\n",
    "        \"\"\"Measure retrieval quality\"\"\"\n",
    "        # TODO: Calculate precision@k, recall@k\n",
    "        pass\n",
    "\n",
    "    def evaluate_generation(self):\n",
    "        \"\"\"Measure answer quality\"\"\"\n",
    "        # TODO: Use LLM-as-judge or RAGAS metrics\n",
    "        pass\n",
    "\n",
    "    def evaluate_performance(self):\n",
    "        \"\"\"Measure latency and cost\"\"\"\n",
    "        # TODO: Track time and token usage\n",
    "        pass\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"Comprehensive evaluation report\"\"\"\n",
    "        # TODO: Combine all metrics\n",
    "        pass\n",
    "\n",
    "# Test your evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfRnZxAE_PTS"
   },
   "source": [
    "## Summary: What We Built\n",
    "\n",
    "### ‚úÖ Session 3.3 Achievements:\n",
    "\n",
    "1. **Basic RAG**: Simple question-answering\n",
    "2. **Advanced RAG**: Custom prompts with LCEL\n",
    "3. **Citations**: Source tracking and attribution\n",
    "4. **Conversational RAG**: Memory-enabled Q&A\n",
    "5. **Query Decomposition**: Complex question handling\n",
    "6. **HyDE**: Hypothetical document embeddings\n",
    "7. **Evaluation**: RAG quality metrics\n",
    "8. **Alternatives**: Compared with fine-tuning and long context\n",
    "\n",
    "### üé® BakeryAI RAG Capabilities:\n",
    "\n",
    "‚ú® **Accurate Answers**: Based on real knowledge base  \n",
    "‚ú® **Source Citations**: Every fact is traceable  \n",
    "‚ú® **Conversational**: Remembers context  \n",
    "‚ú® **Complex Queries**: Handles multi-part questions  \n",
    "‚ú® **Cost-Effective**: Only retrieves what's needed  \n",
    "\n",
    "### üìä RAG Best Practices Summary:\n",
    "\n",
    "**Chunk Size**: 500-1500 chars (we use 800)  \n",
    "**Overlap**: 10-20% (we use 100 chars)  \n",
    "**Top K**: 3-5 documents  \n",
    "**Search Type**: MMR for diversity  \n",
    "**Prompt**: Be specific about using only context  \n",
    "**Evaluation**: Always measure and iterate  \n",
    "\n",
    "### üöÄ Next: Notebook 3.4\n",
    "\n",
    "We'll integrate RAG with **agents from Session 2**:\n",
    "- Agents that use RAG tools\n",
    "- Multi-step reasoning with knowledge retrieval\n",
    "- Query routing to appropriate knowledge bases\n",
    "- Complete BakeryAI with agents + RAG!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
