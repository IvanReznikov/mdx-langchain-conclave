{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbLaNjwc-zWz"
   },
   "source": [
    "# Session 1.4: Memory and Conversation Management\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0t_bbVo8AoS6"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1TCfyUKwq_cjW-I1EAgDDK74-A6-pIAQB?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvo2NTaBAoVr"
   },
   "source": [
    "\n",
    "## Overview\n",
    "\n",
    "Memory allows LLMs to maintain context across multiple interactions. In this notebook, you'll learn:\n",
    "\n",
    "- **What is memory** in LLM applications\n",
    "- **Types of memory** in LangChain\n",
    "- **Conversation buffer memory**\n",
    "- **Conversation summary memory**\n",
    "- **Window-based memory**\n",
    "- **Memory management strategies**\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "✅ Understand memory concepts  \n",
    "✅ Implement different memory types  \n",
    "✅ Build stateful conversations  \n",
    "✅ Manage conversation history  \n",
    "✅ Optimize memory usage  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20800,
     "status": "ok",
     "timestamp": 1761238818436,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "R-uzjnXw-zW2",
    "outputId": "469b8ad6-7a63-48e6-8b56-ec6701b22909"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m137.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain langchain-openai langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 25091,
     "status": "ok",
     "timestamp": 1761238843537,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "OfTt4mvv-zW3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "# Set OpenAI API key from Google Colab's user environment or default\n",
    "def set_openai_api_key(default_key: str = \"YOUR_API_KEY\") -> None:\n",
    "    \"\"\"Set the OpenAI API key from Google Colab's user environment or use a default value.\"\"\"\n",
    "    #if not (userdata.get(\"OPENAI_API_KEY\") or \"OPENAI_API_KEY\" in os.environ):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"MDX_OPENAI_API_KEY\") or default_key\n",
    "\n",
    "\n",
    "set_openai_api_key()\n",
    "#set_openai_api_key(\"sk-...\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-njVZlx-zW3"
   },
   "source": [
    "## 1. Why Memory Matters\n",
    "\n",
    "LLMs are **stateless** - they don't remember previous interactions by default.\n",
    "\n",
    "### Without Memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11506,
     "status": "ok",
     "timestamp": 1761238855041,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "fGt9mu1D-zW3",
    "outputId": "6ebaa6b1-23ab-4952-a76d-6f336a8a806c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: My name is Alice\n",
      "AI: Nice to meet you, Alice! How can I help you today? I can answer questions, help plan something, draft a message, explain a concept, or just chat. Would you like me to remember your name for this conversation?\n",
      "\n",
      "User: What's my name?\n",
      "AI: I don’t know your name. I don’t have access to personal data unless you share it. If you’d like, tell me your name or a preferred nickname and I’ll use it. I can also just call you “friend,” “you,” or anything you choose. What would you like me to call you?\n",
      "\n",
      "❌ The model doesn't remember!\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating stateless behavior\n",
    "response1 = llm.invoke(\"My name is Alice\")\n",
    "print(\"User: My name is Alice\")\n",
    "print(f\"AI: {response1.content}\\n\")\n",
    "\n",
    "response2 = llm.invoke(\"What's my name?\")\n",
    "print(\"User: What's my name?\")\n",
    "print(f\"AI: {response2.content}\")\n",
    "print(\"\\n❌ The model doesn't remember!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fvaatsH-zW4"
   },
   "source": [
    "## 2. Message History Basics\n",
    "\n",
    "Manually manage conversation history using message lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7666,
     "status": "ok",
     "timestamp": 1761238862714,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "PqH53Hmk-zW4",
    "outputId": "5b356216-a4c2-4418-abf0-01db66dece77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: My name is Alice\n",
      "AI: Hi Alice! Nice to meet you. How can I help today? If you’d like, I can remember your name for this chat and tailor things accordingly. What would you like to work on or discuss?\n",
      "\n",
      "User: What's my name?\n",
      "AI: Your name is Alice. I can use it to personalize our chat. If you’d like me to stop using it after this session or switch to a nickname, just say the word.\n",
      "\n",
      "✅ Now it remembers!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# Initialize conversation history\n",
    "conversation_history = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\")\n",
    "]\n",
    "\n",
    "# First exchange\n",
    "user_msg_1 = \"My name is Alice\"\n",
    "conversation_history.append(HumanMessage(content=user_msg_1))\n",
    "\n",
    "response1 = llm.invoke(conversation_history)\n",
    "conversation_history.append(AIMessage(content=response1.content))\n",
    "\n",
    "print(f\"User: {user_msg_1}\")\n",
    "print(f\"AI: {response1.content}\\n\")\n",
    "\n",
    "# Second exchange\n",
    "user_msg_2 = \"What's my name?\"\n",
    "conversation_history.append(HumanMessage(content=user_msg_2))\n",
    "\n",
    "response2 = llm.invoke(conversation_history)\n",
    "conversation_history.append(AIMessage(content=response2.content))\n",
    "\n",
    "print(f\"User: {user_msg_2}\")\n",
    "print(f\"AI: {response2.content}\")\n",
    "print(\"\\n✅ Now it remembers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9J8F3jv1-zW4"
   },
   "source": [
    "## 3. ConversationBufferMemory\n",
    "\n",
    "Stores the complete conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20221,
     "status": "ok",
     "timestamp": 1761238882942,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "x3V-o3pU-zW5",
    "outputId": "a9a17f55-fbd7-4a9e-98a7-d8e0d0e979ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1892381350.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "/tmp/ipython-input-1892381350.py:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi! I'm Bob and I love Python programming.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "AI: Hi Bob! Nice to meet you. I love Python too—great choice for a language.\n",
      "\n",
      "What would you like to dive into today? Here are a few options, or tell me your own idea:\n",
      "- Quick refresher on a Python topic (lists, dicts, comprehensions, decorators, etc.)\n",
      "- Build a small project together (CLI tool, web scraper, data analysis starter)\n",
      "- Review and debug some code you’ve written\n",
      "- Best practices (virtual environments, packaging, testing, debugging tips)\n",
      "\n",
      "If you want a fast starter, we can whip up a tiny example right now. For instance:\n",
      "- A simple CLI that greets you and prints the current time\n",
      "- A function to count vowels in a string\n",
      "- A small decorator that logs when a function runs\n",
      "\n",
      "What would you like to start with, or tell me about a project you’re working on?\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi! I'm Bob and I love Python programming.\n",
      "AI: Hi Bob! Nice to meet you. I love Python too—great choice for a language.\n",
      "\n",
      "What would you like to dive into today? Here are a few options, or tell me your own idea:\n",
      "- Quick refresher on a Python topic (lists, dicts, comprehensions, decorators, etc.)\n",
      "- Build a small project together (CLI tool, web scraper, data analysis starter)\n",
      "- Review and debug some code you’ve written\n",
      "- Best practices (virtual environments, packaging, testing, debugging tips)\n",
      "\n",
      "If you want a fast starter, we can whip up a tiny example right now. For instance:\n",
      "- A simple CLI that greets you and prints the current time\n",
      "- A function to count vowels in a string\n",
      "- A small decorator that logs when a function runs\n",
      "\n",
      "What would you like to start with, or tell me about a project you’re working on?\n",
      "Human: What's my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "AI: You're Bob—the name you introduced earlier. Nice to meet you again!\n",
      "\n",
      "What would you like to dive into today?\n",
      "- Quick Python refresher (lists, dicts, comprehensions, decorators, etc.)\n",
      "- Build a small project (CLI tool, web scraper, data analysis starter)\n",
      "- Review/debug some code\n",
      "- Best practices (virtual environments, packaging, testing)\n",
      "\n",
      "If you want a fast starter, we can try:\n",
      "- A simple CLI that greets you and prints the current time\n",
      "- A function to count vowels in a string\n",
      "- A small decorator that logs when a function runs\n",
      "\n",
      "What sounds good?\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi! I'm Bob and I love Python programming.\n",
      "AI: Hi Bob! Nice to meet you. I love Python too—great choice for a language.\n",
      "\n",
      "What would you like to dive into today? Here are a few options, or tell me your own idea:\n",
      "- Quick refresher on a Python topic (lists, dicts, comprehensions, decorators, etc.)\n",
      "- Build a small project together (CLI tool, web scraper, data analysis starter)\n",
      "- Review and debug some code you’ve written\n",
      "- Best practices (virtual environments, packaging, testing, debugging tips)\n",
      "\n",
      "If you want a fast starter, we can whip up a tiny example right now. For instance:\n",
      "- A simple CLI that greets you and prints the current time\n",
      "- A function to count vowels in a string\n",
      "- A small decorator that logs when a function runs\n",
      "\n",
      "What would you like to start with, or tell me about a project you’re working on?\n",
      "Human: What's my name?\n",
      "AI: You're Bob—the name you introduced earlier. Nice to meet you again!\n",
      "\n",
      "What would you like to dive into today?\n",
      "- Quick Python refresher (lists, dicts, comprehensions, decorators, etc.)\n",
      "- Build a small project (CLI tool, web scraper, data analysis starter)\n",
      "- Review/debug some code\n",
      "- Best practices (virtual environments, packaging, testing)\n",
      "\n",
      "If you want a fast starter, we can try:\n",
      "- A simple CLI that greets you and prints the current time\n",
      "- A function to count vowels in a string\n",
      "- A small decorator that logs when a function runs\n",
      "\n",
      "What sounds good?\n",
      "Human: What programming language do I like?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "AI: You love Python. From our chat, you said you love Python programming.\n",
      "\n",
      "What would you like to do next?\n",
      "- Quick Python refresher (lists, dicts, comprehensions, decorators, etc.)\n",
      "- Build a small project (CLI tool, web scraper, data analysis starter)\n",
      "- Review/debug some code\n",
      "- Best practices (virtual environments, packaging, testing)\n",
      "\n",
      "If you want a fast starter, we can try:\n",
      "- A simple CLI that greets you and prints the current time\n",
      "- A function to count vowels in a string\n",
      "- A small decorator that logs when a function runs\n",
      "\n",
      "Which would you like to start with, or tell me about a project you’re working on?\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# Initialize memory\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Create conversation chain\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True  # Shows the prompt being sent\n",
    ")\n",
    "\n",
    "# Have a conversation\n",
    "print(\"=\" * 50)\n",
    "response1 = conversation.predict(input=\"Hi! I'm Bob and I love Python programming.\")\n",
    "print(f\"\\nAI: {response1}\\n\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "response2 = conversation.predict(input=\"What's my name?\")\n",
    "print(f\"\\nAI: {response2}\\n\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "response3 = conversation.predict(input=\"What programming language do I like?\")\n",
    "print(f\"\\nAI: {response3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1761238882984,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "Tx7Gb5CE-zW5",
    "outputId": "42f4f6eb-acf5-4788-c217-b82cac4e037e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Variables:\n",
      "{'history': \"Human: Hi! I'm Bob and I love Python programming.\\nAI: Hi Bob! Nice to meet you. I love Python too—great choice for a language.\\n\\nWhat would you like to dive into today? Here are a few options, or tell me your own idea:\\n- Quick refresher on a Python topic (lists, dicts, comprehensions, decorators, etc.)\\n- Build a small project together (CLI tool, web scraper, data analysis starter)\\n- Review and debug some code you’ve written\\n- Best practices (virtual environments, packaging, testing, debugging tips)\\n\\nIf you want a fast starter, we can whip up a tiny example right now. For instance:\\n- A simple CLI that greets you and prints the current time\\n- A function to count vowels in a string\\n- A small decorator that logs when a function runs\\n\\nWhat would you like to start with, or tell me about a project you’re working on?\\nHuman: What's my name?\\nAI: You're Bob—the name you introduced earlier. Nice to meet you again!\\n\\nWhat would you like to dive into today?\\n- Quick Python refresher (lists, dicts, comprehensions, decorators, etc.)\\n- Build a small project (CLI tool, web scraper, data analysis starter)\\n- Review/debug some code\\n- Best practices (virtual environments, packaging, testing)\\n\\nIf you want a fast starter, we can try:\\n- A simple CLI that greets you and prints the current time\\n- A function to count vowels in a string\\n- A small decorator that logs when a function runs\\n\\nWhat sounds good?\\nHuman: What programming language do I like?\\nAI: You love Python. From our chat, you said you love Python programming.\\n\\nWhat would you like to do next?\\n- Quick Python refresher (lists, dicts, comprehensions, decorators, etc.)\\n- Build a small project (CLI tool, web scraper, data analysis starter)\\n- Review/debug some code\\n- Best practices (virtual environments, packaging, testing)\\n\\nIf you want a fast starter, we can try:\\n- A simple CLI that greets you and prints the current time\\n- A function to count vowels in a string\\n- A small decorator that logs when a function runs\\n\\nWhich would you like to start with, or tell me about a project you’re working on?\"}\n"
     ]
    }
   ],
   "source": [
    "# Inspect memory contents\n",
    "print(\"Memory Variables:\")\n",
    "print(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vv6YFG0k-zW5"
   },
   "source": [
    "## 4. ConversationBufferWindowMemory\n",
    "\n",
    "Keeps only the last K interactions to manage token limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92636,
     "status": "ok",
     "timestamp": 1761238975626,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "4IEh-SdH-zW5",
    "outputId": "05c6c26d-7f8a-4413-8f2b-4054c12325cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-923573390.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  window_memory = ConversationBufferWindowMemory(k=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. User: My favorite color is blue\n",
      "   AI: Nice—blue is a fantastic favorite. It’s often tied to calm, trust, and the vast sky and ocean. Here are a few vibe ideas and shade suggestions:\n",
      "\n",
      "- Airy/light blues: powder blue, sky blue, alice blue — great for bedrooms, summer outfits, or a fresh feel.\n",
      "- Classic blues: royal blue, dodger blue, cornflower blue — bold but friendly; nice for jeans, accents, or logos.\n",
      "- Deep blues: navy, midnight blue, Prussian blue — sophisticated and versatile; ideal for formalwear or elegant decor.\n",
      "\n",
      "Pairing tips:\n",
      "- White + blue for a crisp, nautical vibe.\n",
      "- Gray + blue for a modern, subdued look.\n",
      "- Orange or coral accents for a lively pop.\n",
      "- Gold accents for a touch of elegance.\n",
      "\n",
      "Want me to tailor a palette for a specific use (clothes, a room, a website)? I can also give hex codes if you’d like.\n",
      "\n",
      "2. User: I work as a data scientist\n",
      "   AI: Nice—data scientist. I can tailor color palettes for your specific use cases (visualizations, dashboards, slides, or even code syntax highlighting). Want blue-dominant palettes, colorblind-safe options, or both? If you’d like, I can also give exact hex codes.\n",
      "\n",
      "Here are two ready-to-use palettes you can try right away. They’re designed to work well in charts and dashboards and avoid common accessibility pitfalls.\n",
      "\n",
      "Palette A: Calm blues for charts/dashboards (blue-dominant with a bright accent)\n",
      "- Light background: #f7fbff\n",
      "- Panel/plot area: #ffffff\n",
      "- Primary blue: #2b6cb0\n",
      "- Secondary blue: #4a7bd4\n",
      "- Navy/deep blue: #0b3d8f\n",
      "- Accent (for highlighting): #ff8c00\n",
      "\n",
      "How to use:\n",
      "- Map your quantitative series to the blues gradient (low to high).\n",
      "- Use the orange accent to flag anomalies, key thresholds, or a single highlight series.\n",
      "- Keep text and grid contrast high against the light background.\n",
      "\n",
      "Palette B: Colorblind-friendly blue-orange diverging (good for centered data)\n",
      "- Low values: #1f78b4 (blue)\n",
      "- Mid-low values: #6baed6 (light blue)\n",
      "- Center: #ffffff (neutral)\n",
      "- Mid-high values: #f4a300 (orange)\n",
      "- High values: #e55a00 (orange-red)\n",
      "\n",
      "How to use:\n",
      "- Ideal for heatmaps, choropleths, or any diverging data around a meaningful midpoint.\n",
      "- The center white keeps emphasis on deviations from the center.\n",
      "\n",
      "Helpful tips for data science visuals:\n",
      "- Prefer perceptually uniform palettes (viridis, cividis, or blues) for quantitative data. If you want blue emphasis, use Blues-type sequential palettes or a blue gradient as in Palette A.\n",
      "- For categorical data, avoid relying on red-green alone. Use distinct hues plus markers or patterns.\n",
      "- Ensure accessibility: aim for a contrast ratio of at least 4.5:1 for text over backgrounds; verify colorblind safe combinations (blue/orange typically reads well for many color vision deficiencies).\n",
      "- Consistency matters: pick 1–2 base hues and 1 accent color across all plots in a project to keep visuals cohesive.\n",
      "- If you’re using Python, you can apply these directly in seaborn/matplotlib, e.g.:\n",
      "  - plt.set_prop_cycle(color=[\"#2b6cb0\", \"#4a7bd4\", \"#0b3d8f\", \"#ff8c00\"])\n",
      "  - sns.set_palette([\"#2b6cb0\", \"#4a7bd4\", \"#0b3d8f\", \"#ff8c00\"])\n",
      "\n",
      "Would you like me to tailor a palette for a specific use case (e.g., a notebook theme, a dashboard in a BI tool, or a slide deck) or provide more hex options (including a full 5–7 color sequence)? If you share the exact charts you use or the tools (Matplotlib/Seaborn/Plotly/R) I can give you ready-to-paste palettes.\n",
      "\n",
      "3. User: I have a dog named Max\n",
      "   AI: Max sounds like a great companion! If you’d like, I can tailor a color palette inspired by him. Tell me a bit about his coat/breed (e.g., golden, brindle, black-and-tan, husky-like), and I’ll craft a 5–7 color sequence you can use.\n",
      "\n",
      "In the meantime, here are a few “Max-inspired” starter palettes you can use right away:\n",
      "\n",
      "Option 1 — Golden Max (warm, friendly)\n",
      "- Cream: #f6f0e6\n",
      "- Max Gold: #d4a017\n",
      "- Medium Brown: #8b5e2b\n",
      "- Dark Brown: #3a2e1f\n",
      "- Accent Blue: #2b7fff\n",
      "\n",
      "Option 2 — Black & Tan Max (classic and versatile)\n",
      "- Ivory: #f5f0e6\n",
      "- Tan: #d2a76f\n",
      "- Black: #1b1b1b\n",
      "- Rich Brown: #7b5a43\n",
      "- Accent Blue: #4a90e2\n",
      "\n",
      "Option 3 — Husky Max (cool and crisp)\n",
      "- White: #ffffff\n",
      "- Ice Gray: #dfe7f3\n",
      "- Slate: #7a8a99\n",
      "- Navy: #1e3a8a\n",
      "- Accent Orange: #f5a623\n",
      "\n",
      "Tips:\n",
      "- Use 1–2 base colors for most visuals, with 1 accent color for highlights.\n",
      "- If you plan to share visuals with others, consider colorblind-safe pairings (e.g., blue/orange combinations) like in the examples.\n",
      "- Tell me the exact use case (notebook theme, dashboard, slides) and the tool (Matplotlib/Seaborn/Plotly, PowerPoint, Keynote), and I’ll give you ready-to-paste color cycles and theme suggestions.\n",
      "\n",
      "4. User: What's my favorite color?\n",
      "   AI: I don’t know your favorite color. If you’d like, I can help you figure it out or just pick one for you and build a whole palette around it.\n",
      "\n",
      "Ways to proceed:\n",
      "- Tell me a color you already like (e.g., blue, gold, teal), and I’ll give you a full 5–7 color palette centered on that color for charts, slides, or dashboards.\n",
      "- Answer a couple quick questions and I’ll suggest 2–3 top color palettes you’re likely to enjoy.\n",
      "- Or I can present 3 ready-to-use starter palettes (with hex codes) and you can tell me which you prefer.\n",
      "\n",
      "Here are three quick starter palettes to choose from (5 colors each):\n",
      "\n",
      "1) Blue-dominant, high-contrast\n",
      "- #0b3d8f\n",
      "- #2b6cb0\n",
      "- #4a7bd4\n",
      "- #6ec0ff\n",
      "- #ff8c00 (accent)\n",
      "\n",
      "2) Warm, energetic gold/orange\n",
      "- #f7f0e6 (background)\n",
      "- #d4a017 (gold)\n",
      "- #8b5e2b (brown)\n",
      "- #3a2e1f (dark)\n",
      "- #ff6b35 (bright accent)\n",
      "\n",
      "3) Neutral with a blue accent (business-friendly)\n",
      "- #f7f7f7 (background)\n",
      "- #e9ecef (panel)\n",
      "- #6b7280 (neutral gray)\n",
      "- #1e3a8a (blue accent)\n",
      "- #4a90e2 (secondary blue)\n",
      "\n",
      "If you share your use case (notebook theme, dashboard, slides) and tools (Matplotlib/Seaborn/Plotly, PowerPoint, etc.), I’ll tailor a ready-to-paste color cycle and theme. Also, if you want me to guess your favorite color, I can propose a few likely options and you can tell me which one fits.\n",
      "\n",
      "5. User: What's my dog's name?\n",
      "   AI: Your dog's name is Max.\n",
      "\n",
      "Would you like a Max-inspired color palette? Tell me about his coat or breed (e.g., golden, brindle, black-and-tan, husky-like), and I’ll craft a 5–7 color sequence you can use. Or I can tailor from one of the starter palettes I shared earlier.\n",
      "\n",
      "6. User: What do I do for work?\n",
      "   AI: I don’t know your job. But I can tailor a color palette for your work context. How would you like to proceed?\n",
      "\n",
      "Options:\n",
      "- Tell me your industry/role (e.g., data science, marketing, finance, education) and I’ll give you a 5–7 color palette sized for dashboards, slides, and reports.\n",
      "- I can guess a few common roles and suggest palettes; you tell me which fits.\n",
      "- Jump straight to ready-to-use starter palettes below and I’ll tailor from one you pick.\n",
      "\n",
      "Starter palettes (5 colors each):\n",
      "1) Blue-dominant, high-contrast\n",
      "- #0b3d8f\n",
      "- #2b6cb0\n",
      "- #4a7bd4\n",
      "- #6ec0ff\n",
      "- #ff8c00 (accent)\n",
      "\n",
      "2) Warm, energetic gold/orange\n",
      "- #f7f0e6 (background)\n",
      "- #d4a017 (gold)\n",
      "- #8b5e2b (brown)\n",
      "- #3a2e1f (dark)\n",
      "- #ff6b35 (bright accent)\n",
      "\n",
      "3) Neutral with a blue accent (business-friendly)\n",
      "- #f7f7f7 (background)\n",
      "- #e9ecef (panel)\n",
      "- #6b7280 (neutral gray)\n",
      "- #1e3a8a (blue accent)\n",
      "- #4a90e2 (secondary blue)\n",
      "\n",
      "Tips:\n",
      "- Tell me the tool you use (PowerPoint, Google Slides, Excel/Sheets, Matplotlib/Seaborn/Plotly) and I’ll provide a ready-to-paste color cycle and theme.\n",
      "- I can also add accessibility-friendly contrasts and a light/dark pair if you need it.\n",
      "\n",
      "What would you like to do?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "# Keep only last 2 interactions (4 messages total)\n",
    "window_memory = ConversationBufferWindowMemory(k=2)\n",
    "\n",
    "window_conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=window_memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Have multiple exchanges\n",
    "exchanges = [\n",
    "    \"My favorite color is blue\",\n",
    "    \"I work as a data scientist\",\n",
    "    \"I have a dog named Max\",\n",
    "    \"What's my favorite color?\",  # Should remember\n",
    "    \"What's my dog's name?\",      # Should remember\n",
    "    \"What do I do for work?\"      # Might not remember (outside window)\n",
    "]\n",
    "\n",
    "for i, user_input in enumerate(exchanges, 1):\n",
    "    response = window_conversation.predict(input=user_input)\n",
    "    print(f\"{i}. User: {user_input}\")\n",
    "    print(f\"   AI: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BndoZoE-zW5"
   },
   "source": [
    "## 5. ConversationSummaryMemory\n",
    "\n",
    "Summarizes conversation history to save tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197059,
     "status": "ok",
     "timestamp": 1761239172691,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "f3NWhANJ-zW6",
    "outputId": "2ebfe7ba-14aa-4b84-f829-fb414bb7cc17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: I'm planning a trip to Japan next month. I'm interested in visiting Tokyo, Kyoto, and Osaka.\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3066217642.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  summary_memory = ConversationSummaryMemory(llm=llm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: Great choice—Tokyo, Kyoto, and Osaka make a fantastic loop. Here’s a practical starter plan with flexible options, plus some tips to tailor it to your dates and pace.\n",
      "\n",
      "Sample itineraries\n",
      "\n",
      "Option A: 9–10 days (balanced pace)\n",
      "- Tokyo: 4 days\n",
      "  - Highlights: Shibuya Crossing and Hachiko, Shinjuku Gyoen, Meiji Shrine, Harajuku, Asakusa and Senso-ji, Akihabara or teamLab (if you like digital art), Tsukiji Outer Market or Toyosu for seafood, maybe a day trip to Nikko or Hakone if you’re keen.\n",
      "- Kyoto: 3 days\n",
      "  - Highlights: Fushimi Inari Taisha (early morning is best), Kiyomizu-dera, Gion and Higashiyama, Arashiyama Bamboo Grove and Tenryu-ji, Nishiki Market.\n",
      "- Osaka: 2 days\n",
      "  - Highlights: Dotonbori and Kuromon Market, Osaka Castle, Shinsekai, Umeda Sky Building or Floating Garden (great city views). If you’re a theme-park fan, consider a half-day at Universal Studios Japan.\n",
      "- Travel between cities: Shinkansen from Tokyo to Kyoto (about 2h 15m on a Hikari) and from Kyoto to Osaka (about 15–30 minutes by JR Special Rapid or Shinkansen to Shin-Osaka).\n",
      "\n",
      "Option B: 7 days (faster pace)\n",
      "- Tokyo: 2–3 days (hit core neighborhoods and one nearby day trip)\n",
      "- Kyoto: 2 days (classic temples and neighborhoods)\n",
      "- Osaka: 2 days (food-only city vibe plus sights)\n",
      "- Travel: Same rail plan as above, but you’ll move a bit faster between cities.\n",
      "\n",
      "If you’re staying longer or shorter, tell me your total number of days and I’ll tailor a day-by-day plan.\n",
      "\n",
      "Transport and passes\n",
      "\n",
      "- Between cities: If you’re comfortable with Shinkansen, you’ll likely do Tokyo → Kyoto → Osaka. Nozomi trains are the fastest, but they aren’t covered by the nationwide JR Pass (if you’re considering a pass). Hikari (and Kodama) are covered by JR Pass. If you’re not buying a JR Pass, you can still get reserved-seat Shinkansen tickets (typically a bit cheaper if you choose non-Nozomi). Rough ballpark: Tokyo→Kyoto one-way is about 13,000–15,000 JPY for standard reserved seating; Kyoto→Osaka is about 1,000–2,000 JPY depending on route.\n",
      "- In-city transport: Get a rechargeable IC card (Suica or Pasmo in Tokyo; ICOCA in Kansai). These work across Tokyo and Kansai, and you can use them on most trains, subways, buses, and even some merchants.\n",
      "- Rail passes to consider: \n",
      "  - JR Pass (7, 14, 21 days) can be convenient if you plan multiple long Shinkansen legs or many JR local rides, but it may not save money if you’re staying mostly in urban JR lines and short hops. You activate it on the first day you use it.\n",
      "  - Kansai-area passes can be handy for Osaka/Kyoto if you’re spending most time in that region, but they don’t cover Tokyo departures.\n",
      "  - If you prefer simplicity and have a shorter trip, single tickets plus IC cards often works best.\n",
      "- Tickets and reservations: For popular spots and high-season days, book Shinkansen seats in advance when possible. Reserve seats for Tokyo→Kyoto if you want guaranteed seating.\n",
      "\n",
      "Top highlights by city (quick picks)\n",
      "\n",
      "- Tokyo\n",
      "  - Shibuya Crossing and scramble area; Meiji Jingu and Yoyogi Park; Asakusa and Senso-ji; Tsukiji Outer Market or Toyosu for seafood; Odaiba for views and entertainment; optional day trips to Nikko (shrine complex) or Hakone (hot springs, scenery).\n",
      "- Kyoto\n",
      "  - Fushimi Inari Taisha (early morning is best to avoid crowds); Kiyomizu-dera and the historic Higashiyama district; Arashiyama (Bamboo Grove, Tenryu-ji); Kinkaku-ji (Temple of the Golden Pavilion) if you’re into classic sights; Nishiki Market for food strolls.\n",
      "- Osaka\n",
      "  - Dotonbori and downstream food scene; Kuromon Market lunch crawl; Osaka Castle and the surrounding park; Shinsekai for retro vibes; Umeda Sky Building or Harukas for city views; optional day trip to Nara or Kobe if you want more variety.\n",
      "\n",
      "Food and local experiences\n",
      "\n",
      "- Tokyo: sushi or sashimi near Tsukiji/Treon; ramen in neighborhoods like Ichiran, Afuri, or Ichibanya; monjayaki in Tsukishima; yakitori in Omoide Yokocho or memory-lane alleys.\n",
      "- Kyoto: kaiseki or toe-to-toe obanzai meals; tofu dishes in a suimen-yaki or yuba style; street food near Nishiki Market.\n",
      "- Osaka: takoyaki and okonomiyaki in Dotonbori; kushikatsu in Shinsekai; casual izakayas around Namba.\n",
      "\n",
      "Practical tips for your trip\n",
      "\n",
      "- Weather and packing: November in Japan is autumn. Expect mild days and chilly evenings, especially in Kyoto/Osaka. Pack a light jacket, layers, comfortable walking shoes, and an umbrella.\n",
      "- Luggage: If you’re moving cities frequently, consider using a Takkyubin (luggage forwarding) service to ship your bags from Tokyo to Kyoto or Kyoto to Osaka. It makes day trips and quick hotel changes easier.\n",
      "- Connectivity: A pocket Wi-Fi or eSIM is handy for maps and transit apps.\n",
      "- Reservations: Popular restaurants and some attractions require reservations, especially in Kyoto and Tokyo. If you have favorites, book ahead.\n",
      "- Accessibility and walking: Distances between stations and sights can add up; plan 1–2 long walking days and mix in shorter, easy days.\n",
      "\n",
      "What I need from you to tailor this perfectly\n",
      "\n",
      "- How many days are you staying total?\n",
      "- Do you want a slower, more immersive pace or a faster, busy schedule?\n",
      "- Any must-see spots or activities (temples, anime/gaming, food tours, shopping, day trips like Nikko, Nara, Kobe, Hakone, etc.)?\n",
      "- Are you considering a JR Pass or do you prefer paying per trip?\n",
      "- Rough date you’re traveling (the exact days matter for crowds and reservations)?\n",
      "\n",
      "If you share a few details, I’ll turn this into a precise day-by-day plan with exact train options, time estimates, and booking notes.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "New summary:\n",
      "- The human asks for a practical starter plan for a Japan trip covering Tokyo, Kyoto, and Osaka.\n",
      "- The assistant provides two sample itineraries: Option A (9–10 days) with Tokyo (4 days), Kyoto (3 days), Osaka (2 days) and travel details between cities (Shinkansen: Tokyo→Kyoto ~2h15m on Hikari; Kyoto→Osaka 15–30 minutes); Option B (7 days) with a faster pace (2–3 days Tokyo, 2 days Kyoto, 2 days Osaka) and the same general rail plan.\n",
      "- It includes transport guidance: Shinkansen options (Nozomi not JR Pass-covered; Hikari/Kodama covered by JR Pass), rough one-way prices (Tokyo→Kyoto ~13,000–15,000 JPY; Kyoto→Osaka ~1,000–2,000 JPY), recommendation to use IC cards (Suica/Pasmo in Tokyo; ICOCA in Kansai), and notes on JR Pass usefulness based on trip structure; advice on reserving seats.\n",
      "- City highlights by area: Tokyo (Shibuya, Meiji, Asakusa, Tsukiji/Toyosu, Odaiba; day trips to Nikko/Hakone), Kyoto (Fushimi Inari, Kiyomizu-dera, Arashiyama, Nishiki Market), Osaka (Dotonbori, Kuromon Market, Osaka Castle, Shinsekai, Umeda Sky Building; possible Nara/Kobe day trips).\n",
      "- Food and experiential ideas for each city: Tokyo (sushi/ramen/yakitori); Kyoto (kaiseki/obanzai/tofu dishes); Osaka (takoyaki/okonomiyaki/kushikatsu).\n",
      "- Practical tips: November weather in Japan (mild days, cool evenings); luggage forwarding (Takkyubin); connectivity (pocket Wi‑Fi/eSIM); reservations for popular spots; walking and pacing considerations.\n",
      "- Information needed to tailor precisely: total trip days, preferred pace, must-see activities, whether to use a JR Pass, and rough travel dates.\n",
      "- The assistant offers to produce a detailed day-by-day plan with exact train options and booking notes once the user provides those details.\n",
      "Human: I love Japanese food, especially sushi and ramen.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: Awesome—sushi and ramen are a fantastic lens for exploring Japan. Here are foodie-focused ideas to help you start shaping your trip. I can turn this into a detailed day-by-day plan with exact trains and reservations once you share your trip length, dates, and pace.\n",
      "\n",
      "Top sushi and ramen vibes by city\n",
      "\n",
      "Tokyo\n",
      "- Sushi highlights\n",
      "  - Toyosu Market (early morning sushi experience; a lot of people go for the famous counter sushi). If lines are long, you can try good-value options around the Ginza or Shimbashi area.\n",
      "  - Counter sushi spots in Ginza or Tsukiji area for freshness and a classic Edomae vibe. Look for reputable mid-range counters if you don’t want to splurge.\n",
      "  - For a wow factor (and lots of planning), there are several top-tier counters with reservations, but they’re hard to get into without a local connection.\n",
      "- Ramen vibes\n",
      "  - Ramen Street near Tokyo Station for a quick, varied cross-section of Tokyo ramen shops.\n",
      "  - Shinjuku or Shibuya for ramen crawls: tonkotsu, shoyu, miso, or shio—choose a few spots and stroll between them.\n",
      "  - Notable chains you’ll see everywhere: Ichiran and Ippudo are easy to find and reliable; Afuri (yuzu-tinted) offers something lighter and refreshing.\n",
      "- Quick food ideas\n",
      "  - Tsukiji Outer Market for seafood snacks and small bites in the morning.\n",
      "  - Izakaya evenings around Shinjuku, Shibuya, or Ebisu for casual sushi snacks, yakitori, and other small dishes.\n",
      "\n",
      "Kyoto\n",
      "- Sushi-ish notes\n",
      "  - Kyoto isn’t as famous for sushi as Tokyo, but you can still find excellent nigiri and fresh seafood at simple counters. Many visitors pair it with Kyoto’s standout tofu/yuba dishes.\n",
      "- Ramen vibes\n",
      "  - Kyoto-style ramen tends to be lighter and dashi-forward; you’ll find several solid shops around central Kyoto. It’s a nice contrast to Tokyo’s heavier tonkotsu options.\n",
      "- Other must-try food\n",
      "  - Nishiki Market for a tasting stroll: mochi, pickles, yuba (tofu skin) specialties, and Kyoto-style sweets.\n",
      "  - Tofu and kyo-kaiseki options if you want a refined, traditional meal to balance the ramen sushi day.\n",
      "\n",
      "Osaka\n",
      "- Sushi/seafood notes\n",
      "  - Osaka is renowned for affordable, high-energy meals. You’ll find great sushi counters and casual spots, plus the city’s famous street food culture.\n",
      "- Ramen vibes\n",
      "  - Ramen options are plentiful in Osaka, with places concentrated in Namba and Umeda. Look for a small, busy shop with a line; it’s usually a sign of good ramen.\n",
      "- Other must-try foods\n",
      "  - Dotonbori for takoyaki and okonomiyaki (absolute Osaka staples).\n",
      "  - Shinsekai and Kuromon Market are great for a food crawl and trying multiple stalls in one go.\n",
      "  - Kushikatsu in Shinsekai for a crispy, savory finish.\n",
      "\n",
      "Practical tips for sushi and ramen lovers\n",
      "- Reservations and queues\n",
      "  - High-end sushi counters often require reservations and can be pricey; for more budget-friendly options, aim for reputable mid-range counters or reputable chain spots.\n",
      "  - Ramen shops are usually walk-in; if you see a line, consider coming back in ~30 minutes or during off-peak hours (early lunch, mid-afternoon).\n",
      "- Etiquette and pacing\n",
      "  - Sushi: eat nigiri with hands or chopsticks; soy sauce is for dipping the fish side, not the rice. Finish one piece before starting the next; greet the chef politely if you’re at a counter.\n",
      "  - Ramen: slurping is normal and encouraged in Japan. Savor the broth and noodles; you can customize with toppings if the shop offers it (tamago, extra chashu, ajitama, etc.).\n",
      "- Budget and ordering\n",
      "  - In Tokyo and Osaka, you can mix sushi and ramen across a day without breaking the bank if you choose mid-range counters and popular mid-tier ramen spots.\n",
      "  - In Kyoto, you’ll often find great value in Nishiki Market stalls and smaller local spots; don’t expect haute sushi here, but you’ll get fresh, tasty options and excellent local flavors.\n",
      "- Practicalities\n",
      "  - Freshness and freshness windows matter most for sushi; consider morning visits to markets for the best picks.\n",
      "  - Cash is widely accepted, but many places also take cards; it’s good to have some cash on hand for smaller stalls and market bites.\n",
      "  - Pocket Wi‑Fi or eSIM helps if you’re navigating or checking up-to-date spots on the go.\n",
      "\n",
      "If you want, I can turn this into a concrete, day-by-day, food-focused plan for Tokyo/Kyoto/Osaka. To tailor it well, share:\n",
      "- Total trip length (in days).\n",
      "- Your preferred pace (e.g., 1-2 sushi/ramen stops per day, or a lighter day with 1 big meal + snacks).\n",
      "- Rough budget per person per day.\n",
      "- Any must-try spots (by vibe or neighborhood) or dietary preferences.\n",
      "- Rough travel dates (so I can flag seasonal specialties and market timings).\n",
      "\n",
      "Ready when you are to draft a precise day-by-day sushi- and ramen-centric itinerary with suggested restaurants, reservations, and train notes.\n",
      "\n",
      "\n",
      "==================================================\n",
      "Conversation Summary:\n",
      "{'history': '- The human expresses love for Japanese food, especially sushi and ramen.\\n- The AI responds that sushi and ramen are a great lens for exploring Japan and offers to turn this into a detailed day-by-day plan with exact trains and reservations once trip length, dates, and pace are provided.\\n- It provides top sushi- and ramen-focused vibes by city, detailing Tokyo, Kyoto, and Osaka, including sushi highlights, ramen vibes, and other must-try foods.\\n- Practical tips for sushi and ramen lovers are included (reservations/queues, etiquette, budgeting, and general dining guidance).\\n- It invites tailoring with specific inputs: total trip length, preferred pace, rough budget per person per day, must-try spots or dietary preferences, and rough travel dates.\\n- The AI indicates readiness to draft a precise day-by-day, food-focused itinerary with suggested restaurants, reservations, and train notes once the user supplies those details.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "# Initialize summary memory\n",
    "summary_memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "summary_conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=summary_memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Have a conversation\n",
    "response1 = summary_conversation.predict(\n",
    "    input=\"I'm planning a trip to Japan next month. I'm interested in visiting Tokyo, Kyoto, and Osaka.\"\n",
    ")\n",
    "print(f\"AI: {response1}\\n\")\n",
    "\n",
    "response2 = summary_conversation.predict(\n",
    "    input=\"I love Japanese food, especially sushi and ramen.\"\n",
    ")\n",
    "print(f\"AI: {response2}\\n\")\n",
    "\n",
    "# Check the summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Conversation Summary:\")\n",
    "print(summary_memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9AdjP_l-zW6"
   },
   "source": [
    "## 6. ConversationSummaryBufferMemory\n",
    "\n",
    "Hybrid approach: keeps recent messages and summarizes older ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113022,
     "status": "ok",
     "timestamp": 1761239285705,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "b2j7WsYa-zW6",
    "outputId": "f83ee43e-4b7e-4724-a37d-9f25f86df1ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1975412117.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  hybrid_memory = ConversationSummaryBufferMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Tell me about machine learning\n",
      "AI: Sure—here’s a solid overview of machine learning (ML) and how it fits into the broader field of arti...\n",
      "\n",
      "User: What are neural networks?\n",
      "AI: Neural networks are a family of machine learning models inspired by how brains process information. ...\n",
      "\n",
      "User: Explain deep learning\n",
      "AI: Deep learning is a subset of machine learning that uses neural networks with many layers to learn re...\n",
      "\n",
      "User: What did we start discussing?\n",
      "AI: We started discussing deep learning—the subset of machine learning that uses deep neural networks to...\n",
      "\n",
      "\n",
      "Memory Content:\n",
      "{'history': 'System: New summary:\\nIn addition to the earlier overview of machine learning, the conversation now explains deep learning as a subset of ML that uses neural networks with many layers to learn representations directly from raw data, enabling end-to-end learning. It clarifies that depth matters because multiple layers build progressively abstract features, and training is end-to-end, adjusting all layers to minimize a loss. The process involves forward passes, computing loss, backpropagation, and optimization on large datasets. Common architectures include MLPs, CNNs, RNNs/LSTMs/GRUs, Transformers, and GNNs, each suited to different data types. Deep learning excels at learning complex nonlinear mappings, automatic representation learning, and transfer learning, but requires substantial data and compute, can be opaque, and may overfit or encode biases if not properly regularized. Typical training considerations cover data and compute needs, activation and loss choices, regularization (e.g., dropout, weight decay, data augmentation, early stopping), optimization strategies (SGD variants, Adam), and architectural design decisions (depth/width, skip connections, normalization). Common tasks span image, language, and audio processing, as well as general time-series and reinforcement learning. The AI also offers concrete examples or a step-by-step project walkthrough if you’d like.\\nHuman: What did we start discussing?\\nAI: We started discussing deep learning—the subset of machine learning that uses deep neural networks to learn representations from raw data in an end-to-end fashion (forward pass, loss, backpropagation, optimization).'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "# Summarize when history exceeds token limit\n",
    "hybrid_memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=100  # Summarize when history > 100 tokens\n",
    ")\n",
    "\n",
    "hybrid_conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=hybrid_memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Long conversation\n",
    "topics = [\n",
    "    \"Tell me about machine learning\",\n",
    "    \"What are neural networks?\",\n",
    "    \"Explain deep learning\",\n",
    "    \"What did we start discussing?\"\n",
    "]\n",
    "\n",
    "for topic in topics:\n",
    "    response = hybrid_conversation.predict(input=topic)\n",
    "    print(f\"User: {topic}\")\n",
    "    print(f\"AI: {response[:100]}...\\n\")\n",
    "\n",
    "print(\"\\nMemory Content:\")\n",
    "print(hybrid_memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fsiqqyf-zW6"
   },
   "source": [
    "## 7. Using Memory with LCEL\n",
    "\n",
    "Modern approach using RunnableWithMessageHistory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10957,
     "status": "ok",
     "timestamp": 1761239296666,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "KUrqZHoE-zW6",
    "outputId": "f3a328d1-71c0-4d1e-c14e-f613998cac79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Nice! Python is a great choice—versatile and beginner-friendly. What do you enjoy most about Python? Are you into web development, data science, automation, or something else?\n",
      "\n",
      "If you’d like, I can tailor suggestions to your goal. A few quick ideas:\n",
      "- Beginner projects: a simple CLI to-do list, a calculator, or a file renamer.\n",
      "- Web apps: a tiny Flask or FastAPI app.\n",
      "- Data: analyze a CSV with pandas and visualize results.\n",
      "- Automation: small scripts to automate repetitive tasks.\n",
      "\n",
      "Tell me your current level and what you want to build or learn, and I’ll help with project ideas, explanations of concepts, or code examples.\n",
      "\n",
      "AI: Python. Want some Python-specific project ideas or help with a topic you’re learning?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "# Create prompt with message history placeholder\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Create chain\n",
    "chain = prompt | llm\n",
    "\n",
    "# Store for message histories (in production, use database)\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Wrap chain with message history\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# Have a conversation with session ID\n",
    "config = {\"configurable\": {\"session_id\": \"user_123\"}}\n",
    "\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"input\": \"Hi! My favorite programming language is Python.\"},\n",
    "    config=config\n",
    ")\n",
    "print(f\"AI: {response1.content}\\n\")\n",
    "\n",
    "response2 = chain_with_history.invoke(\n",
    "    {\"input\": \"What's my favorite language?\"},\n",
    "    config=config\n",
    ")\n",
    "print(f\"AI: {response2.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-yzD6qk-zW6"
   },
   "source": [
    "## 8. Multi-User Conversations\n",
    "\n",
    "Handle multiple users with separate conversation histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19581,
     "status": "ok",
     "timestamp": 1761239316250,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "MKqrVCOx-zW7",
    "outputId": "eddee485-c449-4476-adc8-36d76c6f5235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== User 1 ===\n",
      "AI: Hi Alice! Nice to meet you. How can I help you today? I can assist with writing, planning, learning, coding, or just chat—whatever you need.\n",
      "\n",
      "=== User 2 ===\n",
      "AI: Nice to meet you, Bob! How can I help you today? I can answer questions, brainstorm ideas, draft messages or reports, explain topics, help with math or coding, plan tasks, or do research—just tell me what you’d like to work on.\n",
      "\n",
      "=== Back to User 1 ===\n",
      "AI: Your name is Alice. What would you like to do today, Alice?\n",
      "\n",
      "=== Back to User 2 ===\n",
      "AI: Your name is Bob. Would you like me to keep using that name in this chat or remember it for future chats?\n"
     ]
    }
   ],
   "source": [
    "# User 1 conversation\n",
    "print(\"=== User 1 ===\")\n",
    "config_user1 = {\"configurable\": {\"session_id\": \"user_1\"}}\n",
    "\n",
    "r1 = chain_with_history.invoke(\n",
    "    {\"input\": \"My name is Alice\"},\n",
    "    config=config_user1\n",
    ")\n",
    "print(f\"AI: {r1.content}\\n\")\n",
    "\n",
    "# User 2 conversation\n",
    "print(\"=== User 2 ===\")\n",
    "config_user2 = {\"configurable\": {\"session_id\": \"user_2\"}}\n",
    "\n",
    "r2 = chain_with_history.invoke(\n",
    "    {\"input\": \"My name is Bob\"},\n",
    "    config=config_user2\n",
    ")\n",
    "print(f\"AI: {r2.content}\\n\")\n",
    "\n",
    "# Check User 1's name\n",
    "print(\"=== Back to User 1 ===\")\n",
    "r3 = chain_with_history.invoke(\n",
    "    {\"input\": \"What's my name?\"},\n",
    "    config=config_user1\n",
    ")\n",
    "print(f\"AI: {r3.content}\\n\")\n",
    "\n",
    "# Check User 2's name\n",
    "print(\"=== Back to User 2 ===\")\n",
    "r4 = chain_with_history.invoke(\n",
    "    {\"input\": \"What's my name?\"},\n",
    "    config=config_user2\n",
    ")\n",
    "print(f\"AI: {r4.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0GVMwlj-zW7"
   },
   "source": [
    "## 9. Memory Management Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1761239316273,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "jRHOQXQ_-zW7",
    "outputId": "fdd72d26-33f6-4ace-81ab-aeab53926d37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation History:\n",
      "Human: Tell me about artificial intelligence\n",
      "AI: Artificial intelligence (AI) is a branch of computer science...\n",
      "\n",
      "Estimated tokens: 28\n",
      "\n",
      "Token Limits:\n",
      "  GPT-3.5-turbo: 4,096 tokens\n",
      "  GPT-4: 8,192 tokens\n",
      "  GPT-4-turbo: 128,000 tokens\n"
     ]
    }
   ],
   "source": [
    "# Counting tokens in conversation history\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "def estimate_tokens(text):\n",
    "    \"\"\"Rough estimate: 1 token ≈ 4 characters\"\"\"\n",
    "    return len(text) // 4\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context(\n",
    "    {\"input\": \"Tell me about artificial intelligence\"},\n",
    "    {\"output\": \"Artificial intelligence (AI) is a branch of computer science...\"}\n",
    ")\n",
    "\n",
    "history = memory.load_memory_variables({})[\"history\"]\n",
    "token_estimate = estimate_tokens(history)\n",
    "\n",
    "print(f\"Conversation History:\\n{history}\\n\")\n",
    "print(f\"Estimated tokens: {token_estimate}\")\n",
    "print(f\"\\nToken Limits:\")\n",
    "print(f\"  GPT-3.5-turbo: 4,096 tokens\")\n",
    "print(f\"  GPT-4: 8,192 tokens\")\n",
    "print(f\"  GPT-4-turbo: 128,000 tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elJcSACz-zW7"
   },
   "source": [
    "## 10. Memory Type Comparison\n",
    "\n",
    "| Memory Type | When to Use | Pros | Cons |\n",
    "|------------|-------------|------|------|\n",
    "| **ConversationBufferMemory** | Short conversations | Simple, complete history | High token usage |\n",
    "| **ConversationBufferWindowMemory** | Fixed context window | Predictable tokens | Loses old context |\n",
    "| **ConversationSummaryMemory** | Long conversations | Efficient tokens | Loses detail, costs to summarize |\n",
    "| **ConversationSummaryBufferMemory** | Long + detail needed | Best of both | More complex |\n",
    "| **Message History (LCEL)** | Production apps | Flexible, scalable | Requires setup |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kY5pZwz8-zW7"
   },
   "source": [
    "## 🎯 Exercise 6: Build a Personal Assistant\n",
    "\n",
    "**Task**: Create a personal assistant that:\n",
    "1. Remembers user preferences (name, interests, etc.)\n",
    "2. Uses appropriate memory type\n",
    "3. Handles multiple conversation threads\n",
    "4. Can reset or export conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1761239316281,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "8I7ZqVne-zW7"
   },
   "outputs": [],
   "source": [
    "class PersonalAssistant:\n",
    "    def __init__(self, user_id):\n",
    "        \"\"\"\n",
    "        Initialize a personal assistant for a user\n",
    "\n",
    "        Args:\n",
    "            user_id: Unique identifier for the user\n",
    "        \"\"\"\n",
    "        # TODO: Implement initialization\n",
    "        pass\n",
    "\n",
    "    def chat(self, message):\n",
    "        \"\"\"\n",
    "        Send a message to the assistant\n",
    "\n",
    "        Args:\n",
    "            message: User's message\n",
    "\n",
    "        Returns:\n",
    "            Assistant's response\n",
    "        \"\"\"\n",
    "        # TODO: Implement chat\n",
    "        pass\n",
    "\n",
    "    def get_history(self):\n",
    "        \"\"\"\n",
    "        Export conversation history\n",
    "        \"\"\"\n",
    "        # TODO: Implement history export\n",
    "        pass\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Clear conversation history\n",
    "        \"\"\"\n",
    "        # TODO: Implement reset\n",
    "        pass\n",
    "\n",
    "# Test your assistant\n",
    "# assistant = PersonalAssistant(user_id=\"alice\")\n",
    "# assistant.chat(\"Hi, my name is Alice\")\n",
    "# assistant.chat(\"What's my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bq1iy_yS-zW7"
   },
   "source": [
    "## 🎯 Exercise 7: Smart Memory Selection\n",
    "\n",
    "**Task**: Create a function that:\n",
    "1. Analyzes conversation length\n",
    "2. Automatically selects the best memory type\n",
    "3. Switches memory types dynamically if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1761239316306,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "lZo9Y8YK-zW7"
   },
   "outputs": [],
   "source": [
    "def select_memory_type(conversation_length, avg_message_length):\n",
    "    \"\"\"\n",
    "    Select optimal memory type based on conversation characteristics\n",
    "\n",
    "    Args:\n",
    "        conversation_length: Number of messages\n",
    "        avg_message_length: Average message length in characters\n",
    "\n",
    "    Returns:\n",
    "        Appropriate memory instance\n",
    "    \"\"\"\n",
    "    # TODO: Implement smart memory selection\n",
    "    pass\n",
    "\n",
    "# Test\n",
    "# memory = select_memory_type(conversation_length=100, avg_message_length=50)\n",
    "# print(f\"Selected memory type: {type(memory).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ksUXs0L-zW8"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "✅ Why memory is essential for LLM applications  \n",
    "✅ Different memory types and their use cases  \n",
    "✅ ConversationBufferMemory for simple conversations  \n",
    "✅ ConversationBufferWindowMemory for token management  \n",
    "✅ ConversationSummaryMemory for long conversations  \n",
    "✅ Modern LCEL approach with RunnableWithMessageHistory  \n",
    "✅ Multi-user conversation handling  \n",
    "✅ Memory management best practices  \n",
    "\n",
    "**Congratulations!** You've completed Session 1 of the LangChain course!\n",
    "\n",
    "**Next**: Tomorrow we'll dive into advanced topics including Agents, Tools, and RAG systems!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
