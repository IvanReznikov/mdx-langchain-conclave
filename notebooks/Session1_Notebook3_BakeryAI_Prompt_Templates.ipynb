{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAjDkpwM1wkl"
   },
   "source": [
    "# Session 1.3: BakeryAI - Prompt Engineering & Templates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZmOQH-g8-E3"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1SAIwncgxIog0VHd021vGsYPuixldyibr?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nD_fhif58-B8"
   },
   "source": [
    "\n",
    "## üéØ Today's Goal\n",
    "\n",
    "Create **professional, consistent customer interactions** using prompt templates!\n",
    "\n",
    "### What We'll Build:\n",
    "\n",
    "‚úÖ Reusable prompt templates for common interactions  \n",
    "‚úÖ Order confirmation system  \n",
    "‚úÖ Structured product recommendations  \n",
    "‚úÖ Multi-language support  \n",
    "‚úÖ Automated email generation  \n",
    "\n",
    "### Why This Matters:\n",
    "\n",
    "Consistent communication is crucial for customer service:\n",
    "- **Brand voice**: Every interaction feels professional\n",
    "- **Efficiency**: Reuse templates across scenarios\n",
    "- **Quality**: No more inconsistent responses\n",
    "- **Scalability**: Easy to update all interactions at once\n",
    "\n",
    "### üöÄ BakeryAI Progress: 40% ‚Üí 60%\n",
    "```\n",
    "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 60%\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 12836,
     "status": "ok",
     "timestamp": 1761237756332,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "Cy2DQhT87S6G"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q langchain langchain-openai langchain-core langchain-community\n",
    "!pip install -q python-dotenv pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6302,
     "status": "ok",
     "timestamp": 1761237762645,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "GpFJYrVG2jNn",
    "outputId": "31e027d2-9d9b-4948-b3eb-ea908f79c570"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    FewShotPromptTemplate,\n",
    "    MessagesPlaceholder\n",
    ")\n",
    "from langchain_core.output_parsers import (\n",
    "    StrOutputParser,\n",
    "    JsonOutputParser,\n",
    "    CommaSeparatedListOutputParser\n",
    ")\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2067,
     "status": "ok",
     "timestamp": 1761237764715,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "W8AIuztM2pDE",
    "outputId": "4e60bfac-01a9-4225-d6b0-4775a6101757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# Set OpenAI API key from Google Colab's user environment or default\n",
    "def set_openai_api_key(default_key: str = \"YOUR_API_KEY\") -> None:\n",
    "    \"\"\"Set the OpenAI API key from Google Colab's user environment or use a default value.\"\"\"\n",
    "    #if not (userdata.get(\"OPENAI_API_KEY\") or \"OPENAI_API_KEY\" in os.environ):\n",
    "    try:\n",
    "      os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"MDX_OPENAI_API_KEY\")\n",
    "    except:\n",
    "      os.environ[\"OPENAI_API_KEY\"] = default_key\n",
    "\n",
    "set_openai_api_key()\n",
    "#set_openai_api_key(\"sk-...\")\n",
    "\n",
    "# Verify API key is loaded\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚úÖ OpenAI API key loaded successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå OpenAI API key not found. Please set it in .env file\")\n",
    "\n",
    "# Initialize models\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 933,
     "status": "ok",
     "timestamp": 1761237765654,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "97z6HpAF2sjA",
    "outputId": "34015a75-b169-4d17-8d4f-f361a1ca5df0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mdx-langchain-conclave'...\n",
      "remote: Enumerating objects: 19, done.\u001b[K\n",
      "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
      "remote: Total 19 (delta 1), reused 19 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (19/19), 239.34 KiB | 6.47 MiB/s, done.\n",
      "Resolving deltas: 100% (1/1), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/IvanReznikov/mdx-langchain-conclave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1761237765721,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "5bfbMtBH1wko",
    "outputId": "7ba18a1d-ce9a-42bf-8f5a-c07189ebdbbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment ready!\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "try:\n",
    "    cakes_df = pd.read_csv('/content/mdx-langchain-conclave/data/cake_descriptions.csv', encoding='cp1252')\n",
    "    orders_df = pd.read_csv('/content/mdx-langchain-conclave/data/orders.csv', encoding='cp1252')\n",
    "except FileNotFoundError:\n",
    "    cakes_df = pd.DataFrame({\n",
    "        'Name': ['Chocolate Truffle Cake', 'Vanilla Bean Cake', 'Red Velvet Cake'],\n",
    "        'Description': ['Rich chocolate', 'Classic vanilla', 'Velvety red'],\n",
    "        'Energy_kcal': [450, 380, 420],\n",
    "        'Delivery_time_hr': [24, 24, 48]\n",
    "    })\n",
    "\n",
    "print(\"‚úÖ Environment ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0x_Z8Pze1wkp"
   },
   "source": [
    "## 1. Basic Prompt Templates for BakeryAI\n",
    "\n",
    "Create reusable templates for common customer interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11370,
     "status": "ok",
     "timestamp": 1761237777105,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "N_sSSBKI1wkp",
    "outputId": "e1ac5217-cbad-43b3-d9d1-7f26d3b1111b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç∞ BakeryAI Response:\n",
      "Absolutely! The Chocolate Truffle Cake is a wonderful choice for a birthday party. Its rich chocolate cake with a silky truffle filling feels festive and indulgent, and it‚Äôs sure to be a crowd-pleaser.\n",
      "\n",
      "Ways to make it party-ready:\n",
      "- Size and servings: We offer multiple sizes to fit your guest count (tell me how many guests you‚Äôre expecting and I‚Äôll suggest the right size).\n",
      "- Birthday customization: Add a Happy Birthday message, edible toppers, and coordinating decorations or ribbons.\n",
      "- Presentation: We can decorate with birthday candles, chocolate shavings, or a themed finish to match your party vibe.\n",
      "\n",
      "Delivery and timing:\n",
      "- Delivery typically takes 24 hours from order. If you have a specific date, I can help plan accordingly.\n",
      "\n",
      "Dietary needs:\n",
      "- If anyone has dietary restrictions (nuts, dairy, gluten, etc.), let me know and I‚Äôll check which options we can accommodate.\n",
      "\n",
      "Would you like me to check availability for your date, and get a size and decoration plan started? If so, please share:\n",
      "- Date and time of the party\n",
      "- Estimated number of guests\n",
      "- Any inscription or theme preferences\n",
      "- Any dietary considerations\n"
     ]
    }
   ],
   "source": [
    "# Product inquiry template\n",
    "product_inquiry_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"\n",
    "    You are BakeryAI, a friendly and knowledgeable bakery assistant.\n",
    "\n",
    "    Brand Voice:\n",
    "    - Warm and welcoming\n",
    "    - Professional but not stuffy\n",
    "    - Enthusiastic about our products\n",
    "    - Always helpful and informative\n",
    "\n",
    "    Product: {product_name}\n",
    "    Description: {product_description}\n",
    "    Calories: {calories} kcal\n",
    "    Delivery Time: {delivery_time} hours\n",
    "    \"\"\"),\n",
    "    (\"human\", \"{customer_question}\")\n",
    "])\n",
    "\n",
    "# Create chain\n",
    "product_chain = product_inquiry_template | llm | StrOutputParser()\n",
    "\n",
    "# Test it\n",
    "response = product_chain.invoke({\n",
    "    \"product_name\": \"Chocolate Truffle Cake\",\n",
    "    \"product_description\": \"Rich chocolate cake with truffle filling\",\n",
    "    \"calories\": 450,\n",
    "    \"delivery_time\": 24,\n",
    "    \"customer_question\": \"Is this cake suitable for a birthday party?\"\n",
    "})\n",
    "\n",
    "print(\"üç∞ BakeryAI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5Iqr1ik1wkq"
   },
   "source": [
    "## 2. Order Confirmation Template\n",
    "\n",
    "Generate professional order confirmations with structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14437,
     "status": "ok",
     "timestamp": 1761237791547,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "2StTeFpr1wkq",
    "outputId": "b25b61d0-31ed-4989-b9a3-8404a31665ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìß Order Confirmation:\n",
      "{'order_number': '12345', 'customer_name': 'Sarah Johnson', 'items': ['1x Chocolate Truffle Cake', '2x Vanilla Cupcakes'], 'total_amount': 65.0, 'delivery_date': 'Tomorrow, 2 PM', 'confirmation_message': \"Hi Sarah, your order #12345 is confirmed. We've prepared 1x Chocolate Truffle Cake and 2x Vanilla Cupcakes for you. The total is $65.00. Delivery is scheduled for tomorrow at 2 PM. Please ensure someone is available to receive the order. If you need to adjust anything, just reply and we'll be happy to help.\"}\n"
     ]
    }
   ],
   "source": [
    "# Define order confirmation structure\n",
    "class OrderConfirmation(BaseModel):\n",
    "    order_number: str = Field(description=\"Unique order identifier\")\n",
    "    customer_name: str = Field(description=\"Customer's name\")\n",
    "    items: list = Field(description=\"List of ordered items\")\n",
    "    total_amount: float = Field(description=\"Total order amount\")\n",
    "    delivery_date: str = Field(description=\"Expected delivery date\")\n",
    "    confirmation_message: str = Field(description=\"Friendly confirmation message\")\n",
    "\n",
    "# JSON parser\n",
    "order_parser = JsonOutputParser(pydantic_object=OrderConfirmation)\n",
    "\n",
    "# Order confirmation template\n",
    "order_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are BakeryAI's order processing system.\n",
    "    Generate a friendly order confirmation based on the provided details.\n",
    "    Be warm and reassuring. Include delivery expectations.\"\"\"),\n",
    "    (\"human\", \"\"\"{order_details}\n",
    "\n",
    "    {format_instructions}\"\"\")\n",
    "])\n",
    "\n",
    "order_chain = order_template | llm | order_parser\n",
    "\n",
    "# Test order confirmation\n",
    "sample_order = \"\"\"\n",
    "Order #12345\n",
    "Customer: Sarah Johnson\n",
    "Items: 1x Chocolate Truffle Cake, 2x Vanilla Cupcakes\n",
    "Total: $65.00\n",
    "Delivery: Tomorrow, 2 PM\n",
    "\"\"\"\n",
    "\n",
    "confirmation = order_chain.invoke({\n",
    "    \"order_details\": sample_order,\n",
    "    \"format_instructions\": order_parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "print(\"üìß Order Confirmation:\")\n",
    "print(confirmation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0osbeWh1wkq"
   },
   "source": [
    "## 3. Product Recommendation Template with Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22162,
     "status": "ok",
     "timestamp": 1761237813713,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "0pgz7HYq1wkq",
    "outputId": "daff2a06-d669-48e1-bbde-08a671bf3edc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Personalized Recommendation:\n",
      "\n",
      "Recommended: Dubai Midnight Pistachio Fantasy\n",
      "\n",
      "Reasons:\n",
      "  ‚Ä¢ Elegant presentation and name‚Äîperfect for an anniversary dinner.\n",
      "  ‚Ä¢ Contains white chocolate ganache, offering a refined chocolate element that will please a chocolate lover.\n",
      "  ‚Ä¢ Luxurious pistachio-forward flavor with subtle floral notes, sophisticated enough for a special occasion.\n",
      "  ‚Ä¢ Priced within the requested budget of $50-$80.\n",
      "\n",
      "Message: Hi Michael, for your anniversary dinner, Dubai Midnight Pistachio Fantasy offers an elegant centerpiece with a chocolate accent from the white ganache and a refined pistachio flavor. It fits your $50-$80 budget and pairs well with a celebratory mood. If you‚Äôd prefer something leaner or more chocolate-forward, I can explore additional options.\n"
     ]
    }
   ],
   "source": [
    "class ProductRecommendation(BaseModel):\n",
    "    recommended_product: str = Field(description=\"Name of recommended product\")\n",
    "    reasons: list = Field(description=\"List of reasons for recommendation\")\n",
    "    alternatives: list = Field(description=\"2 alternative products\")\n",
    "    price_range: str = Field(description=\"Expected price range\")\n",
    "    personalized_message: str = Field(description=\"Personalized recommendation message\")\n",
    "\n",
    "recommendation_parser = JsonOutputParser(pydantic_object=ProductRecommendation)\n",
    "\n",
    "recommendation_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are BakeryAI's recommendation engine.\n",
    "    Analyze customer preferences and suggest the perfect product.\n",
    "\n",
    "    Available Products:\n",
    "    {product_catalog}\n",
    "\n",
    "    Provide thoughtful recommendations with clear reasoning.\"\"\"),\n",
    "    (\"human\", \"\"\"Customer: {customer_name}\n",
    "    Occasion: {occasion}\n",
    "    Preferences: {preferences}\n",
    "    Budget: {budget}\n",
    "\n",
    "    {format_instructions}\"\"\")\n",
    "])\n",
    "\n",
    "recommendation_chain = recommendation_template | llm | recommendation_parser\n",
    "\n",
    "# Create product catalog string\n",
    "product_catalog = \"\\n\".join([\n",
    "    f\"- {row['Name']}: {row['Description']} ({row['Energy_kcal']} kcal)\"\n",
    "    for _, row in cakes_df.head(3).iterrows()\n",
    "])\n",
    "\n",
    "# Get recommendation\n",
    "recommendation = recommendation_chain.invoke({\n",
    "    \"product_catalog\": product_catalog,\n",
    "    \"customer_name\": \"Michael\",\n",
    "    \"occasion\": \"Anniversary dinner\",\n",
    "    \"preferences\": \"Loves chocolate, wants something elegant\",\n",
    "    \"budget\": \"$50-80\",\n",
    "    \"format_instructions\": recommendation_parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "print(\"üéØ Personalized Recommendation:\")\n",
    "print(f\"\\nRecommended: {recommendation['recommended_product']}\")\n",
    "print(f\"\\nReasons:\")\n",
    "for reason in recommendation['reasons']:\n",
    "    print(f\"  ‚Ä¢ {reason}\")\n",
    "print(f\"\\nMessage: {recommendation['personalized_message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UP4wRpH1wkr"
   },
   "source": [
    "## 4. Few-Shot Learning for Customer Service\n",
    "\n",
    "Train BakeryAI on example interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32834,
     "status": "ok",
     "timestamp": 1761237846545,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "31iWmtiq1wkr",
    "outputId": "94750665-6568-4e77-d855-470f3f819419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üôã Customer: I have a severe nut allergy, which cakes are safe?\n",
      "üç∞ BakeryAI: I understand‚Äînut allergies are serious, and your safety comes first. We do offer nut-free options and take precautions to prevent cross-contact, but please note that trace amounts can still occur in shared kitchens.\n",
      "\n",
      "How can I help right now?\n",
      "- I can pull up our current nut-free cake options and confirm which ones are prepared with extra precautions.\n",
      "- I can check the ingredients of a specific cake you‚Äôre considering to confirm it contains no nuts.\n",
      "- If this is for an existing order, share your order number and I‚Äôll flag it as nut-free and ensure no nut-containing toppings are used.\n",
      "\n",
      "A few quick questions to tailor my help:\n",
      "- Any flavor or size preferences (vanilla, chocolate, fruit-based, etc.)?\n",
      "- Are there any other allergies I should be aware of?\n",
      "- Is this for a future order or an existing order? If the latter, please share the order number.\n",
      "\n",
      "Would you like me to start by listing our nut-free options?\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üôã Customer: The cake was too sweet for my taste\n",
      "üç∞ BakeryAI: I‚Äôm sorry the cake was too sweet‚Äîthat‚Äôs definitely not ideal. We‚Äôd love to fix this for you. I can:\n",
      "- Arrange a remake with less sugar, or\n",
      "- Suggest a milder flavor for a future order, or\n",
      "- Issue a refund or store credit\n",
      "\n",
      "Please share your order number and tell me which option you‚Äôd prefer. If you‚Äôd like, I can also note a ‚Äúless sweet‚Äù preference for future orders.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "üôã Customer: Do you deliver on Sundays?\n",
      "üç∞ BakeryAI: Yes‚ÄîSunday delivery is available in most areas. Availability depends on your address and chosen time window. Please share your ZIP code or delivery address and your preferred Sunday time, and I‚Äôll check and confirm. If Sundays aren‚Äôt available where you are, I can suggest the next best option or arrange pickup.\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Customer service examples\n",
    "cs_examples = [\n",
    "    {\n",
    "        \"customer_message\": \"My order arrived damaged\",\n",
    "        \"bakery_response\": \"I'm so sorry to hear that! We take great pride in our products and packaging. I'll immediately arrange for a replacement to be delivered within 24 hours at no extra cost. Can you please share your order number?\"\n",
    "    },\n",
    "    {\n",
    "        \"customer_message\": \"Do you have vegan options?\",\n",
    "        \"bakery_response\": \"Yes, we have several delicious vegan options! Our Vegan Chocolate Cake and Lemon Almond Cake are customer favorites. They're made with plant-based ingredients without compromising on taste. Would you like to know more about these options?\"\n",
    "    },\n",
    "    {\n",
    "        \"customer_message\": \"Can I change my delivery time?\",\n",
    "        \"bakery_response\": \"Of course! We understand plans change. Could you please share your order number and preferred new delivery time? I'll do my best to accommodate your request.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create example template\n",
    "example_template = PromptTemplate(\n",
    "    input_variables=[\"customer_message\", \"bakery_response\"],\n",
    "    template=\"Customer: {customer_message}\\nBakeryAI: {bakery_response}\"\n",
    ")\n",
    "\n",
    "# Few-shot prompt\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=cs_examples,\n",
    "    example_prompt=example_template,\n",
    "    prefix=\"\"\"You are BakeryAI customer service. Learn from these examples:\"\"\",\n",
    "    suffix=\"Customer: {input}\\nBakeryAI:\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "# Test few-shot learning\n",
    "test_queries = [\n",
    "    \"I have a severe nut allergy, which cakes are safe?\",\n",
    "    \"The cake was too sweet for my taste\",\n",
    "    \"Do you deliver on Sundays?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    prompt = few_shot_prompt.format(input=query)\n",
    "    response = llm.invoke(prompt)\n",
    "    print(f\"\\nüôã Customer: {query}\")\n",
    "    print(f\"üç∞ BakeryAI: {response.content}\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_03XXYqW1wkr"
   },
   "source": [
    "## 5. Email Generation Templates\n",
    "\n",
    "Automated emails for various scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1761237846576,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "iv25zqzD1wks",
    "outputId": "62d4df46-3a01-4bc9-8180-7b44f74ec317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìß Generated Email:\n",
      "Human: Subject: Order Confirmation #12345 - BakeryAI\n",
      "\n",
      "Dear Sarah,\n",
      "\n",
      "Thank you for your order! We're excited to prepare your delicious treats.\n",
      "\n",
      "Order Details:\n",
      "- 1x Chocolate Truffle Cake\n",
      "- 2x Vanilla Cupcakes\n",
      "\n",
      "Delivery: Friday, March 15 at 2:00 PM\n",
      "Total: $65.00\n",
      "\n",
      "Your order will be freshly prepared and delivered with care.\n",
      "\n",
      "Track your order: [tracking_link]\n",
      "\n",
      "Sweet regards,\n",
      "BakeryAI Team\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Email templates for different scenarios\n",
    "email_templates = {\n",
    "    \"order_confirmation\": ChatPromptTemplate.from_template(\n",
    "        \"\"\"Subject: Order Confirmation #{order_id} - BakeryAI\n",
    "\n",
    "Dear {customer_name},\n",
    "\n",
    "Thank you for your order! We're excited to prepare your delicious treats.\n",
    "\n",
    "Order Details:\n",
    "{order_items}\n",
    "\n",
    "Delivery: {delivery_date} at {delivery_time}\n",
    "Total: ${total_amount}\n",
    "\n",
    "Your order will be freshly prepared and delivered with care.\n",
    "\n",
    "Track your order: [tracking_link]\n",
    "\n",
    "Sweet regards,\n",
    "BakeryAI Team\n",
    "        \"\"\"\n",
    "    ),\n",
    "\n",
    "    \"delivery_reminder\": ChatPromptTemplate.from_template(\n",
    "        \"\"\"Subject: Your BakeryAI Order Arrives Tomorrow! üç∞\n",
    "\n",
    "Hi {customer_name},\n",
    "\n",
    "Exciting news! Your order #{order_id} will be delivered tomorrow {delivery_date}.\n",
    "\n",
    "Items:\n",
    "{order_items}\n",
    "\n",
    "Please ensure someone is available to receive your order.\n",
    "\n",
    "Questions? Reply to this email or call us at [phone].\n",
    "\n",
    "Can't wait for you to enjoy!\n",
    "BakeryAI Team\n",
    "        \"\"\"\n",
    "    ),\n",
    "\n",
    "    \"feedback_request\": ChatPromptTemplate.from_template(\n",
    "        \"\"\"Subject: How Was Your BakeryAI Experience? üåü\n",
    "\n",
    "Hello {customer_name},\n",
    "\n",
    "We hope you enjoyed your recent order of {product_name}!\n",
    "\n",
    "Your feedback helps us improve. Would you mind taking 2 minutes to share your thoughts?\n",
    "\n",
    "[Feedback Survey Link]\n",
    "\n",
    "As a thank you, enjoy 10% off your next order with code: THANKYOU10\n",
    "\n",
    "Warm wishes,\n",
    "BakeryAI Team\n",
    "        \"\"\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# Generate sample emails\n",
    "order_email = email_templates[\"order_confirmation\"].format(\n",
    "    order_id=\"12345\",\n",
    "    customer_name=\"Sarah\",\n",
    "    order_items=\"- 1x Chocolate Truffle Cake\\n- 2x Vanilla Cupcakes\",\n",
    "    delivery_date=\"Friday, March 15\",\n",
    "    delivery_time=\"2:00 PM\",\n",
    "    total_amount=\"65.00\"\n",
    ")\n",
    "\n",
    "print(\"üìß Generated Email:\")\n",
    "print(order_email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJy5dHOn1wks"
   },
   "source": [
    "## 6. Multi-Language Support\n",
    "\n",
    "Translate customer interactions automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28174,
     "status": "ok",
     "timestamp": 1761237874754,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "_Wh71x9g1wks",
    "outputId": "b01df36c-8722-4cad-d31a-0b8057527327"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Spanish]\n",
      "¬°Hola! Gracias por preguntar. Tenemos dos pasteles disponibles para entrega:\n",
      "\n",
      "- Pastel de Trufa de Chocolate\n",
      "- Pastel de Vainilla\n",
      "\n",
      "Ambos listos para entrega. ¬øQu√© tama√±o/porciones necesitas y para qu√© fecha? Si me das la direcci√≥n de entrega, tambi√©n puedo verificar horarios. ¬øQuieres que te ayude a hacer el pedido ahora mismo?\n",
      "------------------------------------------------------------\n",
      "\n",
      "[French]\n",
      "Nous avons deux g√¢teaux disponibles pour livraison:\n",
      "- G√¢teau Truffe au Chocolat\n",
      "- G√¢teau √† la Vanille\n",
      "\n",
      "Souhaitez-vous conna√Ætre les tailles et les prix, ou passer une commande d√®s maintenant ?\n",
      "------------------------------------------------------------\n",
      "\n",
      "[Arabic]\n",
      "Ÿäÿ≥ÿπÿØŸÜÿß ÿ•ÿÆÿ®ÿßÿ±ŸÉ ÿ®ÿ£ŸÜ ŸÑÿØŸäŸÜÿß ÿÆŸäÿßÿ±ŸäŸÜ ŸÖÿ™ÿßÿ≠ŸäŸÜ ŸÑŸÑÿ™ŸàÿµŸäŸÑ ÿßŸÑÿ¢ŸÜ:\n",
      "\n",
      "- ŸÉÿπŸÉÿ© ÿßŸÑÿ™ÿ±ÿßŸÅŸÑ ÿ®ÿßŸÑÿ¥ŸàŸÉŸàŸÑÿßÿ™ÿ© ‚Äî ŸÉÿπŸÉÿ© ÿ¥ŸàŸÉŸàŸÑÿßÿ™ÿ© ÿ∫ŸÜŸäÿ© ŸÖÿπ ÿ≠ÿ¥Ÿàÿ© Ÿàÿ™ÿ∫ÿ∑Ÿäÿ© ÿ™ÿ±ÿßŸÅŸÑ ŸÉÿ±ŸäŸÖŸäÿ©.\n",
      "- ŸÉÿπŸÉÿ© ÿßŸÑŸÅÿßŸÜŸäŸÑÿß Ÿàÿ®ÿ∞Ÿàÿ± ÿßŸÑŸÅÿßŸÜŸäŸÑÿß ‚Äî ŸÉÿπŸÉÿ© ŸÅÿßŸÜŸäŸÑÿß ŸÜÿßÿπŸÖÿ© ŸÖÿπ ŸÜŸÉŸáÿ© ÿßŸÑŸÅÿßŸÜŸäŸÑÿß Ÿàÿ®ÿ∞Ÿàÿ± ÿßŸÑŸÅÿßŸÜŸäŸÑÿß.\n",
      "\n",
      "ŸáŸÑ ÿ™ŸàÿØ ŸÖÿπÿ±ŸÅÿ© ÿßŸÑÿ£ÿ≠ÿ¨ÿßŸÖ ÿßŸÑŸÖÿ™ÿßÿ≠ÿ© ŸàÿßŸÑÿ£ÿ≥ÿπÿßÿ±ÿå ÿ£Ÿà ÿ™ÿ±ÿ∫ÿ® ÿ®ÿπŸÖŸÑ ÿ∑ŸÑÿ® ÿ™ŸàÿµŸäŸÑ ÿßŸÑÿ¢ŸÜÿü\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "multilang_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are BakeryAI's multilingual customer service.\n",
    "    Respond in {language} with the same warm, professional tone.\n",
    "\n",
    "    Context: {context}\"\"\"),\n",
    "    (\"human\", \"{customer_message}\")\n",
    "])\n",
    "\n",
    "multilang_chain = multilang_template | llm | StrOutputParser()\n",
    "\n",
    "# Test in different languages\n",
    "languages = [\"Spanish\", \"French\", \"Arabic\"]\n",
    "context = \"We have Chocolate Truffle Cake and Vanilla Bean Cake available for delivery.\"\n",
    "message = \"What cakes do you have available?\"\n",
    "\n",
    "for lang in languages:\n",
    "    response = multilang_chain.invoke({\n",
    "        \"language\": lang,\n",
    "        \"context\": context,\n",
    "        \"customer_message\": message\n",
    "    })\n",
    "    print(f\"\\n[{lang}]\")\n",
    "    print(response)\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAPxiyJe1wks"
   },
   "source": [
    "## 7. Dynamic Pricing Messages\n",
    "\n",
    "Generate pricing information with promotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10432,
     "status": "ok",
     "timestamp": 1761237885192,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "nIXjqKyb1wks",
    "outputId": "a8078bfa-0b4e-481f-ae8b-959a0ea6a109"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí∞ Pricing Message:\n",
      "Chocolate Truffle Cake‚Äîirresistible value with 15% off using SPRING15 until March 31. Originally $45, now $38.25. Rich ganache, luxurious cocoa‚Äîperfect for any celebration. Buy now and savor the savings.\n"
     ]
    }
   ],
   "source": [
    "def get_current_promotions():\n",
    "    \"\"\"Simulated promotion data\"\"\"\n",
    "    return {\n",
    "        \"active\": True,\n",
    "        \"discount\": 15,\n",
    "        \"code\": \"SPRING15\",\n",
    "        \"expiry\": \"March 31\"\n",
    "    }\n",
    "\n",
    "pricing_template = PromptTemplate(\n",
    "    input_variables=[\"product_name\", \"base_price\"],\n",
    "    template=\"\"\"Product: {product_name}\n",
    "    Base Price: ${base_price}\n",
    "\n",
    "    Current Promotion: {promotion}\n",
    "\n",
    "    Write an engaging price message that highlights the value and encourages purchase.\n",
    "    Keep it under 50 words.\"\"\",\n",
    "    partial_variables={\"promotion\": lambda: str(get_current_promotions())}\n",
    ")\n",
    "\n",
    "pricing_chain = pricing_template | llm | StrOutputParser()\n",
    "\n",
    "price_message = pricing_chain.invoke({\n",
    "    \"product_name\": \"Chocolate Truffle Cake\",\n",
    "    \"base_price\": \"45\"\n",
    "})\n",
    "\n",
    "print(\"üí∞ Pricing Message:\")\n",
    "print(price_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQDX4Zh21wkt"
   },
   "source": [
    "## 8. Chain-of-Thought for Complex Queries\n",
    "\n",
    "Handle multi-step customer requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19158,
     "status": "ok",
     "timestamp": 1761237904355,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "jePO5qXI1wkt",
    "outputId": "cc1dbb62-6797-4fef-984a-855f4653599c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î BakeryAI's Thoughtful Response:\n",
      "Great idea. Here‚Äôs how we can get this sorted for tomorrow.\n",
      "\n",
      "Step 1: Confirm the delivery area\n",
      "- You mentioned ‚Äúdowntown.‚Äù To finalize delivery, please tell me the city (and the exact downtown area or address if you have one). We do deliver to downtown areas in many cities, but I‚Äôll need the city to confirm.\n",
      "\n",
      "Step 2: Pick a crowd-pleasing flavor (tomorrow-ready)\n",
      "All of these flavors have quick 12-hour or shorter delivery times, so they‚Äôre suitable for a tomorrow party:\n",
      "- Red Velvet Cake (12 hr)\n",
      "- Cheesecake (12 hr)\n",
      "- Strawberry Shortcake (12 hr)\n",
      "- Chocolate Truffle Cake (12 hr)\n",
      "- Black Forest Cake (12 hr)\n",
      "- Tiramisu Cake (12 hr)\n",
      "\n",
      "If you want a single flavor that tends to please most people, Red Velvet Cake, Cheesecake, or Strawberry Shortcake are strong, crowd-pleasing choices.\n",
      "\n",
      "Step 3: Practical options (for a typical party)\n",
      "Tell me your guest count (or desired size), and I‚Äôll suggest the appropriate size. A common starting option is an 8-inch cake that serves about 12‚Äì16 people.\n",
      "\n",
      "- Option A: 8\" Red Velvet Cake (serves ~12‚Äì16)\n",
      "- Option B: 8\" Cheesecake (serves ~12‚Äì16)\n",
      "- Option C: 8\" Strawberry Shortcake (serves ~12‚Äì16)\n",
      "(If you need more servings or a second flavor for variety, I can suggest a two-cake setup.)\n",
      "\n",
      "Step 4: Gather what I need to place the order\n",
      "- City and exact downtown area (and delivery address if you have it)\n",
      "- Date and preferred delivery window tomorrow\n",
      "- Flavor(s) and size(s)\n",
      "- Any dietary considerations (e.g., nut-free, gluten-free)\n",
      "- Any message for the cake (name, birthday greeting, etc.)\n",
      "\n",
      "If you‚Äôd like, I can propose a single-flavor option now and hold a backup flavor in case you want variety. Tell me your city and the number of guests, and I‚Äôll tailor the best tomorrow-ready option and confirm delivery feasibility.\n"
     ]
    }
   ],
   "source": [
    "cot_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are BakeryAI's problem-solving assistant.\n",
    "    Break down complex requests step-by-step.\n",
    "\n",
    "    Available Data:\n",
    "    {data_context}\n",
    "\n",
    "    Think through the problem:\n",
    "    1. Understand what the customer needs\n",
    "    2. Check what's available\n",
    "    3. Provide a comprehensive solution\"\"\"),\n",
    "    (\"human\", \"{customer_request}\")\n",
    "])\n",
    "\n",
    "cot_chain = cot_template | llm | StrOutputParser()\n",
    "\n",
    "# Complex request\n",
    "data_context = f\"\"\"\n",
    "Products: {cakes_df[['Name', 'Delivery_time_hr']].to_string()}\n",
    "Today's date: {datetime.now().strftime('%Y-%m-%d')}\n",
    "\"\"\"\n",
    "\n",
    "complex_request = \"\"\"\n",
    "I need a cake for tomorrow's party, but I also need to know if you can deliver\n",
    "to downtown, and I'm not sure what flavor most people like. Can you help?\n",
    "\"\"\"\n",
    "\n",
    "response = cot_chain.invoke({\n",
    "    \"data_context\": data_context,\n",
    "    \"customer_request\": complex_request\n",
    "})\n",
    "\n",
    "print(\"ü§î BakeryAI's Thoughtful Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5tiVZz-1wkt"
   },
   "source": [
    "## üéØ Exercise 5: Build a Complete Order Flow\n",
    "\n",
    "**Task**: Create a multi-step order template system:\n",
    "1. Product selection with recommendations\n",
    "2. Customization options (size, message, etc.)\n",
    "3. Delivery details collection\n",
    "4. Order confirmation generation\n",
    "5. Follow-up email scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1761237904370,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "GS8_B_kt1wkt"
   },
   "outputs": [],
   "source": [
    "class OrderFlowManager:\n",
    "    def __init__(self):\n",
    "        self.order_data = {}\n",
    "\n",
    "    def step1_product_selection(self, customer_preferences):\n",
    "        \"\"\"Recommend products based on preferences\"\"\"\n",
    "        # TODO: Implement product recommendation\n",
    "        pass\n",
    "\n",
    "    def step2_customization(self, product, custom_requests):\n",
    "        \"\"\"Handle customization options\"\"\"\n",
    "        # TODO: Process customizations\n",
    "        pass\n",
    "\n",
    "    def step3_delivery_details(self, delivery_info):\n",
    "        \"\"\"Collect and validate delivery information\"\"\"\n",
    "        # TODO: Validate delivery details\n",
    "        pass\n",
    "\n",
    "    def step4_generate_confirmation(self):\n",
    "        \"\"\"Generate order confirmation\"\"\"\n",
    "        # TODO: Create confirmation with all details\n",
    "        pass\n",
    "\n",
    "    def step5_schedule_followup(self, days_after=3):\n",
    "        \"\"\"Schedule follow-up email\"\"\"\n",
    "        # TODO: Generate follow-up email content\n",
    "        pass\n",
    "\n",
    "# Test the order flow\n",
    "# order_manager = OrderFlowManager()\n",
    "# order_manager.step1_product_selection(\"chocolate lover, birthday party\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMqZkxkd1wkt"
   },
   "source": [
    "## üéØ Exercise 6: A/B Testing Response Templates\n",
    "\n",
    "**Task**: Create a system to test different prompt templates:\n",
    "1. Define 2-3 variations of a customer service response\n",
    "2. Generate responses from each template\n",
    "3. Compare effectiveness (length, tone, completeness)\n",
    "4. Recommend the best version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1761237904380,
     "user": {
      "displayName": "Ivan Reznikov",
      "userId": "03906939862966425294"
     },
     "user_tz": -240
    },
    "id": "cMmN8yJP1wkt"
   },
   "outputs": [],
   "source": [
    "def ab_test_templates(scenario, template_variants):\n",
    "    \"\"\"\n",
    "    Test multiple template variations\n",
    "\n",
    "    Args:\n",
    "        scenario: Customer service scenario\n",
    "        template_variants: List of different prompt templates\n",
    "\n",
    "    Returns:\n",
    "        Analysis of each template's effectiveness\n",
    "    \"\"\"\n",
    "    # TODO: Implement A/B testing logic\n",
    "    pass\n",
    "\n",
    "# Example scenario\n",
    "# scenario = \"Customer wants to cancel an order placed 2 hours ago\"\n",
    "# templates = [\n",
    "#     \"template_variant_1: formal and brief\",\n",
    "#     \"template_variant_2: warm and detailed\",\n",
    "#     \"template_variant_3: problem-solving focused\"\n",
    "# ]\n",
    "# ab_test_templates(scenario, templates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBdgqgXy1wkt"
   },
   "source": [
    "## Summary: What We Built\n",
    "\n",
    "### ‚úÖ Session 1.3 Achievements:\n",
    "\n",
    "1. **Prompt Templates**: Reusable templates for consistency\n",
    "2. **Order System**: Structured order confirmations\n",
    "3. **Smart Recommendations**: JSON-formatted suggestions with reasoning\n",
    "4. **Few-Shot Learning**: Train on example interactions\n",
    "5. **Email Automation**: Professional email generation\n",
    "6. **Multi-Language**: Serve global customers\n",
    "7. **Complex Queries**: Chain-of-thought for problem-solving\n",
    "\n",
    "### üöÄ BakeryAI Progress: 60%\n",
    "\n",
    "```\n",
    "[‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 60%\n",
    "```\n",
    "\n",
    "### Key Capabilities Added:\n",
    "\n",
    "‚ú® **Consistent Brand Voice**: Every interaction feels professional  \n",
    "‚ú® **Structured Outputs**: JSON for easy integration  \n",
    "‚ú® **Automated Communications**: Orders, reminders, feedback  \n",
    "‚ú® **Global Reach**: Multi-language support  \n",
    "‚ú® **Smart Problem Solving**: Handle complex customer requests  \n",
    "\n",
    "### Next: Notebook 1.4\n",
    "\n",
    "We'll add **conversation memory** so BakeryAI can:\n",
    "- Remember customer preferences across conversations\n",
    "- Handle multi-turn order taking\n",
    "- Maintain context throughout a session\n",
    "- Provide personalized experiences"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
