{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udf1f BONUS: Deep Agents with Reflection Patterns\n",
        "\n",
        "## \ud83c\udfaf Advanced Agentic AI with Self-Reflection\n",
        "\n",
        "### What Are Deep Agents?\n",
        "\n",
        "**Deep Agents** are an advanced agent architecture designed for handling complex, multi-step tasks that require:\n",
        "- \ud83e\udde0 **Planning capability**: Break down large tasks into subtasks\n",
        "- \ud83d\udcad **Self-reflection**: Critique and improve their own outputs\n",
        "- \ud83d\udd04 **Context management**: Retain information across long conversations\n",
        "- \ud83e\udd16 **Sub-agent delegation**: Launch specialized agents for focused tasks\n",
        "- \ud83d\udcc1 **File system integration**: Persist and retrieve memory\n",
        "\n",
        "### Real-World Applications:\n",
        "\n",
        "- \ud83d\udd0d **Deep Research**: Multi-step investigation and synthesis\n",
        "- \ud83d\udcbb **Code Generation**: Generate, test, and refine code\n",
        "- \ud83d\udcca **Data Analysis**: Complex analytical workflows\n",
        "- \ud83d\udcdd **Content Creation**: Draft, review, and improve writing\n",
        "\n",
        "### Reflection Pattern:\n",
        "\n",
        "Reflection is a prompting strategy where an LLM:\n",
        "1. **Generates** an initial response\n",
        "2. **Critiques** its own work\n",
        "3. **Revises** based on self-assessment\n",
        "4. **Repeats** until quality standards are met\n",
        "\n",
        "```\n",
        "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "\u2502   Generate  \u2502\n",
        "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "       \u2502\n",
        "       \u25bc\n",
        "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "\u2502   Reflect   \u2502 \u25c4\u2500\u2500\u2510\n",
        "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n",
        "       \u2502           \u2502\n",
        "       \u25bc           \u2502\n",
        "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n",
        "\u2502   Revise    \u2502\u2500\u2500\u2500\u2500\u2518\n",
        "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "       \u2502\n",
        "       \u25bc\n",
        "    Quality\n",
        " Threshold Met?\n",
        "```\n",
        "\n",
        "Let's build advanced reflection agents for BakeryAI! \ud83d\ude80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q langgraph langchain langchain-openai\n",
        "!pip install -q python-dotenv tavily-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import TypedDict, Annotated, List\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "\n",
        "print(\"\u2705 Environment ready for Deep Agents!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Basic Reflection Pattern\n",
        "\n",
        "Start with simple generate \u2192 reflect \u2192 revise cycle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReflectionState(TypedDict):\n",
        "    task: str\n",
        "    generation: str\n",
        "    reflection: str\n",
        "    revision_count: int\n",
        "    max_revisions: int\n",
        "    final_output: str\n",
        "\n",
        "def generate_content(state: ReflectionState) -> ReflectionState:\n",
        "    \"\"\"Generate initial content\"\"\"\n",
        "    print(f\"\\n\ud83d\udcdd Generating content (attempt {state['revision_count'] + 1})...\")\n",
        "    \n",
        "    if state['revision_count'] == 0:\n",
        "        # Initial generation\n",
        "        prompt = f\"\"\"Create a professional response for this task:\n",
        "        \n",
        "        Task: {state['task']}\n",
        "        \n",
        "        Provide a complete, well-structured response.\"\"\"\n",
        "    else:\n",
        "        # Revision based on reflection\n",
        "        prompt = f\"\"\"Improve this response based on the critique:\n",
        "        \n",
        "        Original Task: {state['task']}\n",
        "        \n",
        "        Previous Response:\n",
        "        {state['generation']}\n",
        "        \n",
        "        Critique:\n",
        "        {state['reflection']}\n",
        "        \n",
        "        Provide an improved version that addresses the critique.\"\"\"\n",
        "    \n",
        "    response = llm.invoke(prompt)\n",
        "    state['generation'] = response.content\n",
        "    \n",
        "    print(f\"   Generated {len(response.content)} characters\")\n",
        "    return state\n",
        "\n",
        "def reflect_on_content(state: ReflectionState) -> ReflectionState:\n",
        "    \"\"\"Reflect on generated content\"\"\"\n",
        "    print(\"\\n\ud83e\udd14 Reflecting on content...\")\n",
        "    \n",
        "    reflection_prompt = f\"\"\"You are a critic. Analyze this response:\n",
        "    \n",
        "    Task: {state['task']}\n",
        "    \n",
        "    Response:\n",
        "    {state['generation']}\n",
        "    \n",
        "    Provide constructive criticism focusing on:\n",
        "    1. Completeness: Does it fully address the task?\n",
        "    2. Clarity: Is it clear and well-structured?\n",
        "    3. Accuracy: Is the information correct?\n",
        "    4. Professionalism: Is the tone appropriate?\n",
        "    \n",
        "    If the response is excellent, say \"APPROVED\".\n",
        "    Otherwise, provide specific improvements needed.\"\"\"\n",
        "    \n",
        "    critique = llm.invoke(reflection_prompt)\n",
        "    state['reflection'] = critique.content\n",
        "    \n",
        "    print(f\"   Critique: {critique.content[:100]}...\")\n",
        "    return state\n",
        "\n",
        "def should_continue(state: ReflectionState) -> str:\n",
        "    \"\"\"Decide whether to continue revising\"\"\"\n",
        "    \n",
        "    # Check if approved\n",
        "    if \"APPROVED\" in state['reflection'].upper():\n",
        "        print(\"\\n\u2705 Content APPROVED!\")\n",
        "        return \"finalize\"\n",
        "    \n",
        "    # Check revision limit\n",
        "    state['revision_count'] += 1\n",
        "    if state['revision_count'] >= state['max_revisions']:\n",
        "        print(f\"\\n\u23f8\ufe0f  Max revisions ({state['max_revisions']}) reached\")\n",
        "        return \"finalize\"\n",
        "    \n",
        "    print(\"\\n\ud83d\udd04 Revising...\")\n",
        "    return \"revise\"\n",
        "\n",
        "def finalize_output(state: ReflectionState) -> ReflectionState:\n",
        "    \"\"\"Finalize the output\"\"\"\n",
        "    state['final_output'] = state['generation']\n",
        "    print(\"\\n\ud83c\udf89 Final output ready!\")\n",
        "    return state\n",
        "\n",
        "# Build reflection graph\n",
        "reflection_graph = StateGraph(ReflectionState)\n",
        "\n",
        "reflection_graph.add_node(\"generate\", generate_content)\n",
        "reflection_graph.add_node(\"reflect\", reflect_on_content)\n",
        "reflection_graph.add_node(\"finalize\", finalize_output)\n",
        "\n",
        "reflection_graph.set_entry_point(\"generate\")\n",
        "\n",
        "reflection_graph.add_edge(\"generate\", \"reflect\")\n",
        "\n",
        "reflection_graph.add_conditional_edges(\n",
        "    \"reflect\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"revise\": \"generate\",\n",
        "        \"finalize\": \"finalize\"\n",
        "    }\n",
        ")\n",
        "\n",
        "reflection_graph.add_edge(\"finalize\", END)\n",
        "\n",
        "reflection_app = reflection_graph.compile()\n",
        "\n",
        "print(\"\u2705 Basic reflection agent created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test basic reflection\n",
        "print(\"\ud83e\uddea Testing Basic Reflection Agent\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "task = \"\"\"Write a customer email responding to a complaint about a delayed cake order. \n",
        "The order was delayed due to supply chain issues with specialty ingredients.\"\"\"\n",
        "\n",
        "result = reflection_app.invoke({\n",
        "    \"task\": task,\n",
        "    \"generation\": \"\",\n",
        "    \"reflection\": \"\",\n",
        "    \"revision_count\": 0,\n",
        "    \"max_revisions\": 3,\n",
        "    \"final_output\": \"\"\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\ud83d\udce7 FINAL EMAIL:\")\n",
        "print(\"=\"*70)\n",
        "print(result['final_output'])\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"Revisions made: {result['revision_count']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Reflexion Agent with External Tools\n",
        "\n",
        "Advanced reflection with tool usage and grounded critique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "@tool\n",
        "def check_bakery_policy(policy_type: str) -> str:\n",
        "    \"\"\"Check BakeryAI policies\n",
        "    \n",
        "    Args:\n",
        "        policy_type: Type of policy (refund, delivery, allergen, etc.)\n",
        "    \"\"\"\n",
        "    policies = {\n",
        "        \"refund\": \"Full refund within 24 hours of order. Store credit after 24 hours.\",\n",
        "        \"delivery\": \"Free delivery on orders over $100. $10 fee for orders under $100.\",\n",
        "        \"allergen\": \"All products may contain traces of nuts, dairy, eggs, wheat.\",\n",
        "        \"cancellation\": \"Cancel up to 12 hours before delivery for full refund.\"\n",
        "    }\n",
        "    return policies.get(policy_type.lower(), \"Policy not found\")\n",
        "\n",
        "@tool\n",
        "def check_ingredient_availability(ingredient: str) -> str:\n",
        "    \"\"\"Check ingredient availability\n",
        "    \n",
        "    Args:\n",
        "        ingredient: Name of ingredient\n",
        "    \"\"\"\n",
        "    import random\n",
        "    available = random.random() > 0.3\n",
        "    if available:\n",
        "        return f\"{ingredient} is currently in stock\"\n",
        "    return f\"{ingredient} is temporarily out of stock - expected in 2-3 days\"\n",
        "\n",
        "tools = [check_bakery_policy, check_ingredient_availability]\n",
        "\n",
        "# Optional: Add web search\n",
        "try:\n",
        "    web_search = TavilySearchResults(max_results=2)\n",
        "    tools.append(web_search)\n",
        "    print(\"\u2705 Web search tool added\")\n",
        "except:\n",
        "    print(\"\u26a0\ufe0f  Tavily not configured (optional)\")\n",
        "\n",
        "print(f\"\u2705 {len(tools)} tools available for reflexion agent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
        "\n",
        "class ReflexionState(TypedDict):\n",
        "    task: str\n",
        "    draft: str\n",
        "    search_queries: List[str]\n",
        "    tool_results: List[str]\n",
        "    critique: str\n",
        "    revision: str\n",
        "    iterations: int\n",
        "    max_iterations: int\n",
        "\n",
        "def draft_response(state: ReflexionState) -> ReflexionState:\n",
        "    \"\"\"Generate initial draft with tool usage\"\"\"\n",
        "    print(f\"\\n\ud83d\udcdd Drafting response (iteration {state['iterations'] + 1})...\")\n",
        "    \n",
        "    if state['iterations'] == 0:\n",
        "        # Initial draft\n",
        "        prompt_template = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"You are a helpful BakeryAI assistant.\n",
        "            Draft a response to the customer's request.\n",
        "            Use tools to verify policies and check information.\n",
        "            \n",
        "            Generate search queries if you need more information.\"\"\"),\n",
        "            (\"human\", \"{input}\"),\n",
        "            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
        "        ])\n",
        "        \n",
        "        agent = create_openai_functions_agent(llm, tools, prompt_template)\n",
        "        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
        "        \n",
        "        result = agent_executor.invoke({\"input\": state['task']})\n",
        "        state['draft'] = result['output']\n",
        "    else:\n",
        "        # Revision based on critique\n",
        "        revision_prompt = f\"\"\"Improve this draft based on the critique:\n",
        "        \n",
        "        Task: {state['task']}\n",
        "        \n",
        "        Previous Draft:\n",
        "        {state['draft']}\n",
        "        \n",
        "        Critique:\n",
        "        {state['critique']}\n",
        "        \n",
        "        Tool Results:\n",
        "        {chr(10).join(state['tool_results'])}\n",
        "        \n",
        "        Provide improved version addressing all issues.\"\"\"\n",
        "        \n",
        "        response = llm.invoke(revision_prompt)\n",
        "        state['draft'] = response.content\n",
        "    \n",
        "    print(f\"   Draft length: {len(state['draft'])} chars\")\n",
        "    return state\n",
        "\n",
        "def execute_searches(state: ReflexionState) -> ReflexionState:\n",
        "    \"\"\"Execute tool calls for verification\"\"\"\n",
        "    print(\"\\n\ud83d\udd0d Executing verification checks...\")\n",
        "    \n",
        "    # Simulate tool execution\n",
        "    tool_results = []\n",
        "    \n",
        "    # Check relevant policies\n",
        "    for policy in [\"refund\", \"delivery\"]:\n",
        "        result = check_bakery_policy.invoke({\"policy_type\": policy})\n",
        "        tool_results.append(f\"{policy.title()} Policy: {result}\")\n",
        "    \n",
        "    state['tool_results'] = tool_results\n",
        "    print(f\"   Retrieved {len(tool_results)} tool results\")\n",
        "    return state\n",
        "\n",
        "def critique_draft(state: ReflexionState) -> ReflexionState:\n",
        "    \"\"\"Critique draft with external grounding\"\"\"\n",
        "    print(\"\\n\ud83d\udd0e Critiquing draft...\")\n",
        "    \n",
        "    critique_prompt = f\"\"\"You are an expert critic. Analyze this customer service response:\n",
        "    \n",
        "    Task: {state['task']}\n",
        "    \n",
        "    Draft Response:\n",
        "    {state['draft']}\n",
        "    \n",
        "    Verified Facts:\n",
        "    {chr(10).join(state['tool_results'])}\n",
        "    \n",
        "    Critique the response on:\n",
        "    1. **Accuracy**: Does it match verified policies?\n",
        "    2. **Completeness**: Does it address all aspects?\n",
        "    3. **Tone**: Is it empathetic and professional?\n",
        "    4. **Citations**: Does it reference policies correctly?\n",
        "    \n",
        "    If excellent, say \"APPROVED\".\n",
        "    Otherwise, enumerate specific issues to fix.\"\"\"\n",
        "    \n",
        "    critique = llm.invoke(critique_prompt)\n",
        "    state['critique'] = critique.content\n",
        "    \n",
        "    print(f\"   Critique: {critique.content[:80]}...\")\n",
        "    return state\n",
        "\n",
        "def should_revise(state: ReflexionState) -> str:\n",
        "    \"\"\"Decide whether to revise\"\"\"\n",
        "    if \"APPROVED\" in state['critique'].upper():\n",
        "        print(\"\\n\u2705 Draft APPROVED!\")\n",
        "        return END\n",
        "    \n",
        "    state['iterations'] += 1\n",
        "    if state['iterations'] >= state['max_iterations']:\n",
        "        print(f\"\\n\u23f8\ufe0f  Max iterations ({state['max_iterations']}) reached\")\n",
        "        return END\n",
        "    \n",
        "    print(\"\\n\ud83d\udd04 Needs revision\")\n",
        "    return \"draft\"\n",
        "\n",
        "# Build Reflexion graph\n",
        "reflexion_graph = StateGraph(ReflexionState)\n",
        "\n",
        "reflexion_graph.add_node(\"draft\", draft_response)\n",
        "reflexion_graph.add_node(\"search\", execute_searches)\n",
        "reflexion_graph.add_node(\"critique\", critique_draft)\n",
        "\n",
        "reflexion_graph.set_entry_point(\"draft\")\n",
        "\n",
        "reflexion_graph.add_edge(\"draft\", \"search\")\n",
        "reflexion_graph.add_edge(\"search\", \"critique\")\n",
        "\n",
        "reflexion_graph.add_conditional_edges(\n",
        "    \"critique\",\n",
        "    should_revise,\n",
        "    {\n",
        "        \"draft\": \"draft\",\n",
        "        END: END\n",
        "    }\n",
        ")\n",
        "\n",
        "reflexion_app = reflexion_graph.compile()\n",
        "\n",
        "print(\"\u2705 Reflexion agent with tools created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Reflexion agent\n",
        "print(\"\ud83e\uddea Testing Reflexion Agent with Tools\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "task = \"\"\"A customer wants to cancel their wedding cake order that's scheduled \n",
        "for delivery tomorrow. They're asking about refund options. Write a response.\"\"\"\n",
        "\n",
        "result = reflexion_app.invoke({\n",
        "    \"task\": task,\n",
        "    \"draft\": \"\",\n",
        "    \"search_queries\": [],\n",
        "    \"tool_results\": [],\n",
        "    \"critique\": \"\",\n",
        "    \"revision\": \"\",\n",
        "    \"iterations\": 0,\n",
        "    \"max_iterations\": 3\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\ud83d\udce7 FINAL RESPONSE:\")\n",
        "print(\"=\"*70)\n",
        "print(result['draft'])\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\\n\ud83d\udccb VERIFICATION:\")\n",
        "for tool_result in result['tool_results']:\n",
        "    print(f\"  \u2022 {tool_result}\")\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"Iterations: {result['iterations']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Deep Agent with Planning & Sub-Agents\n",
        "\n",
        "Full deep agent implementation with task decomposition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DeepAgentState(TypedDict):\n",
        "    objective: str\n",
        "    plan: List[str]\n",
        "    current_step: int\n",
        "    step_results: List[str]\n",
        "    reflections: List[str]\n",
        "    final_output: str\n",
        "\n",
        "def create_plan(state: DeepAgentState) -> DeepAgentState:\n",
        "    \"\"\"Decompose objective into steps\"\"\"\n",
        "    print(\"\\n\ud83d\udccb Creating execution plan...\")\n",
        "    \n",
        "    planning_prompt = f\"\"\"Break down this objective into 3-5 concrete steps:\n",
        "    \n",
        "    Objective: {state['objective']}\n",
        "    \n",
        "    Provide a numbered list of specific, actionable steps.\n",
        "    Each step should be clear and measurable.\"\"\"\n",
        "    \n",
        "    response = llm.invoke(planning_prompt)\n",
        "    \n",
        "    # Parse steps\n",
        "    steps = []\n",
        "    for line in response.content.split('\\n'):\n",
        "        line = line.strip()\n",
        "        if line and (line[0].isdigit() or line.startswith('-') or line.startswith('*')):\n",
        "            # Remove numbering\n",
        "            step = line.lstrip('0123456789.-* ')\n",
        "            if step:\n",
        "                steps.append(step)\n",
        "    \n",
        "    state['plan'] = steps\n",
        "    state['current_step'] = 0\n",
        "    \n",
        "    print(\"\\n\ud83d\udccc Execution Plan:\")\n",
        "    for i, step in enumerate(steps, 1):\n",
        "        print(f\"   {i}. {step}\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "def execute_step(state: DeepAgentState) -> DeepAgentState:\n",
        "    \"\"\"Execute current step with sub-agent\"\"\"\n",
        "    step_num = state['current_step']\n",
        "    step = state['plan'][step_num]\n",
        "    \n",
        "    print(f\"\\n\u2699\ufe0f  Executing Step {step_num + 1}/{len(state['plan'])}: {step}\")\n",
        "    \n",
        "    # Create specialized sub-agent for this step\n",
        "    execution_prompt = f\"\"\"You are a specialized sub-agent for this task:\n",
        "    \n",
        "    Overall Objective: {state['objective']}\n",
        "    Current Step: {step}\n",
        "    \n",
        "    Previous Results:\n",
        "    {chr(10).join([f\"Step {i+1}: {r}\" for i, r in enumerate(state['step_results'])])}\n",
        "    \n",
        "    Execute this step and provide concrete results.\n",
        "    Be specific and actionable.\"\"\"\n",
        "    \n",
        "    result = llm.invoke(execution_prompt)\n",
        "    state['step_results'].append(result.content)\n",
        "    \n",
        "    print(f\"   \u2713 Result: {result.content[:80]}...\")\n",
        "    return state\n",
        "\n",
        "def reflect_on_progress(state: DeepAgentState) -> DeepAgentState:\n",
        "    \"\"\"Reflect on step execution\"\"\"\n",
        "    print(\"\\n\ud83e\udd14 Reflecting on progress...\")\n",
        "    \n",
        "    reflection_prompt = f\"\"\"Reflect on the execution of this step:\n",
        "    \n",
        "    Step: {state['plan'][state['current_step']]}\n",
        "    Result: {state['step_results'][-1]}\n",
        "    \n",
        "    Assess:\n",
        "    1. Was the step completed successfully?\n",
        "    2. Is the result sufficient for proceeding?\n",
        "    3. Any issues or gaps?\n",
        "    \n",
        "    Provide brief reflection (2-3 sentences).\"\"\"\n",
        "    \n",
        "    reflection = llm.invoke(reflection_prompt)\n",
        "    state['reflections'].append(reflection.content)\n",
        "    \n",
        "    print(f\"   Reflection: {reflection.content[:60]}...\")\n",
        "    return state\n",
        "\n",
        "def should_continue_plan(state: DeepAgentState) -> str:\n",
        "    \"\"\"Check if more steps remain\"\"\"\n",
        "    state['current_step'] += 1\n",
        "    \n",
        "    if state['current_step'] < len(state['plan']):\n",
        "        return \"execute\"\n",
        "    \n",
        "    print(\"\\n\u2705 All steps completed!\")\n",
        "    return \"synthesize\"\n",
        "\n",
        "def synthesize_results(state: DeepAgentState) -> DeepAgentState:\n",
        "    \"\"\"Synthesize all results into final output\"\"\"\n",
        "    print(\"\\n\ud83c\udfaf Synthesizing final output...\")\n",
        "    \n",
        "    synthesis_prompt = f\"\"\"Synthesize all step results into a comprehensive final output:\n",
        "    \n",
        "    Objective: {state['objective']}\n",
        "    \n",
        "    Execution Plan & Results:\n",
        "    {chr(10).join([f\"Step {i+1}: {state['plan'][i]}\\nResult: {state['step_results'][i]}\\n\" \n",
        "                   for i in range(len(state['plan']))])}\n",
        "    \n",
        "    Reflections:\n",
        "    {chr(10).join([f\"{i+1}. {r}\" for i, r in enumerate(state['reflections'])])}\n",
        "    \n",
        "    Provide a complete, coherent final output that achieves the objective.\"\"\"\n",
        "    \n",
        "    final = llm.invoke(synthesis_prompt)\n",
        "    state['final_output'] = final.content\n",
        "    \n",
        "    print(\"   \u2713 Final output generated\")\n",
        "    return state\n",
        "\n",
        "# Build Deep Agent graph\n",
        "deep_agent_graph = StateGraph(DeepAgentState)\n",
        "\n",
        "deep_agent_graph.add_node(\"plan\", create_plan)\n",
        "deep_agent_graph.add_node(\"execute\", execute_step)\n",
        "deep_agent_graph.add_node(\"reflect\", reflect_on_progress)\n",
        "deep_agent_graph.add_node(\"synthesize\", synthesize_results)\n",
        "\n",
        "deep_agent_graph.set_entry_point(\"plan\")\n",
        "\n",
        "deep_agent_graph.add_edge(\"plan\", \"execute\")\n",
        "deep_agent_graph.add_edge(\"execute\", \"reflect\")\n",
        "\n",
        "deep_agent_graph.add_conditional_edges(\n",
        "    \"reflect\",\n",
        "    should_continue_plan,\n",
        "    {\n",
        "        \"execute\": \"execute\",\n",
        "        \"synthesize\": \"synthesize\"\n",
        "    }\n",
        ")\n",
        "\n",
        "deep_agent_graph.add_edge(\"synthesize\", END)\n",
        "\n",
        "deep_agent = deep_agent_graph.compile()\n",
        "\n",
        "print(\"\u2705 Deep Agent with planning & reflection created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Deep Agent\n",
        "print(\"\ud83e\uddea Testing Deep Agent\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "objective = \"\"\"Create a comprehensive marketing campaign for BakeryAI's \n",
        "new gluten-free product line, including social media strategy, \n",
        "email campaigns, and in-store promotions.\"\"\"\n",
        "\n",
        "result = deep_agent.invoke({\n",
        "    \"objective\": objective,\n",
        "    \"plan\": [],\n",
        "    \"current_step\": 0,\n",
        "    \"step_results\": [],\n",
        "    \"reflections\": [],\n",
        "    \"final_output\": \"\"\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\ud83c\udfaf FINAL MARKETING CAMPAIGN:\")\n",
        "print(\"=\"*70)\n",
        "print(result['final_output'])\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"Steps executed: {len(result['step_results'])}\")\n",
        "print(f\"Reflections made: {len(result['reflections'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. BakeryAI Deep Research Agent\n",
        "\n",
        "Complete deep agent for research and analysis tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResearchState(TypedDict):\n",
        "    research_question: str\n",
        "    research_plan: List[str]\n",
        "    findings: List[dict]\n",
        "    synthesis: str\n",
        "    quality_score: float\n",
        "\n",
        "def research_agent_demo():\n",
        "    \"\"\"Demonstrate research agent capabilities\"\"\"\n",
        "    \n",
        "    print(\"\\n\ud83d\udd2c DEEP RESEARCH AGENT DEMO\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    research_question = \"\"\"What are the emerging trends in gluten-free baking \n",
        "    for 2025, and how should BakeryAI adapt its product line?\"\"\"\n",
        "    \n",
        "    print(f\"\\n\u2753 Research Question:\\n{research_question}\")\n",
        "    \n",
        "    # Simulate research process\n",
        "    print(\"\\n\ud83d\udccb Research Plan:\")\n",
        "    plan = [\n",
        "        \"Survey current gluten-free baking trends\",\n",
        "        \"Analyze customer preferences and dietary requirements\",\n",
        "        \"Review competitor offerings\",\n",
        "        \"Identify ingredient innovations\",\n",
        "        \"Synthesize recommendations\"\n",
        "    ]\n",
        "    \n",
        "    for i, step in enumerate(plan, 1):\n",
        "        print(f\"   {i}. {step}\")\n",
        "    \n",
        "    print(\"\\n\ud83d\udd0d Key Findings:\")\n",
        "    findings = [\n",
        "        \"Clean label ingredients trending (almond flour, coconut flour)\",\n",
        "        \"Protein-enriched gluten-free products gaining popularity\",\n",
        "        \"Customers willing to pay 15-20% premium for quality\",\n",
        "        \"Cross-contamination concerns require dedicated facilities\"\n",
        "    ]\n",
        "    \n",
        "    for finding in findings:\n",
        "        print(f\"   \u2022 {finding}\")\n",
        "    \n",
        "    print(\"\\n\ud83d\udca1 Recommendations:\")\n",
        "    recommendations = [\n",
        "        \"Launch premium gluten-free line with almond/coconut flour base\",\n",
        "        \"Invest in dedicated gluten-free production space\",\n",
        "        \"Partner with nutritionist for protein-enriched recipes\",\n",
        "        \"Implement strict allergen testing and certification\"\n",
        "    ]\n",
        "    \n",
        "    for rec in recommendations:\n",
        "        print(f\"   \u2713 {rec}\")\n",
        "    \n",
        "    print(\"\\n\u2705 Research Complete!\")\n",
        "\n",
        "research_agent_demo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Key Patterns Comparison\n",
        "\n",
        "Understanding when to use each pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "comparison = \"\"\"\n",
        "\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n",
        "\u2502                 AGENTIC AI PATTERNS COMPARISON                      \u2502\n",
        "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
        "\u2502 Pattern         \u2502 Best For                                          \u2502\n",
        "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
        "\u2502 Basic           \u2502 \u2022 Quick responses                                 \u2502\n",
        "\u2502 Reflection      \u2502 \u2022 Quality more important than speed               \u2502\n",
        "\u2502                 \u2502 \u2022 Customer-facing content                         \u2502\n",
        "\u2502                 \u2502 \u2022 Email, documents, reports                       \u2502\n",
        "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
        "\u2502 Reflexion       \u2502 \u2022 Factual accuracy critical                       \u2502\n",
        "\u2502 with Tools      \u2502 \u2022 Policy compliance required                      \u2502\n",
        "\u2502                 \u2502 \u2022 External verification needed                    \u2502\n",
        "\u2502                 \u2502 \u2022 Customer service, legal docs                    \u2502\n",
        "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
        "\u2502 Deep Agent      \u2502 \u2022 Complex, multi-step tasks                       \u2502\n",
        "\u2502 with Planning   \u2502 \u2022 Research and analysis                           \u2502\n",
        "\u2502                 \u2502 \u2022 Strategy development                            \u2502\n",
        "\u2502                 \u2502 \u2022 Long-running workflows                          \u2502\n",
        "\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n",
        "\u2502 Tree Search     \u2502 \u2022 Multiple solution paths                         \u2502\n",
        "\u2502 (LATS)          \u2502 \u2022 Code generation                                 \u2502\n",
        "\u2502                 \u2502 \u2022 Optimization problems                           \u2502\n",
        "\u2502                 \u2502 \u2022 Creative ideation                               \u2502\n",
        "\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "\n",
        "Performance Metrics:\n",
        "\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n",
        "Pattern           Speed    Quality   Cost      Use Case\n",
        "\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n",
        "Basic             \u2605\u2605\u2605\u2605\u2605   \u2605\u2605\u2605\u2606\u2606    $         Simple tasks\n",
        "Reflection        \u2605\u2605\u2605\u2606\u2606   \u2605\u2605\u2605\u2605\u2606    $$        Quality content\n",
        "Reflexion         \u2605\u2605\u2606\u2606\u2606   \u2605\u2605\u2605\u2605\u2605    $$$       Verified facts\n",
        "Deep Agent        \u2605\u2606\u2606\u2606\u2606   \u2605\u2605\u2605\u2605\u2605    $$$$      Complex research\n",
        "Tree Search       \u2605\u2606\u2606\u2606\u2606   \u2605\u2605\u2605\u2605\u2605    $$$$$     Optimal solutions\n",
        "\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n",
        "\"\"\"\n",
        "\n",
        "print(comparison)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: Deep Agents & Reflection\n",
        "\n",
        "### \u2705 What We Built:\n",
        "\n",
        "1. **Basic Reflection Agent**: Generate \u2192 Reflect \u2192 Revise cycle\n",
        "2. **Reflexion with Tools**: External verification and grounded critique\n",
        "3. **Deep Agent**: Planning, sub-agents, and synthesis\n",
        "4. **Research Agent**: Complete investigation workflows\n",
        "\n",
        "### \ud83c\udfaf Key Concepts:\n",
        "\n",
        "**Reflection** = Self-critique and improvement\n",
        "- Increases quality at the cost of latency\n",
        "- Reduces hallucinations through verification\n",
        "- Best for high-stakes outputs\n",
        "\n",
        "**Deep Agents** = Complex task decomposition\n",
        "- Break down objectives into steps\n",
        "- Use specialized sub-agents\n",
        "- Maintain context across long workflows\n",
        "- Synthesize results into coherent output\n",
        "\n",
        "### \ud83d\udca1 Production Tips:\n",
        "\n",
        "1. **Set iteration limits** to control costs\n",
        "2. **Define quality criteria** explicitly\n",
        "3. **Use tools** for factual grounding\n",
        "4. **Cache results** when possible\n",
        "5. **Monitor performance** with LangSmith\n",
        "\n",
        "### \ud83d\udcca When to Use:\n",
        "\n",
        "**Use Reflection when:**\n",
        "- \u2705 Quality > Speed\n",
        "- \u2705 Customer-facing content\n",
        "- \u2705 Errors have consequences\n",
        "\n",
        "**Use Deep Agents when:**\n",
        "- \u2705 Multi-step complexity\n",
        "- \u2705 Research and analysis\n",
        "- \u2705 Long-running workflows\n",
        "\n",
        "### \ud83d\ude80 Next Steps:\n",
        "\n",
        "1. Integrate with BakeryAI production system\n",
        "2. Add human-in-the-loop for approvals\n",
        "3. Implement Tree Search (LATS) for optimization\n",
        "4. Deploy with LangSmith monitoring\n",
        "\n",
        "### \ud83d\udcda Resources:\n",
        "\n",
        "- [LangChain Reflection Agents](https://blog.langchain.com/reflection-agents/)\n",
        "- [Deep Agents Architecture](https://blog.langchain.com/deep-agents/)\n",
        "- [Reflexion Paper](https://arxiv.org/abs/2303.11366)\n",
        "- [LATS Framework](https://arxiv.org/abs/2310.04406)\n",
        "\n",
        "**\ud83c\udf89 You now have advanced agentic AI capabilities for production systems!**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}